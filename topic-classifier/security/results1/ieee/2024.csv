uuid,title,response
ieee_2024_0,"IEEE Symposium on Security and Privacy, SP 2024, San Francisco, CA, USA, May 19-23, 2024.","No, the abstract is not related to AML. The text provided does not contain any information or context about machine learning systems or adversarial attacks."
ieee_2024_1,On SMS Phishing Tactics and Infrastructure.,"No. The abstract focuses on understanding and combating SMS phishing by analyzing datasets, campaigns, and infrastructure, but it does not involve adversarial techniques or manipulation of machine learning models, which are core to adversarial machine learning."
ieee_2024_2,Conning the Crypto Conman: End-to-End Analysis of Cryptocurrency-based Technical Support Scams.,"No, the abstract is not related to AML because it focuses on analyzing and mitigating cryptocurrency-based technical support scams rather than presenting techniques to manipulate or defend machine learning models."
ieee_2024_3,From Chatbots to Phishbots?: Phishing Scam Generation in Commercial Large Language Models.,"Yes, the abstract is related to AML as it discusses the use of Large Language Models to generate phishing attacks and details the creation of a detection tool to counteract these adversarial uses."
ieee_2024_4,A Representative Study on Human Detection of Artificially Generated Media Across Countries.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it primarily focuses on human perception of AI-generated media rather than discussing attacks on machine learning models or defending against adversarial inputs."
ieee_2024_5,AVA: Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection.,"Yes, the abstract is related to AML as it discusses a novel adversarial attack (AVA) that targets the vulnerabilities of DeepFake detection algorithms, which are DNN-based models, showcasing how these models can be bypassed through attribute-variation-based perturbations."
ieee_2024_6,An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape.,"Yes. The abstract is related to AML as it discusses the use of adversarial attacks on deepfake detectors, highlighting vulnerabilities and proposing defenses against such attacks."
ieee_2024_7,DP-Auditorium: A Large-Scale Library for Auditing Differential Privacy.,"No, the abstract is not related to AML as it focuses on developing a tool for testing the efficacy of differentially private mechanisms, which is more aligned with data privacy rather than adversarial machine learning attacks or defenses."
ieee_2024_8,Time-Aware Projections: Truly Node-Private Graph Statistics under Continual Observation.,"No, the abstract is not related to AML as it focuses on differential privacy in social network data, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2024_9,Synq: Public Policy Analytics Over Encrypted Data.,"No, the abstract is not related to AML because it focuses on data privacy and analytics over encrypted data rather than addressing adversarial attacks or defenses related to machine learning models."
ieee_2024_10,The Great Request Robbery: An Empirical Study of Client-side Request Hijacking Vulnerabilities on the Web.,"No. The abstract focuses on request forgery attacks in web applications, which are more related to web security rather than adversarial machine learning."
ieee_2024_11,Break the Wall from Bottom: Automated Discovery of Protocol-Level Evasion Vulnerabilities in Web Application Firewalls.,"Yes. This abstract relates to AML as it discusses testing for vulnerabilities in Web Application Firewalls that adversaries could exploit to evade detection, aligning with the concept of evasion attacks in AML."
ieee_2024_12,"Parse Me, Baby, One More Time: Bypassing HTML Sanitizer via Parsing Differentials.","No. The abstract focuses on HTML sanitization and parsing differentials for preventing cross-site scripting (XSS) attacks, which is a web security concern, not directly related to adversarial machine learning attacks on ML models."
ieee_2024_13,Holistic Concolic Execution for Dynamic Web Applications via Symbolic Interpreter Analysis.,"No. The abstract focuses on symbolic execution and vulnerability detection in web applications using a novel approach for improved syntax support and code coverage, without any mention of adversarial machine learning or manipulating machine learning models."
ieee_2024_14,Where URLs Become Weapons: Automated Discovery of SSRF Vulnerabilities in Web Applications.,"No, the abstract is not related to AML because it focuses on detecting Server-Side Request Forgery (SSRF) vulnerabilities in web applications, which is a web security issue, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2024_15,SINBAD: Saliency-informed detection of breakage caused by ad blocking.,"No, the abstract is not related to AML. It focuses on detecting breakages in privacy-enhancing blocking tools and improving filter rules, rather than on adversarial attacks or defenses in machine learning systems."
ieee_2024_16,C-Frame: Characterizing and measuring in-the-wild CAPTCHA attacks.,"No, the abstract is not related to AML. It focuses on measuring and analyzing CAPTCHA attacks rather than exploring adversarial methods targeting machine learning models."
ieee_2024_17,Jasmine: Scale up JavaScript Static Security Analysis with Computation-based Semantic Explanation.,"No, the abstract is not related to AML because it focuses on improving static data flow analysis for detecting vulnerabilities in web applications, rather than addressing adversarial attacks or defenses in machine learning systems."
ieee_2024_18,A Tale of Two Industroyers: It was the Season of Darkness.,"No. The abstract focuses on studying malware that targets industrial control systems and developing a sandbox for understanding malware behavior, which does not specifically involve adversarial attacks on machine learning systems."
ieee_2024_19,AquaSonic: Acoustic Manipulation of Underwater Data Center Operations and Resource Management.,"No, this abstract is not related to Adversarial Machine Learning because it focuses on identifying and mitigating acoustic injection attacks on underwater data centers, which primarily pertains to physical security vulnerabilities rather than manipulating or attacking any machine learning models."
ieee_2024_20,"""Watching over the shoulder of a professional"": Why Hackers Make Mistakes and How They Fix Them.","No. The abstract is focused on examining mistakes made in vulnerability discovery processes using social media analysis, rather than addressing adversarial attacks or machine learning system vulnerabilities."
ieee_2024_21,A Picture is Worth 500 Labels: A Case Study of Demographic Disparities in Local Machine Learning Models for Instagram and TikTok.,"No, the abstract is not related to AML. It addresses biases and performance disparities in ML models used by social media apps, not adversarial attacks or defenses against them."
ieee_2024_22,MAWSEO: Adversarial Wiki Search Poisoning for Illicit Online Promotion.,"Yes. The abstract is related to AML as it discusses the automation of adversarial edits on Wiki to manipulate search results, bypass existing detection systems, and includes strategies for potential defenses, which aligns with the concepts of adversarial attacks and defenses in machine learning."
ieee_2024_23,Poisoning Web-Scale Training Datasets is Practical.,"Yes. The abstract is related to AML as it introduces dataset poisoning attacks, which are a form of adversarial attack on machine learning models."
ieee_2024_24,Don't Shoot the Messenger: Localization Prevention of Satellite Internet Users.,"No, the abstract is not related to AML because it focuses on protecting satellite Internet users from localization and triangulation, rather than discussing any machine learning model or adversarial attacks on such models."
ieee_2024_25,The Dark Side of Scale: Insecurity of Direct-to-Cell Satellite Mega-Constellations.,"No. The abstract is focused on exploiting signaling protocol vulnerabilities in satellite communication systems, rather than targeting machine learning models or systems."
ieee_2024_26,SoK: Collusion-resistant Multi-party Private Set Intersections in the Semi-honest Model.,"No, the abstract is not related to AML. It discusses private set intersection protocols in a cryptographic context rather than addressing adversarial attacks or defenses in a machine learning setting."
ieee_2024_27,GAuV: A Graph-Based Automated Verification Framework for Perfect Semi-Honest Security of Multiparty Computation Protocols.,"No, the given abstract is related to the security verification of Multiparty Computation (MPC) protocols, which is more relevant to cryptography and protocol analysis, not adversarial machine learning."
ieee_2024_28,Don't Eject the Impostor: Fast Three-Party Computation With a Known Cheater.,"No. The abstract focuses on secure multi-party computation (MPC) protocols for privacy-preserving computations, which do not specifically involve adversarial attacks or defenses in machine learning."
ieee_2024_29,Scalable Mixed-Mode MPC.,"No, the abstract is not related to AML. It focuses on the design and implementation of a secure multi-party computation (MPC) system, which is more relevant to cryptographic protocols and secure computation rather than malicious attacks or defenses in machine learning."
ieee_2024_30,Asterisk: Super-fast MPC with a Friend.,No. This abstract focuses on secure multiparty computation (MPC) for privacy-preserving collaborative computation and does not discuss machine learning models or adversarial attacks and defenses.
ieee_2024_31,Efficient Actively Secure DPF and RAM-based 2PC with One-Bit Leakage.,"No, the abstract is not related to AML as it focuses on improving the efficiency and security of secure two-party computation protocols in the RAM model, without discussing adversarial machine learning attacks or defenses."
ieee_2024_32,MPC-in-the-Head Framework without Repetition and its Applications to the Lattice-based Cryptography.,"No. The abstract discusses a novel method for Non-Interactive Zero-Knowledge Arguments of Knowledge in cryptographic protocols, not involving adversarial machine learning or manipulating ML models."
ieee_2024_33,Orca: FSS-based Secure Training and Inference with GPUs.,"No. The abstract is focused on optimizing secure two-party computation (2PC) and improving efficiency with GPUs for machine learning scenarios, but it does not discuss adversarial attacks or defenses related to machine learning systems."
ieee_2024_34,"Security, Privacy, and Data-sharing Trade-offs When Moving to the United States: Insights from a Qualitative Study.","No, the abstract is not related to Adversarial Machine Learning (AML) as it discusses privacy and security concerns faced by individuals moving to a new country, rather than focusing on attacks or defenses involving machine learning systems."
ieee_2024_35,SoK: Safer Digital-Safety Research Involving At-Risk Users.,"No, the abstract is not related to AML. It focuses on digital safety research for at-risk users and discusses research risks, safety practices, and guidelines in the context of computer security and privacy, not adversarial machine learning."
ieee_2024_36,Janus: Safe Biometric Deduplication for Humanitarian Aid Distribution.,"No. This abstract discusses privacy-enhancing technologies and biometrics for preventing double registration in aid distribution, without mentioning machine learning models, adversarial attacks, or their defenses."
ieee_2024_37,SoK: Technical Implementation and Human Impact of Internet Privacy Regulations.,"No. The abstract is related to privacy laws and data protection regulations, not adversarial machine learning or attacks on ML systems."
ieee_2024_38,Digital Security - A Question of Perspective A Large-Scale Telephone Survey with Four At-Risk User Groups.,"No, the given abstract is not related to AML. It focuses on the digital security experiences and concerns of various user groups in Germany, rather than discussing adversarial machine learning attacks or defenses."
ieee_2024_39,No Easy Way Out: the Effectiveness of Deplatforming an Extremist Forum to Suppress Hate and Harassment.,"No, the abstract is not related to AML because it focuses on the challenges of deplatforming online hate and harassment forums, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2024_40,Withdrawing is believing? Detecting Inconsistencies between Withdrawal Choices and Third-party Data Collections in Mobile Apps.,"No, the given abstract is not related to AML because it focuses on detecting withdrawal inconsistencies in mobile apps' data collection, which pertains to privacy issues rather than adversarial machine learning attacks or defenses."
ieee_2024_41,The Role of User-Agent Interactions on Mobile Money Practices in Kenya and Tanzania.,"No, the abstract is not related to AML. It focuses on the practices, challenges, and workarounds in mobile money services in Africa, rather than machine learning systems or adversarial attacks."
ieee_2024_42,You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content.,"No, this abstract is not related to AML. It discusses using large language models for detecting and mitigating toxic content, but does not address adversarial techniques or attacks against machine learning systems."
ieee_2024_43,Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models.,"No. The abstract is about detecting online hate using a novel framework with reasoning-based techniques, and does not discuss adversarial attacks on machine learning systems or defenses against such attacks, which is the focus of AML."
ieee_2024_44,Nightshade: Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models.,"Yes. The abstract discusses poisoning attacks on diffusion-based text-to-image models and introduces ""Nightshade,"" an attack optimized for potency, indicating a focus on adversarial manipulation of machine learning systems."
ieee_2024_45,On Large Language Models' Resilience to Coercive Interrogation.,"Yes, the abstract is related to AML because it describes a method for extracting harmful content from large language models, which involves understanding and manipulating model outputs, a characteristic of adversarial attacks."
ieee_2024_46,PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification.,"No. The abstract focuses on the protection of prompt copyright through watermarking, not on adversarial attacks or defenses related to the behavior of machine learning models."
ieee_2024_47,"LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities (Yet?): A Comprehensive Evaluation, Framework, and Benchmarks.","No. The given abstract focuses on evaluating the capability of Large Language Models (LLMs) to identify and reason about security-related bugs, but it does not discuss manipulating ML systems or adversarial attacks, which are key aspects of Adversarial Machine Learning."
ieee_2024_48,LLMIF: Augmented Large Language Model for Fuzzing IoT Devices.,"No. The abstract is related to improving IoT protocol fuzzing using large language models, but it does not involve adversarial machine learning tactics or defense mechanisms against adversarial attacks."
ieee_2024_49,SneakyPrompt: Jailbreaking Text-to-image Generative Models.,"Yes. The abstract describes an adversarial attack framework called SneakyPrompt that manipulates the input to text-to-image generative models to bypass safety filters, which is a form of adversarial machine learning."
ieee_2024_50,Eureka: A General Framework for Black-box Differential Privacy Estimators.,"No. The abstract is focused on differential privacy and its estimation methods, rather than on adversarial attacks or defenses in machine learning."
ieee_2024_51,Casual Users and Rational Choices within Differential Privacy.,"No. The abstract focuses on differential privacy, user comprehension, and communication methods of privacy parameters, rather than discussing adversarial attacks or defenses on machine learning systems."
ieee_2024_52,Lower Bounds for Rényi Differential Privacy in a Black-Box Setting.,"No. The abstract focuses on assessing privacy guarantees for algorithms through Rényi Differential Privacy, not on adversarial attacks or defenses specific to machine learning models."
ieee_2024_53,Bounded and Unbiased Composite Differential Privacy.,"No. The abstract focuses on developing a differentially private mechanism for privacy-preserving data analysis, which is about safeguarding personal data rather than adversarially attacking or defending machine learning systems."
ieee_2024_54,Cohere: Managing Differential Privacy in Large Scale Systems.,"No. The abstract is focused on privacy management and the implementation of Differential Privacy (DP) in large-scale systems, which is more about privacy preservation and not specifically about adversarial attacks or defenses in machine learning."
ieee_2024_55,DPI: Ensuring Strict Differential Privacy for Infinite Data Streaming.,"No, the abstract is related to differential privacy in the context of streaming data and focuses on privacy leakage prevention rather than adversarial attacks or defenses in machine learning systems."
ieee_2024_56,Budget Recycling Differential Privacy.,"No. The abstract is related to improving differential privacy mechanisms and managing the privacy-utility tradeoff, which doesn't pertain to adversarial attacks or defenses in machine learning systems."
ieee_2024_57,Measure-Observe-Remeasure: An Interactive Paradigm for Differentially-Private Exploratory Analysis.,"No. The abstract focuses on differential privacy and how analysts allocate their privacy loss budget during interactive data analysis, which does not involve manipulating machine learning models or adversarial attacks."
ieee_2024_58,Everyone for Themselves? A Qualitative Study about Individual Security Setups of Open Source Software Contributors.,"No. This abstract is focused on the security practices of open-source software contributors and their impact on supply chain security, without any specific reference to adversarial machine learning or attacks on machine learning models."
ieee_2024_59,Measuring the Effects of Stack Overflow Code Snippet Evolution on Open-Source Software Security.,"No, the abstract is not related to AML because it focuses on the security implications of using outdated code snippets from Stack Overflow in GitHub projects, rather than on adversarial attacks or defenses concerning machine learning systems."
ieee_2024_60,Shedding Light on CVSS Scoring Inconsistencies: A User-Centric Study on Evaluating Widespread Security Vulnerabilities.,"No, the abstract is not related to AML because it focuses on evaluating the consistency and factors influencing the Common Vulnerability Scoring System (CVSS) for vulnerability assessment, rather than addressing adversarial attacks or defenses in machine learning systems."
ieee_2024_61,TrojanPuzzle: Covertly Poisoning Code-Suggestion Models.,"Yes, the abstract is related to AML because it discusses data poisoning attacks on large language models used for code suggestion, specifically targeting model behavior by injecting malicious data."
ieee_2024_62,Poisoned ChatGPT Finds Work for Idle Hands: Exploring Developers' Coding Practices with Insecure Suggestions from Poisoned AI Models.,"Yes. The abstract is related to AML because it discusses poisoning attacks on AI-powered coding assistant tools, which intentionally introduce malicious code to manipulate the tools and potentially introduce vulnerabilities into developers' programs."
ieee_2024_63,"Signing in Four Public Software Package Registries: Quantity, Quality, and Influencing Factors.","No. The abstract discusses software signing practices and supply chain security, which are not directly related to adversarial machine learning attacks or defenses."
ieee_2024_64,"More Haste, Less Speed: Cache Related Security Threats in Continuous Integration Services.","No. The abstract is related to security threats in Continuous Integration platforms, specifically focusing on cache poisoning and data leakage, which does not directly involve adversarial attacks on machine learning models."
ieee_2024_65,Patchy Performance? Uncovering the Vulnerability Management Practices of IoT-Centric Vendors.,"No. The abstract focuses on analyzing factors influencing IoT vendors' security performance and their vulnerability disclosure and patching behaviors, without discussing adversarial attacks or defenses specific to machine learning systems."
ieee_2024_66,Need for Speed: Taming Backdoor Attacks with Speed and Precision.,"Yes. The abstract discusses backdoor attacks, a form of adversarial attack, and presents a defense mechanism for identifying and removing such threats from DNNs, making it related to adversarial machine learning."
ieee_2024_67,Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection.,"Yes. The abstract discusses adversarial attacks on a graph neural network-based malicious domain detection system by manipulating features and connections in a domain maliciousness graph, fitting AML's focus on manipulating machine learning models."
ieee_2024_68,Dropout Attacks.,"Yes, the abstract is related to AML because it introduces a new type of poisoning attack, DROPOUTATTACK, which manipulates the dropout mechanism in neural networks to degrade performance, specifically targeting the training and prediction processes."
ieee_2024_69,BounceAttack: A Query-Efficient Decision-based Adversarial Attack by Bouncing into the Wild.,"Yes. The abstract discusses an adversarial attack method (BounceAttack) that targets deep neural networks in a black-box setting, which is a core aspect of adversarial machine learning."
ieee_2024_70,Loki: Large-scale Data Reconstruction Attack against Federated Learning through Model Manipulation.,"Yes. The abstract describes an attack on federated learning systems that exploits vulnerabilities in shared gradients to reconstruct private data, which falls under adversarial machine learning."
ieee_2024_71,Test-Time Poisoning Attacks Against Test-Time Adaptation Models.,"Yes. The abstract is related to AML as it discusses test-time poisoning attacks on ML models, which involves manipulating inputs to impact model performance, fitting within the scope of adversarial machine learning."
ieee_2024_72,Attacking Byzantine Robust Aggregation in High Dimensions.,"Yes. The abstract is related to AML as it discusses poisoning attacks and a new attack called HiDRA that targets Byzantine robust aggregation, which are both relevant to adversarial machine learning."
ieee_2024_73,"CaFA: Cost-aware, Feasible Attacks With Database Constraints Against Neural Tabular Classifiers.","Yes, this abstract is related to AML as it discusses the creation of a system called CaFA for generating adversarial examples specifically designed to test the robustness of neural tabular classifiers, which are a type of machine learning model."
ieee_2024_74,Universal Neural-Cracking-Machines: Self-Configurable Password Models from Auxiliary Data.,"No, the abstract is not related to AML because it focuses on creating a password model using deep learning for password strength estimation and adaptation without discussing adversarial attacks or defenses in machine learning systems."
ieee_2024_75,PassREfinder: Credential Stuffing Risk Prediction by Representing Password Reuse between Websites on a Graph.,"No. The abstract focuses on preventing credential stuffing attacks and password reuse using a risk prediction framework and graph neural networks, which is more related to cybersecurity and user behavior than to adversarial machine learning."
ieee_2024_76,Breach Extraction Attacks: Exposing and Addressing the Leakage in Second Generation Compromised Credential Checking Services.,"No, the abstract is focused on a security analysis and protocol improvement for preventing credential tweaking attacks, which relates more to cryptographic privacy and data security than adversarial machine learning."
ieee_2024_77,A Security Analysis of Honey Vaults.,"No. The abstract focuses on honey encryption and techniques to improve password vault security, addressing cryptographic challenges rather than adversarial machine learning attacks on machine learning models."
ieee_2024_78,Combing for Credentials: Active Pattern Extraction from Smart Reply.,"Yes. The abstract describes an active extraction attack in an adversarial context, targeting vulnerabilities in large language models to extract sensitive data, which is a relevant aspect of adversarial machine learning."
ieee_2024_79,ARMOR: A Formally Verified Implementation of X.509 Certificate Chain Validation.,"No. The abstract is focused on formal verification and validation of X.509 certificate chain logic, which is related to cryptographic protocols and security, not adversarial machine learning."
ieee_2024_80,DY Fuzzing: Formal Dolev-Yao Models Meet Cryptographic Protocol Fuzz Testing.,"No, the abstract is not related to AML as it focuses on cryptographic protocol vulnerabilities and logical attacks using formal verification and fuzzing, rather than adversarial attacks on machine learning models."
ieee_2024_81,To Auth or Not To Auth? A Comparative Analysis of the Pre- and Post-Login Security Landscape.,"No, the given abstract is not related to AML. It focuses on the security aspects of web applications, specifically analyzing differences between unauthenticated and authenticated states, without discussing adversarial attacks or machine learning models."
ieee_2024_82,Targeted and Troublesome: Tracking and Advertising on Children's Websites.,No. The abstract focuses on measuring tracking and advertising practices on child-directed websites and not on adversarial machine learning attacks or defenses.
ieee_2024_83,"Children, Parents, and Misinformation on Social Media.",No. The abstract focuses on the effects of misinformation on children and their families rather than discussing techniques for attacking or defending machine learning systems.
ieee_2024_84,Understanding Parents' Perceptions and Practices Toward Children's Security and Privacy in Virtual Reality.,"No. The abstract focuses on security and privacy concerns in the context of virtual reality for underage users and explores parental awareness and strategies, without discussing adversarial attacks or defenses related to machine learning systems."
ieee_2024_85,The Times They Are A-Changin': Characterizing Post-Publication Changes to Online News.,"No. The abstract is not related to AML because it focuses on analyzing post-publication changes in online news articles, which does not involve manipulating machine learning models or defenses against adversarial attacks."
ieee_2024_86,The Inventory is Dark and Full of Misinformation: Understanding Ad Inventory Pooling in the Ad-Tech Supply Chain.,"No, the abstract is not related to AML because it focuses on deception and transparency issues within the ad-tech supply chain rather than adversarial attacks or defenses in machine learning systems."
ieee_2024_87,Specious Sites: Tracking the Spread and Sway of Spurious News Stories at Scale.,"No. The abstract focuses on identifying and tracking misinformation narratives online using machine learning, but it does not discuss manipulating or defending against adversarial attacks on a machine learning model."
ieee_2024_88,ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features.,"Yes. The abstract discusses adversarial attacks on automatic speech recognition systems, which aligns with adversarial machine learning as it involves generating adversarial examples to manipulate machine learning model outputs."
ieee_2024_89,FlowMur: A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge.,"Yes. The abstract is related to AML as it describes the development of FlowMur, a method for performing backdoor attacks on speech recognition systems powered by DNNs, which is a type of adversarial attack in machine learning."
ieee_2024_90,Understanding and Benchmarking the Commonality of Adversarial Examples.,"Yes, the abstract is related to AML as it discusses adversarial example attacks on speech recognition systems and addresses understanding and defending against these attacks."
ieee_2024_91,Scores Tell Everything about Bob: Non-adaptive Face Reconstruction on Face Recognition Systems.,"Yes. The abstract describes a score-based adversarial attack on face recognition systems, specifically targeting the reconstruction and impersonation of faces, which is a form of adversarial machine learning."
ieee_2024_92,OdScan: Backdoor Scanning for Object Detection Models.,"Yes, the abstract is related to AML as it discusses backdoor attacks on deep learning-based object detection models and proposes a new technique for trigger inversion to address these adversarial threats."
ieee_2024_93,Transferable Multimodal Attack on Vision-Language Pre-training Models.,"Yes. The abstract describes an adversarial attack framework for Vision-Language Pre-training (VLP) models, which fits within the domain of Adversarial Machine Learning as it focuses on exploiting vulnerabilities in ML models and enhancing attack transferability."
ieee_2024_94,Certifying Zero-Knowledge Circuits with Refinement Types.,"No, the abstract is not related to Adversarial Machine Learning. It focuses on zero-knowledge proof systems and the development of a programming language for formal verification in cryptographic applications, rather than addressing adversarial attacks or defenses in machine learning systems."
ieee_2024_95,Ligetron: Lightweight Scalable End-to-End Zero-Knowledge Proofs Post-Quantum ZK-SNARKs on a Browser.,"No. The abstract is about designing an efficient zero-knowledge proof system called Ligetron, which is a cryptographic method, not related to adversarial machine learning or attacks on machine learning systems."
ieee_2024_96,Pianist: Scalable zkRollups via Fully Distributed Zero-Knowledge Proofs.,"No, the abstract is not related to AML because it discusses blockchain scalability and zero-knowledge proofs, which pertain to cryptography rather than adversarial machine learning or attacks on machine learning systems."
ieee_2024_97,Scalable Verification of Zero-Knowledge Protocols.,"No, the given abstract is not related to AML as it discusses Zero-Knowledge proofs and techniques for verifying properties of arithmetic circuits, which are more relevant to cryptographic protocols and not about adversarial machine learning attacks or defenses."
ieee_2024_98,Efficient Zero-Knowledge Arguments For Paillier Cryptosystem.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on enhancements to zero-knowledge proofs for the Paillier cryptosystem, which is more about cryptographic improvements rather than manipulating or defending ML models against adversarial attacks."
ieee_2024_99,SwiftRange: A Short and Efficient Zero-Knowledge Range Argument For Confidential Transactions and More.,"No, this abstract is unrelated to AML because it focuses on zero-knowledge range proofs for confidential transactions in blockchain systems, not on adversarial attacks or defenses related to machine learning models."
ieee_2024_100,Titan : Efficient Multi-target Directed Greybox Fuzzing.,"No, the given abstract is not related to AML because it focuses on improving the efficiency and effectiveness of directed fuzzing for software testing, which is not directly about adversarial attacks or defenses on machine learning models."
ieee_2024_101,Benzene: A Practical Root Cause Analysis System with an Under-Constrained State Mutation.,"No. The abstract is focused on software testing and root cause analysis for debugging, not on adversarial machine learning or attacks on ML systems."
ieee_2024_102,Predecessor-aware Directed Greybox Fuzzing.,"No, the given abstract is not related to AML. It describes a novel approach to software vulnerability detection using fuzzing techniques, which focuses on testing and improving software security rather than attacking or defending machine learning models."
ieee_2024_103,AFGen: Whole-Function Fuzzing for Applications and Libraries.,"No. The abstract is related to fuzzing technology for vulnerability discovery in applications and libraries, not about adversarial attacks or defenses in machine learning systems."
ieee_2024_104,Labrador: Response Guided Directed Fuzzing for Black-box IoT Devices.,"No, the abstract is primarily focused on fuzzing techniques to identify vulnerabilities in IoT firmware, which is related to software security testing rather than adversarial machine learning."
ieee_2024_105,Chronos: Finding Timeout Bugs in Practical Distributed Systems by Deep-Priority Fuzzing with Transient Delay.,"No. The abstract is focused on a testing framework for detecting timeout bugs in distributed systems, which is related to system reliability and debugging rather than adversarial machine learning."
ieee_2024_106,Everything is Good for Something: Counterexample-Guided Directed Fuzzing via Likely Invariant Inference.,"No, the given abstract is not related to AML because it describes a technique to improve directed fuzzing for bug reproduction and patch verification, which focuses on software testing rather than attacking or defending machine learning systems."
ieee_2024_107,SoK: Prudent Evaluation Practices for Fuzzing.,"No, the given abstract is not related to AML. It focuses on evaluating and improving fuzzing techniques for uncovering software bugs, which is not specifically about adversarial attacks or defenses for machine learning systems."
ieee_2024_108,MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic.,"Yes, the abstract is related to AML because it discusses detecting and mitigating backdoor attacks—a type of adversarial threat—on deep neural network classifiers."
ieee_2024_109,BadVFL: Backdoor Attacks in Vertical Federated Learning.,"Yes, the abstract is related to AML as it discusses backdoor attacks aimed at manipulating a federated learning model during training to cause misclassifications, which is a form of adversarial attack."
ieee_2024_110,Distribution Preserving Backdoor Attack in Self-supervised Learning.,"Yes. The abstract is related to AML as it addresses backdoor attacks on self-supervised learning models and proposes a method for evading existing backdoor defenses, both of which are key aspects of adversarial machine learning."
ieee_2024_111,Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics.,"Yes, the abstract is related to AML as it discusses a novel backdoor attack and proposes a detection method to identify such adversarial manipulations in deep learning models."
ieee_2024_112,DeepVenom: Persistent DNN Backdoors Exploiting Transient Weight Perturbations in Memories.,"Yes, the abstract is related to AML because it discusses the development of a backdoor attack that uses hardware-based techniques to manipulate machine learning models, which aligns with adversarial machine learning's focus on exploiting model vulnerabilities."
ieee_2024_113,Baffle: Hiding Backdoors in Offline Reinforcement Learning Datasets.,"Yes, the abstract discusses backdoor attacks on offline Reinforcement Learning (RL), a form of adversarial machine learning targeting the manipulation of datasets to trigger specific behaviors in ML agents."
ieee_2024_114,Exploring the Orthogonality and Linearity of Backdoor Attacks.,"Yes. The abstract discusses backdoor attacks, a type of adversarial attack in machine learning, and analyzes the effectiveness of various defense techniques against them, which is directly related to adversarial machine learning."
ieee_2024_115,BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting.,"Yes. The abstract is related to Adversarial Machine Learning as it discusses backdoor attacks on deep neural networks, a form of attack aimed at manipulating models, and introduces a method to enhance the stealthiness of such attacks against existing defenses."
ieee_2024_116,Formal Model-Driven Analysis of Resilience of GossipSub to Attacks from Misbehaving Peers.,"No, the abstract is not related to AML. It focuses on modeling and understanding a peer-to-peer communication protocol's resilience to misbehaving peers, which pertains to network security rather than adversarial machine learning."
ieee_2024_117,Larger-scale Nakamoto-style Blockchains Don't Necessarily Offer Better Security.,"No. The abstract focuses on analyzing the security and network dynamics of Nakamoto-style blockchain protocols, not on adversarial attacks or techniques concerning machine learning systems."
ieee_2024_118,Nurgle: Exacerbating Resource Consumption in Blockchain State Storage via MPT Manipulation.,"No, this abstract is not related to AML as it focuses on a Denial-of-Service attack targeting blockchain state storage, rather than any adversarial attacks or defenses involving machine learning systems."
ieee_2024_119,Nyx: Detecting Exploitable Front-Running Vulnerabilities in Smart Contracts.,"No. The abstract is about detecting front-running vulnerabilities in smart contracts, which is more related to blockchain security rather than adversarial machine learning."
ieee_2024_120,SmartInv: Multimodal Learning for Smart Contract Invariant Inference.,"No, the abstract is not related to AML. It focuses on detecting bugs in smart contracts using a framework to infer invariants from multiple sources of information, rather than on malicious attacks or defenses in machine learning systems."
ieee_2024_121,Pulling Off The Mask: Forensic Analysis of the Deceptive Creator Wallets Behind Smart Contract Fraud.,"No. The abstract focuses on fraudulent activities related to crypto wallets and smart contracts, which is more related to cybersecurity and forensic analysis rather than adversarial machine learning."
ieee_2024_122,Towards Smart Contract Fuzzing on GPUs.,"No, the given abstract is not related to Adversarial Machine Learning (AML) because it focuses on improving the throughput of fuzzing for smart contracts using GPU parallel computing, which does not involve manipulating machine learning inputs or exploring adversarial attacks or defenses."
ieee_2024_123,Large-Scale Study of Vulnerability Scanners for Ethereum Smart Contracts.,"No, the abstract is not related to AML because it focuses on evaluating security scanners for Ethereum smart contract vulnerabilities, without discussing machine learning models or adversarial attacks."
ieee_2024_124,Who Left the Door Open? Investigating the Causes of Exposed IoT Devices in an Academic Network.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on identifying and addressing misconfigured IoT devices exposing Telnet and FTP services in a network without discussing attacks or defenses related to machine learning systems."
ieee_2024_125,SyzTrust: State-aware Fuzzing on Trusted OS Designed for IoT Devices.,"No. The abstract is focused on developing a framework for security analysis of Trusted Operating Systems in IoT devices, which pertains to hardware-level security and vulnerability detection rather than adversarial machine learning."
ieee_2024_126,A Systematic Study of Physical Sensor Attack Hardness.,"Yes, the abstract is related to AML because it addresses the study of sensor attacks on robotic vehicles, highlighting the challenges, prerequisites, and potential vulnerabilities, which are core aspects of adversarial machine learning."
ieee_2024_127,Revisiting Automotive Attack Surfaces: a Practitioners' Perspective.,"No, the abstract is not related to AML because it primarily addresses cybersecurity challenges and improvements in threat analysis for automotive systems without mentioning adversarial attacks on machine learning models."
ieee_2024_128,From Virtual Touch to Tesla Command: Unlocking Unauthenticated Control Chains From Smart Glasses for Vehicle Takeover.,"Yes, the abstract is related to AML because it discusses exploiting vulnerabilities and executing attacks on systems controlled by automated tools, which aligns with the concepts of adversarial attacks on security-critical automated systems."
ieee_2024_129,MQTTactic: Security Analysis and Verification for Logic Flaws in MQTT Implementations.,"No, the abstract is not related to AML because it focuses on the security analysis of MQTT brokers in IoT systems, rather than on adversarial attacks or defenses against machine learning models."
ieee_2024_130,Wear's my Data? Understanding the Cross-Device Runtime Permission Model in Wearables.,"No. The abstract focuses on the privacy and permission issues in wearable devices and companion apps, rather than on adversarial attacks or manipulations in machine learning systems."
ieee_2024_131,Video-Based Cryptanalysis: Extracting Cryptographic Keys from Video Footage of a Device's Power LED Captured by Standard Video Cameras.,"No, the abstract is not related to Adversarial Machine Learning (AML). It focuses on video-based cryptanalysis to recover secret keys through side-channel attacks on power consumption, which is unrelated to attacks or defenses specifically targeting machine learning models."
ieee_2024_132,SoK: Explainable Machine Learning in Adversarial Environments.,Yes. The abstract is related to AML because it discusses the vulnerabilities of explainable machine learning methods to adversarial attacks and the development of robust defenses against such manipulations.
ieee_2024_133,GrOVe: Ownership Verification of Graph Neural Networks using Embeddings.,"Yes, the abstract is related to AML, as it discusses model extraction attacks on Graph Neural Networks (GNNs) and proposes a defense mechanism to verify model ownership, which is an aspect of adversarial machine learning."
ieee_2024_134,Revisiting Black-box Ownership Verification for Graph Neural Networks.,"Yes, the abstract is related to AML as it discusses methods to mitigate model extraction attacks, a type of adversarial attack, on Graph Neural Networks (GNNs)."
ieee_2024_135,CORELOCKER: Neuron-level Usage Control.,"No, the abstract is not related to AML. It focuses on protecting the intellectual property of machine learning models by selectively controlling model access rather than addressing or mitigating adversarial attacks or manipulation of models."
ieee_2024_136,MEA-Defender: A Robust Watermark against Model Extraction Attack.,"Yes, the abstract is related to AML because it discusses defending Deep Neural Networks against model extraction attacks, which are a type of adversarial attack intended to infringe on intellectual property by replicating model behavior."
ieee_2024_137,Securing Graph Neural Networks in MLaaS: A Comprehensive Realization of Query-based Integrity Verification.,"Yes. The abstract is related to AML as it discusses protection mechanisms against model-centric attacks on Graph Neural Networks, which are malicious attacks that manipulate model parameters to affect predictions."
ieee_2024_138,Sophon: Non-Fine-Tunable Learning to Restrain Task Transferability For Pre-trained Models.,"Yes. The abstract is related to AML as it addresses the prevention of misuse of pre-trained models for unethical tasks, and proposes a protection framework to make models resistant to being fine-tuned for such purposes."
ieee_2024_139,FLShield: A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks.,"Yes. The abstract is related to AML as it discusses the design of a federated learning system that is robust against adversarial attacks, specifically mentioning defenses against poisoning and backdoor attacks."
ieee_2024_140,"Secure Messaging with Strong Compromise Resilience, Temporal Privacy, and Immediate Decryption.","No. The abstract focuses on designing a secure messaging protocol with properties like resilience against compromises and temporal privacy, which are primarily related to cryptography and security, not adversarial machine learning."
ieee_2024_141,Private Hierarchical Governance for Encrypted Messaging.,"No. The abstract is about designing private hierarchical governance systems for end-to-end encrypted messaging, which focuses on content moderation and privacy rather than adversarial attacks or defenses on machine learning models."
ieee_2024_142,Enforcing End-to-end Security for Remote Conference Applications.,"No, the given abstract is not related to AML because it focuses on secure data encryption and end-to-end encryption for conference applications, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2024_143,Injection Attacks Against End-to-End Encrypted Applications.,"No. The abstract is not related to AML as it focuses on exploiting encryption and analyzing ciphertext lengths in messaging apps, rather than manipulating machine learning models or datasets."
ieee_2024_144,Device-Oriented Group Messaging: A Formal Cryptographic Analysis of Matrix' Core.,"No. The abstract is focused on the formal description and analysis of the cryptographic aspects of the Matrix secure group messaging protocol, not on adversarial machine learning or attacks on ML systems."
ieee_2024_145,Multi-Stage Group Key Distribution and PAKEs: Securing Zoom Groups against Malicious Servers without New Security Elements.,"No, the abstract is related to enhancing security protocols in video conferencing applications like Zoom to protect against malicious servers, but it does not specifically address adversarial machine learning, attacks on machine learning models, or defenses."
ieee_2024_146,"Holepunch: Fast, Secure File Deletion with Crash Consistency.","No, the given abstract is not related to AML as it focuses on secure deletion of data on file systems using cryptographic techniques and does not involve adversarial attacks or defenses in the context of machine learning."
ieee_2024_147,INVISILINE: Invisible Plausibly-Deniable Storage.,"No, the abstract is not related to AML. It focuses on the development of a plausibly-deniable storage system to maintain data invisibility from adversaries, which pertains more to data security and privacy rather than adversarial machine learning."
ieee_2024_148,Guessing on Dominant Paths: Understanding the Limitation of Wireless Authentication Using Channel State Information.,"No. The abstract is focused on wireless network authentication and channel state information (CSI) rather than on machine learning systems, their vulnerabilities, or adversarial attacks, which are central to AML."
ieee_2024_149,MetaFly: Wireless Backhaul Interception via Aerial Wavefront Manipulation.,"No, the abstract is not related to AML as it focuses on eavesdropping on wireless backhaul links using aerial metasurfaces, which pertains to physical layer security rather than adversarial machine learning attacks or defenses."
ieee_2024_150,NFCEraser: A Security Threat of NFC Message Modification Caused by Quartz Crystal Oscillator.,"No. This abstract is related to a security vulnerability in NFC communication, focusing on electromagnetic interference, rather than adversarial attacks on machine learning systems."
ieee_2024_151,Secure Ranging with IEEE 802.15.4z HRP UWB.,"No, the abstract is not related to AML. It focuses on secure ranging using ultra-wideband impulse radio and analyzing the security of specific waveform implementations, rather than on manipulating machine learning models or their inputs."
ieee_2024_152,MIMOCrypt: Multi-User Privacy-Preserving Wi-Fi Sensing via MIMO Encryption.,"No, this abstract is not related to AML. It focuses on a privacy-preserving Wi-Fi sensing framework using MIMO technology for human sensing and encryption, without addressing machine learning attacks or defenses."
ieee_2024_153,Surveilling the Masses with Wi-Fi-Based Positioning Systems.,"No, the given abstract is not related to AML because it focuses on the privacy implications of Wi-Fi-based Positioning Systems and geolocation tracking, not on manipulating or attacking machine learning systems."
ieee_2024_154,SoK: The Long Journey of Exploiting and Defending the Legacy of King Harald Bluetooth.,"No, the abstract is not related to Adversarial Machine Learning as it focuses on Bluetooth security, attacks, and defenses without discussing any machine learning systems or the manipulation of their inputs and outputs."
ieee_2024_155,Practical Obfuscation of BLE Physical-Layer Fingerprints on Mobile Devices.,"No, the given abstract is not related to AML. It focuses on obfuscating physical-layer hardware imperfections to prevent device tracking via BLE signals, which pertains to hardware security rather than adversarial machine learning."
ieee_2024_156,It's Simplex! Disaggregating Measures to Improve Certified Robustness.,"Yes. The abstract relates to AML as it discusses certified robustness, a method to defend against adversarial attacks and improve the analysis and performance of certification mechanisms on machine learning models."
ieee_2024_157,Sabre: Cutting through Adversarial Noise with Adaptive Spectral Filtering and Input Reconstruction.,"Yes. The abstract discusses the susceptibility of neural networks to adversarial perturbations and introduces a defense framework, signifying its relevance to adversarial machine learning."
ieee_2024_158,Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks.,"Yes. The abstract discusses adversarial attacks on language models, specifically focusing on defending against textual adversarial attacks and proposing a robustness framework, which falls under the category of Adversarial Machine Learning."
ieee_2024_159,FCert: Certifiably Robust Few-Shot Classification in the Era of Foundation Models.,"Yes. The abstract discusses data poisoning attacks and a certified defense for few-shot classification, both of which are topics relevant to adversarial machine learning."
ieee_2024_160,Node-aware Bi-smoothing: Certified Robustness against Graph Injection Attacks.,"Yes. The abstract is related to AML as it discusses vulnerabilities in Deep Graph Learning models, specifically addressing defense techniques against evasion and poisoning attacks, which are key concepts in adversarial machine learning."
ieee_2024_161,LACMUS: Latent Concept Masking for General Robustness Enhancement of DNNs.,"Yes. The abstract is related to AML as it discusses enhancing the robustness of DNNs against adversarial attacks through the LACMUS methodology, aiming to address vulnerabilities to adversarial perturbations."
ieee_2024_162,SoK: Unintended Interactions among Machine Learning Defenses and Risks.,"Yes. The abstract addresses the security and privacy risks associated with machine learning models and discusses a framework to recognize and explain interactions between different defenses, which is relevant to adversarial machine learning."
ieee_2024_163,Securely Fine-tuning Pre-trained Encoders Against Adversarial Examples.,"Yes, the abstract is related to AML as it discusses the susceptibility of pre-trained encoders to downstream-agnostic adversarial examples and proposes a method to enhance robustness against such attacks."
ieee_2024_164,hinTS: Threshold Signatures with Silent Setup.,"No, the abstract is not related to AML as it focuses on cryptographic techniques for threshold signature schemes, without any mention of adversarial attacks or machine learning models."
ieee_2024_165,Threshold ECDSA in Three Rounds.,No. This abstract is related to cryptographic protocols for threshold ECDSA signing and does not involve adversarial machine learning attacks or defenses on machine learning models.
ieee_2024_166,"Private Analytics via Streaming, Sketching, and Silently Verifiable Proofs.","No. The abstract is not related to AML; it focuses on a system for privacy-preserving data collection and efficient server communication, rather than malicious attacks or manipulations against machine learning systems."
ieee_2024_167,"Hyena: Balancing Packing, Reuse, and Rotations for Encrypted Inference.","No, this abstract is not related to AML. It focuses on improving performance and energy efficiency for AI services using homomorphic encryption rather than discussing techniques to attack or defend machine learning models adversarially."
ieee_2024_168,Make Revocation Cheaper: Hardware-Based Revocable Attribute-Based Encryption.,"No, the abstract is not related to AML because it focuses on attribute-based encryption and user revocation for secure data storage, without discussing machine learning systems or adversarial attacks against them."
ieee_2024_169,SoK: Efficient Design and Implementation of Polynomial Hash Functions over Prime Fields.,"No, the abstract is not related to AML because it focuses on the design and optimization of polynomial hash functions for cryptographic purposes rather than discussing adversarial attacks or defenses on machine learning systems."
ieee_2024_170,Springproofs: Efficient Inner Product Arguments for Vectors of Arbitrary Length.,"No. The abstract is unrelated to AML as it focuses on cryptographic techniques for improving inner product arguments in blockchain applications, without addressing adversarial attacks or machine learning systems."
ieee_2024_171,CryptoVampire: Automated Reasoning for the Complete Symbolic Attacker Cryptographic Model.,"No. The abstract focuses on cryptographic protocol verification and formal security proofs, which are more related to cryptography and symbolic reasoning than adversarial machine learning."
ieee_2024_172,Nebula: A Privacy-First Platform for Data Backhaul.,"No, the abstract is not related to AML because it focuses on enabling IoT devices to connect to the cloud through a decentralized, privacy-focused network without mentioning any manipulation or adversarial interaction with machine learning models."
ieee_2024_173,Pudding: Private User Discovery in Anonymity Networks.,"No, the abstract is not related to AML because it focuses on a protocol for user discovery and privacy in anonymity networks, and does not discuss adversarial attacks or machine learning systems."
ieee_2024_174,Attacking and Improving the Tor Directory Protocol.,"No. The abstract is related to security vulnerabilities and enhancements in the Tor network's consensus protocol, without any mention of machine learning models or adversarial attacks on them."
ieee_2024_175,Real-Time Website Fingerprinting Defense via Traffic Cluster Anonymization.,"Yes, the abstract is related to AML as it addresses a defense mechanism against deep learning-based Website Fingerprinting attacks, which are a type of adversarial attack on anonymity networks."
ieee_2024_176,Learn What You Want to Unlearn: Unlearning Inversion Attacks against Machine Unlearning.,"Yes. The abstract is related to AML as it explores unlearning inversion attacks that exploit the differences between the original and unlearned models to reveal private information, and it discusses potential defenses against such attacks."
ieee_2024_177,Few-shot Unlearning.,"Yes. The abstract is related to AML as it discusses unlearning to counter a privacy attack, a concept concerned with addressing the manipulation or protection of machine learning models."
ieee_2024_178,DeepShuffle: A Lightweight Defense Framework against Adversarial Fault Injection Attacks on Deep Neural Networks in Multi-Tenant Cloud-FPGA.,"Yes, the abstract is related to AML as it discusses an adversarial fault injection attack (Deep-Dup) on DNNs within FPGA-based systems and introduces a defense mechanism (DeepShuffle) to counteract such attacks."
ieee_2024_179,DeepTheft: Stealing DNN Model Architectures through Power Side Channel.,"Yes, the abstract is related to AML because it describes an end-to-end attack using power side-channel information to steal DNN model architectures, which is a form of adversarial attack targeting machine learning systems."
ieee_2024_180,No Privacy Left Outside: On the (In-)Security of TEE-Shielded DNN Partition for On-Device ML.,"Yes, the abstract is related to AML because it addresses vulnerabilities and defenses against model stealing and membership inference attacks on DNN models, which are forms of adversarial attacks."
ieee_2024_181,One for All and All for One: GNN-based Control-Flow Attestation for Embedded Devices.,"No. The abstract is focused on Control-Flow Attestation (CFA) for detecting code reuse attacks on embedded systems using unsupervised graph neural networks, which is not directly related to manipulating or attacking machine learning systems themselves, the primary focus of adversarial machine learning (AML)."
ieee_2024_182,Why Does Little Robustness Help? A Further Step Towards Understanding Adversarial Transferability.,"Yes. The abstract discusses the transferability of adversarial examples for deep neural networks, which is directly related to adversarial machine learning and involves understanding how adversarial attacks can be effective across different model architectures."
ieee_2024_183,Backdooring Multimodal Learning.,"Yes, the abstract is related to AML because it discusses backdoor attacks on Deep Neural Networks used in multimodal learning, which is a form of adversarial attack aimed at manipulating model predictions."
ieee_2024_184,Understanding the Privacy Practices of Political Campaigns: A Perspective from the 2020 US Election Websites.,No. The abstract is focused on evaluating the privacy practices of political campaign websites and does not involve machine learning systems or adversarial attacks.
ieee_2024_185,Thwarting Last-Minute Voter Coercion.,No. The abstract is related to coercion-resistant voting schemes and does not involve adversarial attacks or defenses pertaining to machine learning systems.
ieee_2024_186,Can we cast a ballot as intended and be receipt free?,"No. The abstract is not related to AML as it discusses receipt-free voting protocols and their security properties, which is more relevant to secure voting systems rather than adversarial machine learning."
ieee_2024_187,Investigating Voter Perceptions of Printed Physical Audit Trails for Online Voting.,"No. The abstract discusses a hybrid online voting system focusing on security, trust, and usability of voting and not on adversarial machine learning, which involves manipulating or exploiting machine learning models."
ieee_2024_188,"E-Vote Your Conscience: Perceptions of Coercion and Vote Buying, and the Usability of Fake Credentials in Online Voting.","No. The abstract is focused on online voting systems and the use of fake credentials to mitigate coercion, which is not related to adversarial machine learning or attacks on machine learning models."
ieee_2024_189,NetShuffle: Circumventing Censorship with Shuffle Proxies at the Edge.,"No. The abstract describes a censorship resistance system focusing on network proxy services, which is unrelated to adversarial machine learning."
ieee_2024_190,R-CAID: Embedding Root Cause Analysis within Provenance-based Intrusion Detection.,"Yes. The abstract is related to AML because it addresses the vulnerability of provenance-based intrusion detection systems to mimicry and evasion attacks, which are types of adversarial attacks."
ieee_2024_191,Kairos: Practical Intrusion Detection and Investigation using Whole-system Provenance.,"No. The abstract describes an intrusion detection system utilizing provenance graphs and neural networks for detecting system intrusions, not adversarial machine learning attacks or defenses in machine learning models."
ieee_2024_192,Flash: A Comprehensive Approach to Intrusion Detection via Provenance Graph Representation Learning.,No. The abstract is about improving the efficiency and accuracy of an Intrusion Detection System using Graph Neural Networks and does not discuss adversarial attacks or manipulation of machine learning models.
ieee_2024_193,"eAudit: A Fast, Scalable and Deployable Audit Data Collection System.","No. The abstract is focused on improving forensic analysis systems for cyber attack detection and log collection, which does not directly relate to the manipulation or security of machine learning models."
ieee_2024_194,Understanding and Bridging the Gap Between Unsupervised Network Representation Learning and Security Analytics.,"No. The abstract focuses on improving graph security analytics using unsupervised network representation learning, but does not specifically address adversarial attacks or adversarial machine learning techniques."
ieee_2024_195,DrSec: Flexible Distributed Representations for Efficient Endpoint Security.,"No, the abstract is not related to AML. While it discusses self-supervised learning and improving security applications, it does not involve manipulating ML systems through adversarial attacks or defenses."
ieee_2024_196,Do You Play It by the Books? A Study on Incident Response Playbooks and Influencing Factors.,No. The abstract is related to the study of incident response playbooks in cybersecurity and not specifically focused on adversarial machine learning attacks or defenses.
ieee_2024_197,Jbeil: Temporal Graph-Based Inductive Learning to Infer Lateral Movement in Evolving Enterprise Networks.,"No. The abstract focuses on detecting lateral movement in enterprise networks using a self-supervised deep learning framework, but it does not discuss any adversarial attacks or defenses related to manipulating machine learning models."
ieee_2024_198,Efficient and Generic Microarchitectural Hash-Function Recovery.,"No, the abstract is not directly related to Adversarial Machine Learning (AML) as it focuses on reverse-engineering microarchitectural hash functions for improving microarchitectural attacks, which is more relevant to computer architecture and security rather than manipulating machine learning systems or data inputs."
ieee_2024_199,BUSted!!! Microarchitectural Side-Channel Attacks on the MCU Bus Interconnect.,"No. The abstract discusses side-channel attacks exploiting microcontroller hardware vulnerabilities, which differs from adversarial machine learning attacks aimed at manipulating or compromising machine learning models."
ieee_2024_200,Architectural Mimicry: Innovative Instructions to Efficiently Address Control-Flow Leakage in Data-Oblivious Programs.,"No, the abstract is not related to AML. It focuses on hardware and architectural improvements to prevent side-channel attacks, which is more aligned with computer architecture and security rather than adversarial machine learning."
ieee_2024_201,GPU.zip: On the Side-Channel Implications of Hardware-Based Graphical Data Compression.,"No, the abstract is not related to AML. It focuses on side-channel attacks related to data compression and leakage in GPU architectures, rather than adversarial attacks on machine learning models."
ieee_2024_202,ConjunCT: Learning Inductive Invariants to Prove Unbounded Instruction Safety Against Microarchitectural Timing Attacks.,"No, the given abstract is not related to AML because it focuses on identifying and addressing microarchitectural side-channel vulnerabilities in hardware, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2024_203,Prune+PlumTree - Finding Eviction Sets at Scale.,"No. The abstract focuses on improving the efficiency of finding eviction sets for cache side-channel attacks, which is related to computer architecture and security but does not involve machine learning or adversarial machine learning specifically."
ieee_2024_204,Leaky Address Masking: Exploiting Unmasked Spectre Gadgets with Noncanonical Address Translation.,"No, the abstract is not related to Adversarial Machine Learning. It focuses on the security implications of a hardware feature (Linear Address Masking) and its potential to increase the attack surface for Spectre vulnerabilities, which is more relevant to CPU security rather than machine learning."
ieee_2024_205,Rethinking IC Layout Vulnerability: Simulation-Based Hardware Trojan Threat Assessment with High Fidelity.,"No, the given abstract is not related to AML because it focuses on hardware security concerning IC design and foundry-level Trojan attacks, rather than machine learning systems and adversarial machine learning techniques."
ieee_2024_206,Routing Attacks on Cryptocurrency Mining Pools.,"No, the abstract is focused on network-level attacks against cryptocurrency mining protocols, which is not directly related to adversarial machine learning."
ieee_2024_207,Sweep-UC: Swapping Coins Privately.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on fair exchange protocols in cryptocurrencies and privacy guarantees, rather than discussing attacks or defenses in machine learning systems."
ieee_2024_208,SoK: Security and Privacy of Blockchain Interoperability.,No. The abstract focuses on the security and privacy issues related to cross-chain technologies in blockchain systems and does not discuss adversarial attacks on machine learning models.
ieee_2024_209,Non-Atomic Arbitrage in Decentralized Finance.,"No, the abstract is unrelated to AML because it focuses on maximal extractable value (MEV) and arbitrage in the Ethereum ecosystem without touching upon adversarial attacks or defenses related to machine learning."
ieee_2024_210,Optimal Flexible Consensus and its Application to Ethereum.,"No, the abstract is not related to AML because it focuses on improving safety and liveness in blockchain consensus protocols, specifically within the Ethereum protocol, not on adversarial attacks or defenses in machine learning systems."
ieee_2024_211,"PriDe CT: Towards Public Consensus, Private Transactions, and Forward Secrecy in Decentralized Payments.","No. The abstract discusses advancing a blockchain-based confidential payment system with privacy and forward secrecy, which does not involve adversarial machine learning or attacks on machine learning models."
ieee_2024_212,POMABuster: Detecting Price Oracle Manipulation Attacks in Decentralized Finance.,"No. The abstract focuses on detecting price oracle manipulation attacks in blockchain systems, which involves financial security rather than adversarial machine learning attacks on machine learning models."
ieee_2024_213,"Specular: Towards Secure, Trust-minimized Optimistic Blockchain Execution.","No, the given abstract is not related to Adversarial Machine Learning because it focuses on blockchain scalability and dispute resolution in optimistic rollups, rather than discussing machine learning attacks or defenses."
ieee_2024_214,Efficient Detection of Java Deserialization Gadget Chains via Bottom-up Gadget Search and Dataflow-aided Payload Construction.,"No. The abstract is related to a specific software vulnerability (Java Object Injection) and focuses on discovering and exploiting these vulnerabilities, rather than discussing machine learning systems or adversarial strategies against such systems."
ieee_2024_215,"""False negative - that one is going to kill you"": Understanding Industry Perspectives of Static Analysis based Security Testing.","No. The abstract focuses on understanding the perceptions and use of static analysis security testing tools by developers, without discussing adversarial machine learning or the manipulation of machine learning models."
ieee_2024_216,AirTaint: Making Dynamic Taint Analysis Faster and Easier.,"No, the abstract is not related to AML because it discusses improving the efficiency of Dynamic Taint Analysis for security purposes without mentioning adversarial attacks or defenses on machine learning systems."
ieee_2024_217,Undefined-oriented Programming: Detecting and Chaining Prototype Pollution Gadgets in Node.js Template Engines for Malicious Consequences.,"No, the abstract is not related to AML as it focuses on detecting and chaining gadgets for prototype pollution vulnerabilities in JavaScript, which is more related to software security rather than adversarial machine learning."
ieee_2024_218,APP-Miner: Detecting API Misuses via Automatically Mining API Path Patterns.,"No, the abstract is not related to AML as it focuses on extracting API patterns to detect API misuses, which does not involve adversarial attacks or the manipulation of machine learning systems."
ieee_2024_219,ERASan: Efficient Rust Address Sanitizer.,"No, the abstract is not related to AML. It focuses on memory safety in Rust programming and improving the efficiency of address sanitizers, rather than discussing adversarial machine learning or attacks on ML systems."
ieee_2024_220,"""Len or index or count, anything but v1"": Predicting Variable Names in Decompilation Output with Transfer Learning.","No. This abstract is not related to AML because it discusses a machine learning model, VarBERT, for predicting variable names in decompiled code, which is unrelated to any adversarial attack or defense mechanism in machine learning."
ieee_2024_221,SrcMarker: Dual-Channel Source Code Watermarking via Scalable Code Transformations.,No. This abstract focuses on a watermarking system for source code to track ownership and prevent misuse but does not mention attacks or defenses related to Adversarial Machine Learning.
ieee_2024_222,UnTrustZone: Systematic Accelerated Aging to Expose On-chip Secrets.,"No, the abstract is not related to AML because it focuses on physical attacks on hardware memory, specifically SRAM, and the threats to hardware-backed security enclaves, rather than attacks or defenses related to machine learning models."
ieee_2024_223,On (the Lack of) Code Confidentiality in Trusted Execution Environments.,"No. The abstract is focused on evaluating the resilience of Trusted Execution Environments (TEEs) against side-channel attacks, which is more related to system security rather than adversarial machine learning."
ieee_2024_224,SoK: SGX.Fail: How Stuff Gets eXposed.,"No, the abstract is not related to AML. It discusses Intel’s SGX and its vulnerabilities to hardware attacks and their impact on security rather than focusing on machine learning models or adversarial techniques specific to ML systems."
ieee_2024_225,Pandora: Principled Symbolic Validation of Intel SGX Enclave Runtimes.,"No. The abstract describes a tool called Pandora designed to evaluate and validate Intel SGX enclave shielding runtimes against vulnerabilities, but it does not specifically address adversarial machine learning techniques or attacks."
ieee_2024_226,Obelix: Mitigating Side-Channels Through Dynamic Obfuscation.,"No, the abstract is not related to Adversarial Machine Learning, as it focuses on protecting trusted execution environments (TEEs) from side-channel attacks and does not mention machine learning models, data, or adversarial attacks on such systems."
ieee_2024_227,Serberus: Protecting Cryptographic Code from Spectres at Compile-Time.,"No. The abstract focuses on mitigating Spectre attacks, which are hardware-based side-channel attacks, and does not relate to machine learning models or adversarial machine learning."
ieee_2024_228,WeSee: Using Malicious #VC Interrupts to Break AMD SEV-SNP.,"No, the abstract is not related to AML because it focuses on exploiting vulnerabilities in trusted execution environments (TEEs) through hypervisor manipulation rather than specifically targeting or manipulating machine learning systems."
ieee_2024_229,Sticky Tags: Efficient and Deterministic Spatial Memory Error Mitigation using Persistent Memory Tags.,"No. The abstract is focused on mitigating spatial memory errors in C/C++ programs using deterministic Memory Tagging Extensions, which does not involve machine learning models or adversarial attacks."
ieee_2024_230,Bulkor: Enabling Bulk Loading for Path ORAM.,"No, the abstract is not related to AML because it focuses on improving the efficiency of the Oblivious RAM protocol, which is a cryptographic technique for protecting data access patterns, without any mention of adversarial attacks or machine learning systems."
ieee_2024_231,Distributed & Scalable Oblivious Sorting and Shuffling.,"No, the given abstract is focused on improving the efficiency of oblivious sorting and shuffling in distributed multi-enclave environments for privacy-preserving computing, not on adversarial attacks or defenses related to machine learning systems."
ieee_2024_232,"Piano: Extremely Simple, Single-Server PIR with Sublinear Server Computation.","No. The abstract is related to private information retrieval and storage efficiency, not to adversarial machine learning attacks or defenses."
ieee_2024_233,PIRANA: Faster Multi-query PIR via Constant-weight Codes.,No. The abstract is related to cryptographic protocols for privacy-preserving applications and does not involve any adversarial machine learning concepts or attacks.
ieee_2024_234,"Communication-efficient, Fault Tolerant PIR over Erasure Coded Storage.","No, the abstract is not related to AML because it focuses on private information retrieval techniques to enhance security and fault-tolerance against malicious servers, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2024_235,More is Merrier: Relax the Non-Collusion Assumption in Multi-Server PIR.,"No, the abstract is not related to AML because it focuses on secure computation and collusion mitigation in privacy-preserving tasks, which are more aligned with cryptography and privacy rather than adversarial machine learning."
ieee_2024_236,Group Oblivious Message Retrieval.,"No, the given abstract is related to privacy-preserving communication and does not address any concepts related to adversarial machine learning or the manipulation of machine learning models."
ieee_2024_237,PolySphinx: Extending the Sphinx Mix Format With Better Multicast Support.,"No, the abstract is not related to AML, as it focuses on improving the efficiency of mix networks for anonymous communication rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2024_238,Where Are the Red Lines? Towards Ethical Server-Side Scans in Security and Privacy Research.,"No, the abstract is not related to AML as it focuses on understanding the boundaries and ethical considerations of server-side scanning on the web, rather than discussing any adversarial attacks or manipulation of machine learning systems."
ieee_2024_239,Cerberus: Enabling Efficient and Effective In-Network Monitoring on Programmable Switches.,"No. This abstract is focused on improving network monitoring systems for handling network security issues like DDoS attacks using programmable switches, and it does not discuss any adversarial attacks or defenses related to machine learning models."
ieee_2024_240,Pryde: A Modular Generalizable Workflow for Uncovering Evasion Attacks Against Stateful Firewall Deployments.,"Yes, the abstract is related to AML because it discusses generating evasion attacks against stateful firewalls, which involves learning how to manipulate inputs to bypass security measures, a key aspect of AML."
ieee_2024_241,TuDoor Attack: Systematically Exploring and Exploiting Logic Vulnerabilities in DNS Response Pre-processing with Malformed Packets.,"No. The abstract focuses on discovering and exploiting logic vulnerabilities in DNS systems, which is more related to network security rather than adversarial machine learning."
ieee_2024_242,DNSBomb: A New Practical-and-Powerful Pulsing DoS Attack Exploiting DNS Queries-and-Responses.,"No, the abstract is not related to AML because it focuses on a Denial of Service (DoS) attack technique involving DNS systems, which falls under the category of network security rather than adversarial attacks on machine learning models."
ieee_2024_243,TCP Spoofing: Reliable Payload Transmission Past the Spoofed TCP Handshake.,"No, the given abstract is not related to AML because it focuses on TCP spoofing, which involves network-level attacks on TCP/IP protocols, rather than attacks or defenses related to machine learning models."
ieee_2024_244,Practical Attacks Against DNS Reputation Systems.,"Yes, the abstract is related to AML because it involves evaluating and executing adversarial attacks against DNS reputation systems, which are machine learning-based, to test their robustness and demonstrate their vulnerability to manipulation."
ieee_2024_245,Leveraging Prefix Structure to Detect Volumetric DDoS Attack Signatures with Programmable Switches.,"No, the abstract is not related to AML because it focuses on developing a system for detecting DDoS attack signatures using programmable switches and machine learning, without discussing malicious manipulation or vulnerabilities of machine learning models."
ieee_2024_246,Automated Synthesis of Effect Graph Policies for Microservice-Aware Stateful System Call Specialization.,"No, the abstract is not related to AML as it focuses on a framework for generating security policies for containerized programs and not on adversarial attacks or defenses in machine learning systems."
ieee_2024_247,SoK: A Comprehensive Analysis and Evaluation of Docker Container Attack and Defense Mechanisms.,"No. The abstract is focused on container security and the evaluation of defense mechanisms against vulnerabilities and attacks on containers, rather than adversarial attacks on machine learning systems."
ieee_2024_248,Tabbed Out: Subverting the Android Custom Tab Security Model.,"No, the abstract is not related to AML. It focuses on the security evaluation of the Custom Tab component in mobile applications, addressing vulnerabilities in web session integrity and information leakage, rather than machine learning models and adversarial attacks."
ieee_2024_249,P4Control: Line-Rate Cross-Host Attack Prevention via In-Network Information Flow Control Enabled by Programmable Switches and eBPF.,"No. The abstract describes a network defense system focused on tracking and preventing cross-host attacks in real-time, which is related to network security rather than adversarial machine learning."
ieee_2024_250,To Boldly Go Where No Fuzzer Has Gone Before: Finding Bugs in Linux' Wireless Stacks through VirtIO Devices.,"No, the given abstract is not related to Adversarial Machine Learning, as it discusses fuzz testing for detecting security vulnerabilities in Linux kernel interfaces, rather than attacks or defenses associated with machine learning systems."
ieee_2024_251,Saturn: Host-Gadget Synergistic USB Driver Fuzzing.,"No, the abstract is not related to AML because it focuses on a USB driver fuzzing approach for vulnerability detection in operating systems, which pertains to software security rather than adversarial machine learning attacks or defenses."
ieee_2024_252,SyzGen++: Dependency Inference for Augmenting Kernel Driver Fuzzing.,"No, the abstract is not related to AML because it focuses on kernel fuzzing and vulnerability discovery in operating system kernels, not on manipulating or extracting information from machine learning systems."
ieee_2024_253,Side-Channel-Assisted Reverse-Engineering of Encrypted DNN Hardware Accelerator IP and Attack Surface Exploration.,"Yes, the abstract is related to Adversarial Machine Learning (AML) as it discusses reverse-engineering methods to reveal and exploit vulnerabilities in FPGA-based DNN accelerators, posing threats to their confidentiality and integrity."
ieee_2024_254,SoK: Privacy-Preserving Data Synthesis.,"No, the abstract is not related to AML because it focuses on privacy-preserving data synthesis and data privacy, rather than adversarial attacks or defenses aimed at machine learning systems."
ieee_2024_255,Preserving Node-level Privacy in Graph Neural Networks.,"Yes. The abstract discusses a protocol that addresses privacy concerns in Graph Neural Networks, including combating membership inference attacks, which is a type of adversarial attack relevant to Adversarial Machine Learning (AML)."
ieee_2024_256,From Principle to Practice: Vertical Data Minimization for Machine Learning.,"No, the abstract is not related to AML because it focuses on data minimization and privacy-preserving techniques in machine learning, rather than discussing adversarial attacks or defenses against them."
ieee_2024_257,"BOLT: Privacy-Preserving, Accurate and Efficient Inference for Transformers.","No. The abstract is focused on privacy-preserving inference and optimizing the efficiency of transformer models using secure multiparty computation, rather than addressing adversarial attacks or defenses related to machine learning."
ieee_2024_258,SHERPA: Explainable Robust Algorithms for Privacy-Preserved Federated Learning in Future Networks to Defend Against Data Poisoning Attacks.,"Yes, the abstract is related to AML as it discusses defending against data poisoning attacks in federated learning, a type of adversarial machine learning attack, through a novel algorithm utilizing explainable AI techniques."
ieee_2024_259,Please Tell Me More: Privacy Impact of Explainability through the Lens of Membership Inference Attack.,"Yes. The abstract describes a study of privacy risks in explainable machine learning through a membership inference attack, which is a type of adversarial attack focused on extracting information about the training data of a machine learning model."
ieee_2024_260,From Individual Computation to Allied Optimization: Remodeling Privacy-Preserving Neural Inference with Function Input Tuning.,"No. The abstract focuses on improving the efficiency of privacy-preserving machine learning services using cryptographic techniques, without mentioning adversarial attacks or defenses."
ieee_2024_261,Protecting Label Distribution in Cross-Silo Federated Learning.,No. This abstract focuses on privacy-preserving techniques in federated learning and does not discuss any adversarial attacks or defenses specifically related to adversarial machine learning.
