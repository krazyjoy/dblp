uuid,title,response
ieee_2023_0,"44th IEEE Symposium on Security and Privacy, SP 2023, San Francisco, CA, USA, May 21-25, 2023.",No. The abstract provided is not related to Adversarial Machine Learning as it lacks any content or context to determine its relevance.
ieee_2023_1,Space Odyssey: An Experimental Software Security Analysis of Satellites.,"No. The term ""nan"" does not provide any information about adversarial machine learning or related concepts."
ieee_2023_2,"Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models.","Yes, the abstract is related to AML because it discusses techniques to defend against backdoor attacks on deep neural networks, which involve adversarial manipulations during training."
ieee_2023_3,Scaphy: Detecting Modern ICS Attacks by Correlating Behaviors in SCADA and PHYsical.,"Yes, the abstract is related to AML as it discusses detecting ICS attacks by distinguishing between legitimate and malicious SCADA activities, which involves identifying and countering adversarial behavior in an industrial control system."
ieee_2023_4,Shedding Light on Inconsistencies in Grid Cybersecurity: Disconnects and Recommendations.,"Yes. The abstract discusses adversarial attacks such as False Data Injection Attacks, which are a form of adversarial machine learning threat aimed at altering the behavior of power grids through manipulation."
ieee_2023_5,Red Team vs. Blue Team: A Real-World Hardware Trojan Detection Case Study Across Four Modern CMOS Technology Generations.,"No, this abstract is not related to AML because it focuses on detecting hardware Trojans in integrated circuits, which pertains to hardware security rather than adversarial attacks or defenses specific to machine learning systems."
ieee_2023_6,SoK: Distributed Randomness Beacons.,"No. The abstract focuses on distributed randomness beacons and their cryptographic protocols, which are not related to adversarial machine learning or attacks on machine learning models."
ieee_2023_7,"WeRLman: To Tackle Whale (Transactions), Go Deep (RL).","No, the given abstract is not related to AML as it focuses on analyzing blockchain security and miner incentives using reinforcement learning rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2023_8,Three Birds with One Stone: Efficient Partitioning Attacks on Interdependent Cryptocurrency Networks.,"No. The abstract discusses the security risks and potential for spatial partitioning attacks in cryptocurrency networks due to network topology vulnerabilities, but it does not focus on adversarial machine learning or techniques to manipulate machine learning systems."
ieee_2023_9,Bitcoin-Enhanced Proof-of-Stake Security: Possibilities and Impossibilities.,"No, the abstract is not related to AML because it focuses on security improvements in blockchain technology, particularly Proof-of-Stake chains, without discussing adversarial attacks or defenses against machine learning systems."
ieee_2023_10,MEGA: Malleable Encryption Goes Awry.,"No, the given abstract is not related to AML. It focuses on analyzing cryptographic vulnerabilities in MEGA's security architecture and does not involve adversarial attacks on machine learning systems."
ieee_2023_11,Practically-exploitable Cryptographic Vulnerabilities in Matrix.,No. The abstract is focused on identifying cryptographic vulnerabilities in communication protocols rather than discussing attacks or defenses specifically related to machine learning systems.
ieee_2023_12,DBREACH: Stealing from Databases Using Compression Side Channels.,"No, the abstract describes compression side-channel attacks on database storage engines, which focus on extracting plaintext from encrypted databases rather than manipulating or analyzing machine learning models."
ieee_2023_13,Weak Fiat-Shamir Attacks on Modern Proof Systems.,"No. The abstract discusses vulnerabilities in the incorrect application of the Fiat-Shamir transformation within proof systems used in cryptocurrencies, but it doesn't relate to adversarial attacks or defenses in machine learning systems."
ieee_2023_14,"Attitudes towards Client-Side Scanning for CSAM, Terrorism, Drug Trafficking, Drug Use and Tax Evasion in Germany.","No. The abstract is not related to AML as it discusses privacy-preserving technology and public opinion on Client-Side Scanning for law enforcement purposes, without mentioning adversarial attacks or machine learning systems."
ieee_2023_15,Deep perceptual hashing algorithms with hidden dual purpose: when client-side scanning does facial recognition.,"Yes. The abstract is related to AML as it discusses an adversarial use of perceptual hashing algorithms to manipulate a client-side scanning system for dual purposes, including surveillance, which aligns with the concept of adversarial attacks in machine learning."
ieee_2023_16,Public Verification for Private Hash Matching.,"No. The abstract discusses cryptographic methods for public verification of private hash matching systems for detecting child sexual abuse material, which does not involve adversarial attacks or defenses related to machine learning systems."
ieee_2023_17,Is Cryptographic Deniability Sufficientƒ Non-Expert Perceptions of Deniability in Secure Messaging.,"No. The abstract focuses on secure messaging protocols, deniability, and public perception of evidence in encrypted communications, which are related to cryptography and security rather than adversarial machine learning."
ieee_2023_18,On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning.,No. The abstract focuses on detecting and understanding the evolution of hateful memes using multimodal contrastive learning rather than discussing adversarial attacks or defenses in machine learning.
ieee_2023_19,Lambretta: Learning to Rank for Twitter Soft Moderation.,"No, the abstract is not related to AML because it focuses on a system for moderating false information on social media using Learning To Rank, rather than dealing with adversarial attacks or defenses in machine learning systems."
ieee_2023_20,SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning.,"Yes, the abstract is related to AML because it discusses inference attacks, a type of adversarial attack on machine learning models, and proposes a framework for analyzing these privacy inference risks."
ieee_2023_21,Analyzing Leakage of Personally Identifiable Information in Language Models.,"Yes, the abstract is related to AML because it discusses the risk of language models leaking personally identifiable information through various attacks and evaluates defenses like differential privacy to mitigate such vulnerabilities."
ieee_2023_22,Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective.,"Yes, the abstract is related to AML as it discusses membership inference attacks, which are a form of adversarial attacks on the privacy of machine learning models."
ieee_2023_23,D-DAE: Defense-Penetrating Model Extraction Attacks.,"Yes, the abstract is related to AML as it discusses developing a model extraction attack framework to penetrate defenses, which is a key aspect of adversarial machine learning involving attacks on machine learning systems."
ieee_2023_24,SNAP: Efficient Extraction of Private Properties with Poisoning.,"Yes, the given abstract is related to AML as it discusses property inference attacks, which are a type of adversarial attack targeting the privacy of machine learning models by extracting properties of the training dataset."
ieee_2023_25,On the (In)security of Peer-to-Peer Decentralized Machine Learning.,"Yes. The abstract is related to AML as it discusses novel attacks on a decentralized machine learning framework, exposing vulnerabilities that can be exploited for privacy attacks, such as gradient inversion and control over local models."
ieee_2023_26,Vectorized Batch Private Information Retrieval.,"No, the abstract is not related to AML because it focuses on improving the efficiency of private information retrieval protocols, which is more related to cryptographic communication techniques rather than adversarial machine learning or attacks on ML models."
ieee_2023_27,RoFL: Robustness of Secure Federated Learning.,"Yes. The abstract is related to AML because it addresses vulnerabilities in Federated Learning through targeted attacks and proposes methods to mitigate them, indicating a focus on understanding and countering adversarial threats in machine learning systems."
ieee_2023_28,Flamingo: Multi-Round Single-Server Secure Aggregation with Applications to Private Federated Learning.,"No. The abstract discusses secure data aggregation in federated learning, focusing on privacy and efficiency, rather than adversarial attacks or defenses in machine learning systems."
ieee_2023_29,SoK: Cryptographic Neural-Network Computation.,"No. While the abstract discusses privacy-preserving neural networks and cryptographic techniques, it does not focus on adversarial attacks or defenses within machine learning systems."
ieee_2023_30,FLUTE: Fast and Secure Lookup Table Evaluations.,"No. The abstract focuses on secure multi-party computation and the improvement of LUT evaluation in cryptographic contexts, without any mention of adversarial attacks or defenses related to machine learning systems."
ieee_2023_31,Bicoptor: Two-round Secure Three-party Non-linear Computation without Preprocessing for Privacy-preserving Machine Learning.,"No. The abstract focuses on improving the efficiency of privacy-preserving machine learning (PPML) through secure multiparty computation protocols, rather than discussing adversarial attacks or defenses related to machine learning models."
ieee_2023_32,Investigating the Password Policy Practices of Website Administrators.,"No. The abstract focuses on understanding and improving password policies for online authentication, which is a topic related to security practices but not directly related to adversarial machine learning techniques or defenses."
ieee_2023_33,"""In Eighty Percent of the Cases, I Select the Password for Them"": Security and Privacy Challenges, Advice, and Opportunities at Cybercafes in Kenya.","No, the abstract is not related to AML because it focuses on security and privacy challenges in cybercafes, not on adversarial attacks or defenses in machine learning systems."
ieee_2023_34,Perceptions of Distributed Ledger Technology Key Management - An Interview Study with Finance Professionals.,No. The abstract is related to key management in distributed ledger technology for financial institutions and does not discuss adversarial attacks or manipulations related to machine learning models.
ieee_2023_35,Towards a Rigorous Statistical Analysis of Empirical Password Datasets.,"No. The abstract focuses on password security and the characterization of an attacker's guessing curve, which is related to cryptography rather than adversarial machine learning."
ieee_2023_36,Confident Monte Carlo: Rigorous Analysis of Guessing Curves for Probabilistic Password Models.,"No. The abstract focuses on password security and estimating guessing numbers for passwords, rather than discussing adversarial attacks or defenses related to machine learning systems."
ieee_2023_37,Not Yet Another Digital ID: Privacy-Preserving Humanitarian Aid Distribution.,"No. The abstract is focused on developing a digital aid-distribution system with privacy and security features, but it does not involve any aspects of adversarial machine learning or manipulating ML models."
ieee_2023_38,Disguising Attacks with Explanation-Aware Backdoors.,"Yes, the abstract is related to AML because it describes methods to disguise adversarial operations and manipulate explainability in machine learning models, which aligns with adversarial attacks and obfuscation strategies in AML."
ieee_2023_39,AI-Guardian: Defeating Adversarial Attacks using Backdoors.,Yes. The abstract is related to AML as it discusses the vulnerability of deep neural networks to adversarial attacks and introduces a method called AI-Guardian to defeat such attacks while maintaining the performance of the original tasks.
ieee_2023_40,Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers.,"Yes. The abstract is related to AML as it discusses backdoor attacks on Android malware classifiers, focusing on improving stealthiness and exploring defenses, which falls under the category of adversarial attacks in machine learning."
ieee_2023_41,BayBFed: Bayesian Backdoor Defense for Federated Learning.,"Yes. The abstract is related to AML as it addresses poisoning attacks, specifically backdoor attacks, in federated learning and proposes a defense mechanism to detect and eliminate malicious updates."
ieee_2023_42,Redeem Myself: Purifying Backdoors in Deep Learning Models using Self Attention Distillation.,"Yes. The abstract discusses a defense framework to counter backdoor attacks on deep neural networks, which are a type of adversarial attack in machine learning."
ieee_2023_43,Threshold BBS+ Signatures for Distributed Anonymous Credential Issuance.,"No. The abstract is focused on securing multiparty signing protocols for cryptographic schemes, which involves enhancing privacy and efficiency in cryptographic signature schemes and does not involve machine learning or adversarial manipulation of ML systems."
ieee_2023_44,zk-creds: Flexible Anonymous Credentials from zkSNARKs and Existing Identity Infrastructure.,"No, the abstract is not related to AML because it focuses on the use of zero-knowledge proofs for anonymous credential verification rather than discussing attacks or defenses in the context of machine learning systems."
ieee_2023_45,Private Access Control for Function Secret Sharing.,"No, this abstract is not related to AML as it focuses on enhancing access control and efficiency in Function Secret Sharing (FSS) and its application in secure computation, rather than discussing adversarial machine learning or manipulating or defending against ML models."
ieee_2023_46,MPCAuth: Multi-factor Authentication for Distributed-trust Systems.,"No. The abstract focuses on authentication and security for distributed-trust systems using secure multi-party computation, rather than discussing adversarial attacks or defenses in the context of machine learning."
ieee_2023_47,Silph: A Framework for Scalable and Accurate Generation of Hybrid MPC Protocols.,"No, the abstract is not related to AML because it focuses on improving the efficiency of secure multiparty computation rather than addressing adversarial machine learning attacks or defenses."
ieee_2023_48,SoK: Anti-Facial Recognition Technology.,"No. The abstract focuses on anti-facial recognition tools and the broader design space and challenges of these systems, without specifically addressing adversarial attacks or manipulations on machine learning models."
ieee_2023_49,Spoofing Real-world Face Authentication Systems through Optical Synthesis.,"Yes, the abstract is related to AML as it discusses a new type of spoofing attack designed to deceive multimodal face authentication systems by forging and combining multiple modalities, which aligns with the concept of adversarial attacks in machine learning."
ieee_2023_50,ImU: Physical Impersonating Attack for Face Recognition System with Natural Style Changes.,"Yes, the abstract is related to AML because it describes an attack on face recognition systems using physically realizable style changes, which aligns with adversarial machine learning concepts focused on manipulating inputs to achieve misclassification."
ieee_2023_51,DepthFake: Spoofing 3D Face Authentication with a 2D Photo.,"Yes, this abstract is related to AML because it involves creating an attack (DepthFake) to manipulate machine learning-based 3D face authentication systems using adversarial inputs."
ieee_2023_52,Understanding the (In)Security of Cross-side Face Verification Systems in Mobile Apps: A System Perspective.,"Yes. The abstract discusses the security of Face Verification Systems against adversarial attacks from both a machine learning and system perspective, which aligns with the adversarial machine learning focus on evaluating and securing the robustness of ML models and systems against malicious inputs."
ieee_2023_53,Breaking Security-Critical Voice Authentication.,"Yes, the abstract is related to AML because it discusses creating adversarial attacks on voice authentication systems, specifically targeting and bypassing spoofing countermeasures."
ieee_2023_54,SoK: A Critical Evaluation of Efficient Website Fingerprinting Defenses.,"Yes, the abstract is related to AML because it discusses the evaluation of defense strategies against adversarial attacks on encrypted communication through Tor, using deep learning-based methods."
ieee_2023_55,Fashion Faux Pas: Implicit Stylistic Fingerprints for Bypassing Browsers' Anti-Fingerprinting Defenses.,"No, the abstract is not related to AML. It focuses on browser fingerprinting and anti-fingerprinting countermeasures, which are more associated with privacy and security rather than adversarial attacks or defenses in machine learning systems."
ieee_2023_56,Robust Multi-tab Website Fingerprinting Attacks in the Wild.,"Yes, the given abstract is related to AML because it discusses a novel method for executing a website fingerprinting attack, which can be considered an adversarial attack aimed at identifying user activity despite protective measures like encryption and use of the Tor network."
ieee_2023_57,Only Pay for What You Leak: Leveraging Sandboxes for a Minimally Invasive Browser Fingerprinting Defense.,"No, the abstract is not related to AML because it focuses on browser fingerprinting defenses and privacy in web environments rather than adversarial attacks or defenses on machine learning systems."
ieee_2023_58,"It's (DOM) Clobbering Time: Attack Techniques, Prevalence, and Defenses.","No, the abstract is not related to AML because it focuses on a security vulnerability known as ""DOM Clobbering"" which involves HTML and JavaScript interactions on web platforms, rather than adversarial attacks or defenses specifically targeting machine learning systems."
ieee_2023_59,Scaling JavaScript Abstract Interpretation to Detect and Exploit Node.js Taint-style Vulnerability.,"No, the abstract is unrelated to AML because it focuses on detecting software vulnerabilities in JavaScript packages through abstract interpretation rather than discussing adversarial attacks or defenses related to machine learning systems."
ieee_2023_60,Sound Verification of Security Protocols: From Design to Interoperable Implementations.,No. The abstract focuses on verifying security protocols and I/O specifications rather than addressing or manipulating machine learning systems.
ieee_2023_61,Typing High-Speed Cryptography against Spectre v1.,"No, the abstract is not related to AML. It focuses on cryptographic software and protections against Spectre and Meltdown attacks, which are hardware vulnerabilities, rather than adversarial attacks on machine learning models."
ieee_2023_62,Less is more: refinement proofs for probabilistic proofs.,"No, the abstract is not related to AML because it focuses on improving the efficiency and scalability of translating computations into arithmetic constraints for probabilistic proof systems, which does not pertain to manipulating or attacking machine learning models."
ieee_2023_63,Owl: Compositional Verification of Security Protocols via an Information-Flow Type System.,"No. The abstract is focused on verifying cryptographic protocols using a framework named Owl, which does not pertain to adversarial attacks or defenses in the context of machine learning."
ieee_2023_64,AUC: Accountable Universal Composability.,No. The abstract focuses on developing a framework for accountability in cryptographic models and does not involve adversarial attacks or defenses in machine learning systems.
ieee_2023_65,High-Order Masking of Lattice Signatures in Quasilinear Time.,"No, the abstract is not related to AML as it focuses on developing a side-channel resistant lattice-based signature scheme for post-quantum cryptography, without any mention of adversarial machine learning attacks or defenses."
ieee_2023_66,Practical Timing Side-Channel Attacks on Memory Compression.,"No, the abstract is not related to Adversarial Machine Learning. It focuses on exploiting a timing side channel in compression algorithms, which is more about side-channel attacks and not specifically about attacks or defenses involving machine learning models."
ieee_2023_67,TEEzz: Fuzzing Trusted Applications on COTS Android Devices.,"No. The abstract discusses fuzzing techniques for testing trusted execution environments (TEEs) on smartphones, which is focused on security testing rather than adversarial machine learning."
ieee_2023_68,"Half&Half: Demystifying Intel's Directional Branch Predictors for Fast, Secure Partitioned Execution.","No, the abstract is not related to AML because it addresses defenses against branch-based side-channel attacks, focusing on hardware and software isolation techniques rather than adversarial manipulation or attacks on machine learning models."
ieee_2023_69,"Half&Half: Demystifying Intel's Directional Branch Predictors for Fast, Secure Partitioned Execution.","No, the abstract is not related to AML because it focuses on a software defense against branch-based side-channel attacks, which are a type of hardware security concern rather than an attack on machine learning models."
ieee_2023_70,Improving Developers' Understanding of Regex Denial of Service Tools through Anti-Patterns and Fix Strategies.,"No. The abstract focuses on improving tools for detecting and fixing vulnerabilities in regular expressions specifically against ReDoS attacks, which is not directly related to adversarial machine learning."
ieee_2023_71,Practical Program Modularization with Type-Based Dependence Analysis.,"No, the abstract is not related to AML as it discusses program modularization and type-based dependence analysis for improving program security, which does not involve adversarial attacks or defenses in the context of machine learning models."
ieee_2023_72,WarpAttack: Bypassing CFI through Compiler-Introduced Double-Fetches.,"No, the abstract is not related to AML because it focuses on code-reuse attacks and compiler-related vulnerabilities rather than adversarial attacks or defenses specific to machine learning systems."
ieee_2023_73,SoK: Certified Robustness for Deep Neural Networks.,"Yes. The abstract is related to AML as it discusses adversarial attacks on deep neural networks and explores various defense strategies, particularly focusing on certifiably robust approaches against these attacks."
ieee_2023_74,RAB: Provable Robustness Against Backdoor Attacks.,"Yes, the abstract is related to AML as it discusses certifying and improving the robustness of machine learning models against adversarial attacks, specifically evasion and backdoor attacks."
ieee_2023_75,ObjectSeeker: Certifiably Robust Object Detection against Patch Hiding Attacks via Patch-agnostic Masking.,"Yes, the abstract is related to AML because it discusses a defense mechanism (ObjectSeeker) against adversarial patch hiding attacks on object detectors, which is a form of adversarial machine learning."
ieee_2023_76,PublicCheck: Public Integrity Verification for Services of Run-time Deep Models.,"Yes. The abstract is related to AML as it addresses model integrity verification to combat dishonest service providers and model integrity attacks, indicating a focus on protecting deep models from adversarial manipulations."
ieee_2023_77,FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information.,"Yes. The abstract is related to AML because it addresses poisoning attacks in federated learning and proposes a method to recover a global model affected by such attacks, which is a key aspect of adversarial machine learning."
ieee_2023_78,On The Empirical Effectiveness of Unrealistic Adversarial Hardening Against Realistic Adversarial Attacks.,Yes. The abstract is related to AML as it focuses on security attacks and defenses of machine learning systems by studying adversarial robustness against realistic and unrealistic adversarial attacks.
ieee_2023_79,Rethinking Searchable Symmetric Encryption.,"No, the abstract is not related to AML because it focuses on symmetric searchable encryption (SSE) and inference attacks within cryptographic systems, not on adversarial attacks against machine learning models."
ieee_2023_80,Private Collaborative Data Cleaning via Non-Equi PSI.,"No, the abstract is focused on privacy-preserving collaborative data cleaning using cryptographic protocols, which does not involve manipulating machine learning systems or exploring their vulnerabilities as in adversarial machine learning."
ieee_2023_81,Private Collaborative Data Cleaning via Non-Equi PSI.,"No. The abstract focuses on privacy-preserving data cleaning and private set intersection, which relates to secure data reconciliation rather than adversarial machine learning or manipulating ML model inputs."
ieee_2023_82,SPHINCS+C: Compressing SPHINCS+ With (Almost) No Cost.,"No, the abstract is not related to AML as it focuses on optimizing the SPHINCS+ digital signature scheme, which pertains to post-quantum cryptography, not adversarial machine learning."
ieee_2023_83,Threshold Signatures in the Multiverse.,"No, the given abstract is not related to AML as it focuses on developing a multiverse threshold signature scheme to improve efficiency in cryptographic systems, which does not involve adversarial attacks or defenses on machine learning models."
ieee_2023_84,"FIDO2, CTAP 2.1, and WebAuthn 2: Provable Security and Post-Quantum Instantiation.",No. The abstract is focused on the security analysis and improvements of the FIDO2 authentication protocol and does not pertain to adversarial machine learning attacks or defenses concerning machine learning systems.
ieee_2023_85,Token meets Wallet: Formalizing Privacy and Revocation for FIDO2.,"No, the abstract is not related to AML as it focuses on the security and privacy analysis of the FIDO2 authentication standard rather than on machine learning systems or adversarial attacks."
ieee_2023_86,SoK: Taxonomy of Attacks on Open-Source Software Supply Chains.,"No. The abstract is related to security in open-source software supply chains and does not mention manipulating or defending machine learning models, which are key aspects of adversarial machine learning."
ieee_2023_87,It's like flossing your teeth: On the Importance and Challenges of Reproducible Builds for Software Supply Chain Security.,"No. The abstract is focused on enhancing security in software build systems through Reproducible Builds, which is a broader software security topic and does not specifically address manipulating machine learning models or datasets, which is central to adversarial machine learning."
ieee_2023_88,"""Always Contribute Back"": A Qualitative Study on Security Challenges of the Open Source Supply Chain.","No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on security challenges and practices in using open source components rather than malicious attacks or defenses in machine learning systems."
ieee_2023_89,Continuous Intrusion: Characterizing the Security of Continuous Integration Services.,"No. The abstract focuses on security vulnerabilities and potential attacks within Continuous Integration workflows, not specifically on adversarial machine learning techniques or attacks against machine learning models."
ieee_2023_90,Investigating Package Related Security Threats in Software Registries.,"No. The abstract is focused on identifying and analyzing security vulnerabilities within software registry ecosystems, which is more related to software security rather than adversarial machine learning."
ieee_2023_91,ShadowNet: A Secure and Efficient On-device Model Inference System for Convolutional Neural Networks.,"No, the given abstract is not related to AML. It focuses on securing model privacy and inference on untrusted devices using Trusted Execution Environment (TEE), rather than addressing malicious attacks or defenses in the context of adversarial machine learning."
ieee_2023_92,Deepfake Text Detection: Limitations and Opportunities.,"Yes, the abstract is related to AML as it discusses adversarial attacks on defenses designed to detect machine-generated text, which involves manipulating inputs to assess the robustness of these defenses."
ieee_2023_93,StyleFool: Fooling Video Classification Systems via Style Transfer.,"Yes. The abstract is related to AML as it discusses a novel adversarial attack specifically designed to deceive video classification systems by employing style transfer techniques, which is a classic example of adversarial attacks in machine learning."
ieee_2023_94,"GeeSolver: A Generic, Efficient, and Effortless Solver with Self-Supervised Learning for Breaking Text Captchas.","Yes, the abstract is related to AML because it discusses a solver that breaks text-based captchas, which is a form of evasion attack in adversarial machine learning aimed at bypassing security mechanisms."
ieee_2023_95,TrojanModel: A Practical Trojan Attack against Automatic Speech Recognition Systems.,"Yes, the given abstract is related to AML because it discusses a Trojan attack on deep learning models, specifically targeting Automatic Speech Recognition systems, which involves maliciously altering the model's behavior."
ieee_2023_96,REGA: Scalable Rowhammer Mitigation with Refresh-Generating Activations.,"No. The abstract focuses on addressing the Rowhammer problem in DRAM, a hardware security issue, and does not involve adversarial attacks or defenses related to machine learning systems."
ieee_2023_97,CSI:Rowhammer - Cryptographic Security and Integrity against Rowhammer.,"No. The abstract discusses a hardware-software co-design approach for mitigating Rowhammer attacks using cryptographic techniques, which is a security issue but not specifically related to adversarial machine learning attacks or defenses."
ieee_2023_98,Jolt: Recovering TLS Signing Keys via Rowhammer Faults.,"No, this abstract is unrelated to AML as it focuses on cryptographic attacks targeting digital signature schemes and not on adversarial machine learning tactics like manipulating model inputs or outputs."
ieee_2023_99,Hide and Seek with Spectres: Efficient discovery of speculative information leaks with random testing.,"No. The abstract is focused on speculative execution vulnerabilities in CPUs and the detection of speculative leaks, which are related to hardware security rather than adversarial machine learning attacks on ML models."
ieee_2023_100,Spectre Declassified: Reading from the Right Place at the Wrong Time.,"No. The abstract is focused on speculative execution and information-flow security in programming languages, rather than machine learning or adversarial attacks on machine learning models."
ieee_2023_101,Volttack: Control IoT Devices by Manipulating Power Supply Voltage.,"No, the abstract is not related to AML. It focuses on a hardware vulnerability in IoT devices and describes attacks stemming from manipulating power supply modules, which do not involve adversarial manipulation of machine learning models."
ieee_2023_102,Inducing Wireless Chargers to Voice Out for Inaudible Command Attacks.,"Yes, the abstract is related to AML as it describes the use of malicious inaudible voice commands to manipulate machine learning systems, specifically speech recognition systems and voice assistants."
ieee_2023_103,mmSpoof: Resilient Spoofing of Automotive Millimeter-wave Radars using Reflect Array.,"No, the given abstract is not related to AML because it focuses on spoofing attacks on radar systems rather than manipulating machine learning models or their inputs."
ieee_2023_104,PLA-LiDAR: Physical Laser Attacks against LiDAR-based 3D Object Detection in Autonomous Vehicle.,"Yes, the abstract is related to AML as it explores physically injecting adversarial point clouds using lasers to fool LiDAR-based 3D object detection systems, a classic example of an evasion attack."
ieee_2023_105,mmEcho: A mmWave-based Acoustic Eavesdropping Method.,"No. The abstract is focused on acoustic eavesdropping using millimeter-wave radio signals to measure sound-induced vibrations, which is a surveillance technique rather than manipulating or influencing machine learning models."
ieee_2023_106,Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from Smartphone Cameras with Rolling Shutters and Movable Lenses.,"No, this abstract is not related to Adversarial Machine Learning, as it discusses a side channel attack involving acoustic eavesdropping through camera sensors rather than manipulating or defending against machine learning models."
ieee_2023_107,3DFed: Adaptive and Extensible Framework for Covert Backdoor Attack in Federated Learning.,"Yes, the abstract is related to AML as it discusses designing and executing evasion attacks on federated learning systems to bypass backdoor attack defenses."
ieee_2023_108,Scalable and Privacy-Preserving Federated Principal Component Analysis.,"No, the abstract is not related to AML because it focuses on enhancing data confidentiality in federated PCA using secure multiparty computation and homomorphic encryption, rather than addressing adversarial threats or defenses in machine learning systems."
ieee_2023_109,"Private, Efficient, and Accurate: Protecting Models Trained by Multi-party Learning with Differential Privacy.","No, the given abstract is not related to AML. It focuses on privacy-preserving machine learning using secure multi-party computation and differential privacy, rather than addressing adversarial attacks or defenses in machine learning systems."
ieee_2023_110,Spectral-DP: Differentially Private Deep Learning through Spectral Perturbation and Filtering.,"No, the given abstract is not related to AML. It focuses on improving differential privacy in deep learning models through Spectral-DP, which enhances utility without specifically addressing adversarial attacks or manipulations of the model."
ieee_2023_111,ELSA: Secure Aggregation for Federated Learning with Malicious Actors.,"No, the abstract is not related to AML. It discusses a secure aggregation protocol for federated learning, focusing on efficiency and privacy but does not mention adversarial attacks or defenses specifically aimed at manipulating machine learning models."
ieee_2023_112,No One Drinks From the Firehose: How Organizations Filter and Prioritize Vulnerability Information.,"No, the abstract is not related to AML because it focuses on how organizations handle software vulnerability information and their coping mechanisms, rather than discussing adversarial attacks, defenses, or manipulating machine learning systems."
ieee_2023_113,Vulnerability Discovery for All: Experiences of Marginalization in Vulnerability Discovery.,"No. The abstract focuses on the social aspects and diversity challenges in the field of vulnerability discovery in software security, rather than on adversarial machine learning or its attacks and defenses."
ieee_2023_114,"""We are a startup to the core"": A qualitative interview study on the security and privacy development practices in Turkish software startups.","No. The abstract focuses on the security and privacy practices of software developers, not on adversarial machine learning or attacks on machine learning models."
ieee_2023_115,"""How technical do you get? I'm an English teacher"": Teaching and Learning Cybersecurity and AI Ethics in High School.","No, the abstract is not related to AML. It discusses the teaching of cybersecurity and AI ethics in high schools, rather than attacks on or defenses for machine learning systems."
ieee_2023_116,Skilled or Gullibleƒ Gender Stereotypes Related to Computer Security and Privacy.,No. The abstract is focused on studying gender stereotypes in computer security and privacy rather than on adversarial machine learning or attacks on ML systems.
ieee_2023_117,"Everybody's Got ML, Tell Me What Else You Have: Practitioners' Perception of ML-Based Security Tools and Explanations.","Yes. The abstract explores the perception of security practitioners on the use of ML tools in security operations and mentions robustness to adversarial attacks, which is directly related to adversarial machine learning."
ieee_2023_118,Precise Detection of Kernel Data Races with Probabilistic Lockset Analysis.,"No, the given abstract is not related to Adversarial Machine Learning (AML) as it focuses on race condition detection in kernel development for security, rather than on adversarial attacks or defenses in machine learning systems."
ieee_2023_119,SegFuzz: Segmentizing Thread Interleaving to Discover Kernel Concurrency Bugs through Fuzzing.,"No, the abstract is related to identifying kernel concurrency bugs through fuzzing, which does not involve machine learning models or adversarial attacks on them."
ieee_2023_120,AEM: Facilitating Cross-Version Exploitability Assessment of Linux Kernel Vulnerabilities.,"No. The abstract focuses on cross-version exploitability assessment and exploit migration for Linux kernels, which is more related to systems security and exploit generation rather than adversarial machine learning."
ieee_2023_121,AEM: Facilitating Cross-Version Exploitability Assessment of Linux Kernel Vulnerabilities.,"No, this abstract is not related to AML because it focuses on assessing and migrating exploits across Linux kernel versions rather than manipulating or defending against machine learning models."
ieee_2023_122,When Top-down Meets Bottom-up: Detecting and Exploiting Use-After-Cleanup Bugs in Linux Kernel.,No. The abstract focuses on detecting and exploiting Use-After-Cleanup (UAC) bugs in the Linux kernel for privilege escalation and does not involve manipulating or defending machine learning systems against adversarial attacks.
ieee_2023_123,RSFuzzer: Discovering Deep SMI Handler Vulnerabilities in UEFI Firmware with Hybrid Fuzzing.,"No, the abstract is not related to AML. It focuses on using hybrid fuzzing techniques to detect vulnerabilities in System Management Mode (SMM) of UEFI firmware, which is more aligned with firmware security rather than adversarial machine learning."
ieee_2023_124,A Theory to Instruct Differentially-Private Learning via Clipping Bias Reduction.,No. The abstract focuses on improving the utility and convergence of Differentially-Private Stochastic Gradient Descent (DP-SGD) in deep learning without mentioning adversarial attacks or defenses related to adversarial machine learning.
ieee_2023_125,Continual Observation under User-level Differential Privacy.,"No. The abstract is related to differential privacy mechanisms and their utility guarantees, which is more about privacy preservation techniques than adversarial machine learning."
ieee_2023_126,Locally Differentially Private Frequency Estimation Based on Convolution Framework.,"No. The abstract focuses on optimizing local differential privacy protocols for frequency estimation, which is related to privacy-preserving data collection and not directly related to adversarial machine learning attacks or defenses."
ieee_2023_127,Telepath: A Minecraft-based Covert Communication System.,"No. The abstract is not related to AML as it focuses on designing a covert communication system within online games to resist censorship, without involving machine learning models or adversarial attacks on them."
ieee_2023_128,"Discop: Provably Secure Steganography in Practice Based on ""Distribution Copies"".","No. The abstract is focused on steganography and provably secure information hiding using deep generative models, not on adversarial techniques or defenses related to manipulating or attacking machine learning systems."
ieee_2023_129,SQUIP: Exploiting the Scheduler Queue Contention Side Channel.,No. The abstract is focused on a side-channel attack targeting scheduler queues in CPUs and does not involve machine learning models or the adversarial manipulation of ML systems.
ieee_2023_130,Scatter and Split Securely: Defeating Cache Contention and Occupancy Attacks.,No. The abstract is related to security and cryptography in the context of cache design rather than adversarial machine learning.
ieee_2023_131,DevIOus: Device-Driven Side-Channel Attacks on the IOMMU.,"No, the given abstract is not related to AML because it focuses on a side-channel attack exploiting the IOTLB using DMA-capable devices, which is more relevant to hardware security and does not involve manipulating machine learning models or data."
ieee_2023_132,"DVFS Frequently Leaks Secrets: Hertzbleed Attacks Beyond SIKE, Cryptography, and CPU-Only Data.","No. The abstract discusses security vulnerabilities and attacks related to cryptographic systems and cross-origin pixel stealing, which does not involve adversarial manipulation or attacks on machine learning systems."
ieee_2023_133,A Security RISC: Microarchitectural Attacks on Hardware RISC-V CPUs.,"No, the abstract is not related to AML. The focus is on microarchitectural attacks on RISC-V CPUs and not on attacking or defending machine learning models."
ieee_2023_134,Examining Zero-Shot Vulnerability Repair with Large Language Models.,"No, the abstract is not related to AML because it discusses using LLMs for code vulnerability repair, focusing on correcting security flaws, not on adversarial attacks or defenses in machine learning systems."
ieee_2023_135,Examining Zero-Shot Vulnerability Repair with Large Language Models.,"No, the abstract is not related to Adversarial Machine Learning. It primarily focuses on using large language models for code completion and repair of cybersecurity vulnerabilities, without mention of adversarial attacks or defensive mechanisms against adversarial examples."
ieee_2023_136,Callee: Recovering Call Graphs for Binaries with Transfer and Contrastive Learning.,"No, the abstract is not related to AML because it focuses on using deep learning techniques to improve call graph accuracy in binary analysis, rather than discussing adversarial attacks or defenses in machine learning."
ieee_2023_137,XFL: Naming Functions in Binaries with Extreme Multi-label Learning.,"No. The abstract focuses on using machine learning to predict function names within binaries, which is related to reverse engineering and information retrieval, not adversarial machine learning or malicious manipulation of ML models."
ieee_2023_138,D-ARM: Disassembling ARM Binaries by Lightweight Superset Instruction Interpretation and Graph Modeling.,"No, the given abstract is not related to AML because it focuses on ARM binary disassembly techniques and challenges, which are more relevant to system security and binary analysis rather than adversarial machine learning."
ieee_2023_139,GraphSPD: Graph-Based Security Patch Detection with Enriched Code Semantics.,"No, the abstract is not related to AML. It focuses on detecting security patches in open-source software using graph neural networks, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2023_140,Effective ReDoS Detection by Principled Vulnerability Modeling and Exploit Generation.,"No. The abstract is related to detecting and mitigating Regular expression Denial-of-Service (ReDoS) attacks on regex engines, which is an algorithmic complexity attack rather than an adversarial machine learning attack."
ieee_2023_141,SoK: Decentralized Finance (DeFi) Attacks.,"No, the abstract is not related to Adversarial Machine Learning. It focuses on analyzing and addressing security incidents in the blockchain-based Decentralized Finance (DeFi) ecosystem, which involves areas like price oracle attacks and permissionless interactions, rather than adversarial attacks on machine learning models."
ieee_2023_142,BlindHub: Bitcoin-Compatible Privacy-Preserving Payment Channel Hubs Supporting Variable Amounts.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on privacy-preserving payment channel solutions for cryptocurrencies, which is more related to blockchain technology and cryptography than to machine learning and adversarial attacks."
ieee_2023_143,Optimistic Fast Confirmation While Tolerating Malicious Majority in Blockchains.,"No, the abstract is not related to AML. It focuses on improving blockchain technology's robustness and latency, rather than addressing machine learning attacks or defenses."
ieee_2023_144,Clockwork Finance: Automated Analysis of Economic Security in Smart Contracts.,"No, the abstract is not related to AML because it focuses on a framework for formal verification and economic security analysis of decentralized-finance smart contracts, without discussing manipulation or adversarial attacks on machine learning models."
ieee_2023_145,Tyr: Finding Consensus Failure Bugs in Blockchain System with Behaviour Divergent Model.,"No, the abstract is primarily focused on detecting consensus failure bugs in blockchain systems and does not discuss adversarial attacks or manipulations in machine learning models."
ieee_2023_146,Leaking Arbitrarily Many Secrets: Any-out-of-Many Proofs and Applications to RingCT Protocols.,"No, the abstract is not related to AML. It focuses on improving cryptographic protocols for enhancing privacy in cryptocurrencies, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2023_147,Could you clean up the Internet with a Pit of Tar? Investigating tarpit feasibility on Internet worms.,"No. The abstract is related to cybersecurity and network defense, focusing on using tarpits to contain botnets and malware spread, but it does not involve manipulating machine learning models or systems, which is central to adversarial machine learning (AML)."
ieee_2023_148,Beyond Phish: Toward Detecting Fraudulent e-Commerce Websites at Scale.,"No, the abstract is not related to AML because it focuses on detecting and mitigating fraudulent e-commerce websites rather than discussing adversarial attacks or defenses specifically related to manipulating or exploiting machine learning models."
ieee_2023_149,Limits of I/O Based Ransomware Detection: An Imitation Based Attack.,"Yes. The abstract is related to AML as it describes an attack (Animagus) that exploits the limitations of existing detection techniques by imitating benign behaviors to evade ransomware defenses, which aligns with adversarial evasion attacks in AML."
ieee_2023_150,From Grim Reality to Practical Solution: Malware Classification in Real-World Noise.,"Yes, the abstract is related to AML as it addresses the problem of noise in malware datasets (incorrect labeling), which can lead to inaccurate models, and proposes a solution aimed at minimizing such impact, an issue pertinent to constructing trustworthy ML systems."
ieee_2023_151,SoK: History is a Vast Early Warning System: Auditing the Provenance of System Intrusions.,No. The abstract focuses on system auditing and data provenance for enhancing operating system security and threat detection rather than discussing adversarial attacks or techniques in machine learning.
ieee_2023_152,Collaborative Ad Transparency: Promises and Limitations.,"No, the abstract is not related to AML because it focuses on inferring targeting parameters used by advertisers in ad platforms for transparency, rather than discussing attacks or defenses on machine learning systems."
ieee_2023_153,Toss a Fault to Your Witcher: Applying Grey-box Coverage-Guided Mutational Fuzzing to Detect SQL and Command Injection Vulnerabilities.,"No, the abstract is related to web application vulnerability discovery and is not focused on adversarial machine learning attacks or defenses against machine learning systems."
ieee_2023_154,UTopia: Automatic Generation of Fuzz Driver using Unit Tests.,"No, the given abstract is not related to AML because it discusses fuzz testing, a software testing technique for finding security bugs, rather than adversarial machine learning or machine learning systems in general."
ieee_2023_155,SelectFuzz: Efficient Directed Fuzzing with Selective Path Exploration.,"No. The abstract focuses on a directed fuzzing technique for software testing and vulnerability detection, which does not involve adversarial machine learning attacks or defenses."
ieee_2023_156,Finding Specification Blind Spots via Fuzz Testing.,"No, the abstract is not related to AML. It focuses on ensuring the completeness and correctness of program specifications through fuzzing-assisted testing, whereas AML is concerned with exploiting or defending against vulnerabilities in machine learning systems."
ieee_2023_157,ODDFuzz: Discovering Java Deserialization Vulnerabilities via Structure-Aware Directed Greybox Fuzzing.,"No, the abstract discusses Java deserialization vulnerabilities detection using static analysis and fuzzing techniques, which are related to software security, not adversarial machine learning."
ieee_2023_158,The Leaky Web: Automated Discovery of Cross-Site Information Leaks in Browsers and the Web.,"No, the given abstract is not related to AML because it focuses on detecting and addressing Cross-Site Leaks (XS-Leaks) in web browsers, which is more relevant to web security and privacy rather than adversarial attacks or defenses in machine learning."
ieee_2023_159,WebSpec: Towards Machine-Checked Analysis of Browser Security Mechanisms.,"No, the abstract is not related to AML as it focuses on developing a formal security framework for analyzing browser security mechanisms rather than discussing adversarial attacks or machine learning systems."
ieee_2023_160,Detection of Inconsistencies in Privacy Practices of Browser Extensions.,"No. The abstract is focused on detecting inconsistencies in privacy disclosures of browser extensions, which is related to privacy analysis rather than adversarial machine learning."
ieee_2023_161,TeSec: Accurate Server-side Attack Investigation for Web Applications.,"No. The abstract focuses on accurate attack investigation methods for web UIs, which pertains to security in web applications rather than adversarial machine learning attacks or defenses."
ieee_2023_162,RuleKeeper: GDPR-Aware Personal Data Compliance for Web Frameworks.,"No. The abstract focuses on GDPR compliance and data protection for web development frameworks, without discussing adversarial machine learning or related concepts like manipulating inputs or attacking ML systems."
ieee_2023_163,Characterizing Everyday Misuse of Smart Home Devices.,"No, the abstract is not related to Adversarial Machine Learning because it focuses on the misuse of IoT devices by non-technical users rather than adversarial attacks or defense mechanisms targeting machine learning systems."
ieee_2023_164,"""It's up to the Consumer to be Smart"": Understanding the Security and Privacy Attitudes of Smart Home Users on Reddit.","No, the abstract is not related to AML. It focuses on users' security and privacy attitudes towards smart home technologies rather than discussing attacks, defenses, or manipulations of machine learning systems."
ieee_2023_165,User Perceptions and Experiences with Smart Home Updates.,"No. The abstract focuses on users' perceptions and experiences with security and privacy updates for smart home devices, rather than discussing adversarial attacks or defenses on machine learning systems."
ieee_2023_166,Design and Evaluation of Inclusive Email Security Indicators for People with Visual Impairments.,"No. The abstract focuses on improving accessibility and effectiveness of phishing warnings for users with visual impairments, rather than discussing adversarial machine learning techniques or defenses against them."
ieee_2023_167,"When and Why Do People Want Ad Targeting Explanations? Evidence from a Four-Week, Mixed-Methods Field Study.","No. The abstract focuses on understanding user preferences for ad targeting explanations to enhance transparency in online behavioral advertising, rather than addressing adversarial attacks or defenses in machine learning systems."
ieee_2023_168,SecureCells: A Secure Compartmentalized Architecture.,"No. The abstract is focused on software compartmentalization to enhance security and performance, but it does not specifically address machine learning systems or adversarial machine learning attacks and defenses."
ieee_2023_169,WaVe: a verifiably secure WebAssembly sandboxing runtime.,"No, the given abstract is not related to AML because it focuses on verifying and maintaining secure runtime systems for WebAssembly, rather than discussing adversarial attacks or defenses related to machine learning systems."
ieee_2023_170,μSwitch: Fast Kernel Context Isolation with Implicit Context Switches.,"No, this abstract is not related to AML. It focuses on improving intra-process memory isolation techniques to enhance the security and performance of applications, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2023_171,Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture.,"No, the abstract is not related to AML as it focuses on control flow attacks and software vulnerabilities, and proposes a solution using instruction and data tagging, without involving malicious manipulation or testing of machine learning systems."
ieee_2023_172,EC: Embedded Systems Compartmentalization via Intra-Kernel Isolation.,"No, the abstract is not related to AML because it focuses on improving security through compartmentalization in embedded systems rather than discussing any kind of adversarial attacks or defenses in machine learning."
ieee_2023_173,Low-Cost Privilege Separation with Compile Time Compartmentalization for Embedded Systems.,"No, the abstract is not related to AML. It focuses on improving security in embedded systems through compartmentalization, but it does not address adversarial attacks or defenses in the context of machine learning."
ieee_2023_174,One Key to Rule Them All: Secure Group Pairing for Heterogeneous IoT Devices.,"No, the given abstract is not related to AML as it focuses on a secure group pairing system for IoT devices, which is more aligned with cryptographic key management and secure communication rather than adversarial machine learning."
ieee_2023_175,Optimistic Access Control for the Smart Home.,"No. The abstract focuses on privacy concerns and access control in smart homes, rather than discussing any machine learning models or adversarial attacks."
ieee_2023_176,Protected or Porous: A Comparative Analysis of Threat Detection Capability of IoT Safeguards.,"No. The abstract is not related to AML as it discusses evaluating the effectiveness of IoT safeguards against privacy and security threats, rather than examining adversarial attacks or defenses specific to machine learning systems."
ieee_2023_177,LazyTAP: On-Demand Data Minimization for Trigger-Action Applications.,"No, the abstract is not related to AML as it focuses on enhancing data minimization techniques for Trigger-Action Platforms and does not address adversarial attacks or defenses in machine learning systems."
ieee_2023_178,Blue's Clues: Practical Discovery of Non-Discoverable Bluetooth Devices.,No. The abstract discusses an attack on Bluetooth devices to extract their MAC identifiers and does not mention any machine learning systems or models being attacked or defended against.
ieee_2023_179,DeHiREC: Detecting Hidden Voice Recorders via ADC Electromagnetic Radiation.,"No, the abstract is not related to AML because it focuses on detecting hidden voice recorders via electromagnetic radiations and does not involve manipulating or defending machine learning models."
ieee_2023_180,IPvSeeYou: Exploiting Leaked Identifiers in IPv6 for Street-Level Geolocation.,"No, the abstract is not related to AML because it describes a privacy attack focused on geolocating residential IPv6 hosts rather than targeting or manipulating machine learning models."
ieee_2023_181,From 5G Sniffing to Harvesting Leakages of Privacy-Preserving Messengers.,"No, the given abstract is not related to AML. It describes a tool for sniffing 5G control channels and conducting privacy attacks on users, which concerns network security and privacy rather than adversarial machine learning attacks or defenses."
ieee_2023_182,Man-in-the-Middle Attacks without Rogue AP: When WPAs Meet ICMP Redirects.,"No, the abstract is not related to AML because it focuses on a network security vulnerability and attack on Wi-Fi networks rather than on manipulating machine learning models or systems."
ieee_2023_183,Mew: Enabling Large-Scale and Dynamic Link-Flooding Defenses on Programmable Switches.,"No, the abstract is not related to Adversarial Machine Learning (AML). It focuses on defending against Link-flooding attacks (LFAs) on network connections using programmable switches, which is more about network security rather than manipulating machine learning systems."
ieee_2023_184,PCSPOOF: Compromising the Safety of Time-Triggered Ethernet.,"No. The abstract describes an attack on mixed-criticality networks, specifically targeting Time-Triggered Ethernet (TTE), not machine learning systems."
ieee_2023_185,BLEDiff: Scalable and Property-Agnostic Noncompliance Checking for BLE Implementations.,"No, the abstract is not related to AML. It describes a framework for checking noncompliance in BLE protocol implementations using automata learning and differential testing, which focuses more on protocol analysis rather than adversarial machine learning attacks or defenses."
ieee_2023_186,ViDeZZo: Dependency-aware Virtual Device Fuzzing.,"No, the abstract is not related to Adversarial Machine Learning. It focuses on fuzzing virtual devices to discover vulnerabilities in virtual machines, not on manipulating or attacking machine learning models."
ieee_2023_187,DevFuzz: Automatic Device Model-Guided Device Driver Fuzzing.,"No, the abstract is not related to AML. It focuses on improving device driver testing using fuzzing techniques rather than addressing or defending against adversarial attacks on machine learning systems."
ieee_2023_188,"SyzDescribe: Principled, Automated, Static Generation of Syscall Descriptions for Kernel Drivers.","No, the given abstract is not related to AML because it focuses on generating syscall descriptions for fuzz testing operating system kernels, rather than discussing adversarial machine learning attacks or defences.
"
ieee_2023_189,QueryX: Symbolic Query on Decompiled Code for Finding Bugs in COTS Binaries.,"No, the abstract is not related to AML because it focuses on symbolic analysis for binary code to discover bugs rather than adversarial attacks or defenses against machine learning systems."
ieee_2023_190,Pyfet: Forensically Equivalent Transformation for Python Binary Decompilation.,"No, the abstract is not related to AML because it focuses on improving the decompilation process for Python binaries in forensic analysis, rather than discussing adversarial attacks or defenses in machine learning systems."
ieee_2023_191,Adaptive Risk-Limiting Comparison Audits.,"No. The abstract is related to risk-limiting audits for elections and does not involve adversarial machine learning, which deals with manipulating or securing machine learning models."
ieee_2023_192,Blue Is the New Black (Market): Privacy Leaks and Re-Victimization from Police-Auctioned Cellphones.,"No, while the abstract discusses privacy and data security related to cellphones sold at police auctions, it does not involve adversarial attacks or defenses on machine learning systems."
ieee_2023_193,No Privacy in the Electronics Repair Industry.,"No, the abstract is not related to AML as it focuses on privacy concerns and issues within the electronics repair industry rather than addressing attacks or defenses related to machine learning systems."
ieee_2023_194,How IoT Re-using Threatens Your Sensitive Data: Exploring the User-Data Disposal in Used IoT Devices.,"No, the abstract is not related to Adversarial Machine Learning. While it discusses security concerns around data disposal in IoT devices, it does not address adversarial attacks or defenses involving machine learning systems."
ieee_2023_195,Privacy Leakage via Unrestricted Motion-Position Sensors in the Age of Virtual Reality: A Study of Snooping Typed Input on Virtual Keyboards.,"No. While the abstract discusses security vulnerabilities and potential data privacy risks associated with VR systems, it does not specifically address adversarial attacks or manipulation against machine learning models, which are central to AML."
ieee_2023_196,Uncovering User Interactions on Smartphones via Contactless Wireless Charging Side Channels.,"No. The abstract describes a side-channel attack using wireless charging to infer user interactions, but it does not involve manipulating or attacking a machine learning model."
ieee_2023_197,MagBackdoor: Beware of Your Loudspeaker as A Backdoor For Magnetic Injection Attacks.,"No. The abstract describes a novel magnetic field attack targeting audio systems, which focuses on exploiting the hardware of voice-enabled devices rather than manipulating or adversarially attacking a machine learning model."
ieee_2023_198,Private Eye: On the Limits of Textual Screen Peeking via Eyeglass Reflections in Video Conferencing.,"No. The abstract primarily focuses on privacy concerns related to video conferencing and potential optical leakage from eyeglasses, rather than adversarial attacks or defenses in the context of machine learning systems."
ieee_2023_199,Low-effort VR Headset User Authentication Using Head-reverberated Sounds with Replay Resistance.,"No. The abstract focuses on a novel biometric authentication method for VR devices using skull-reverberated sounds, not on adversarial machine learning or related attacks and defenses."
