uuid,title,response
uss_2022_0,"31st USENIX Security Symposium, USENIX Security 2022, Boston, MA, USA, August 10-12, 2022.","No, because the abstract provides no information or content to assess its relevance to adversarial machine learning."
uss_2022_1,Under the Hood of DANE Mismanagement in SMTP.,"No, the given abstract is not related to AML. It discusses the DNS-based Authentication of Named Entities (DANE) protocol and its use in internet security, which is not inherently about machine learning or adversarial attacks on ML systems."
uss_2022_2,Seeing the Forest for the Trees: Understanding Security Hazards in the 3GPP Ecosystem through Intelligent Analysis on Change Requests.,"No. The abstract focuses on identifying vulnerabilities in 3GPP specifications and their management, without addressing machine learning models or adversarial attacks related to AML."
uss_2022_3,Exploring the Unchartered Space of Container Registry Typosquatting.,"No, the abstract is not related to AML. It focuses on typosquatting attacks in container registries, which involves exploiting similar naming rather than manipulating machine learning models or data."
uss_2022_4,Uninvited Guests: Analyzing the Identity and Behavior of Certificate Transparency Bots.,"No. The abstract discusses the use of Certificate Transparency logs by web bots to probe websites, which pertains to web security and privacy rather than adversarial attacks on machine learning models."
uss_2022_5,Playing for K(H)eaps: Understanding and Improving Linux Kernel Exploit Reliability.,"No. The abstract is related to kernel heap exploitability and assessment in Linux systems, not adversarial attacks or defenses in machine learning."
uss_2022_6,In-Kernel Control-Flow Integrity on Commodity OSes using ARM Pointer Authentication.,"No, the abstract is not related to AML. It focuses on control-flow integrity protection using hardware-based techniques in the kernel, rather than adversarial attacks or defenses in machine learning systems."
uss_2022_7,Midas: Systematic Kernel TOCTTOU Protection.,"No. The abstract is focused on addressing double-fetch bugs in operating system kernels, which is a security concern, but it does not specifically relate to adversarial attacks or defenses in the context of machine learning systems."
uss_2022_8,LinKRID: Vetting Imbalance Reference Counting in Linux kernel with Symbolic Execution.,"No. The abstract is focused on detecting incorrect usage of reference counters in the Linux kernel for memory management, not on adversarial attacks or defenses related to machine learning systems."
uss_2022_9,Mining Node.js Vulnerabilities via Object Dependence Graph and Query.,"No, the abstract is not related to AML as it focuses on detecting vulnerabilities in Node.js packages using program analysis and graph query-based approaches, which are more connected to software security rather than adversarial machine learning."
uss_2022_10,Mistrust Plugins You Must: A Large-Scale Study Of Malicious Plugins In WordPress Marketplaces.,"No, this abstract is not related to AML because it focuses on detecting and analyzing malicious CMS plugins, which is more related to cybersecurity and malware detection, rather than adversarial attacks or defenses in machine learning systems."
uss_2022_11,Web Cache Deception Escalates!,"No. The abstract focuses on Web Cache Deception (WCD), a security vulnerability in web caching mechanisms, rather than discussing attacks or defenses related to machine learning systems."
uss_2022_12,FUGIO: Automatic Exploit Generation for PHP Object Injection Vulnerabilities.,"No. The abstract is focused on PHP object injection vulnerabilities and automatic exploit generation, which is more related to software security and vulnerability exploitation rather than adversarial machine learning."
uss_2022_13,TLS-Anvil: Adapting Combinatorial Testing for TLS Libraries.,"No. The abstract discusses issues related to testing TLS protocol implementations, which is more about software security and testing rather than adversarial machine learning."
uss_2022_14,Open to a fault: On the passive compromise of TLS keys via transient errors.,"No, the abstract is related to cryptographic vulnerabilities and faults in digital signature implementations, not to adversarial attacks or defenses in machine learning systems."
uss_2022_15,Trust Dies in Darkness: Shedding Light on Samsung's TrustZone Keymaster Design.,"No. The abstract discusses the Trusted Execution Environment and cryptographic functions in ARM-based Android smartphones, which is more related to hardware security rather than adversarial machine learning."
uss_2022_16,"Breaking Bridgefy, again: Adopting libsignal is not enough.","No, the abstract is not related to AML. It focuses on the security vulnerabilities and updates of a messaging application, rather than any manipulation or attack on machine learning systems."
uss_2022_17,"""I feel invaded, annoyed, anxious and I may protect myself"": Individuals' Feelings about Online Tracking and their Protective Behaviour across Gender and Country.","No. The abstract focuses on users' feelings and behaviors towards online tracking, which is unrelated to adversarial machine learning or specific attacks on machine learning models."
uss_2022_18,"""Like Lesbians Walking the Perimeter"": Experiences of U.S. LGBTQ+ Folks With Online Security, Safety, and Privacy Advice.","No, the given abstract is not related to AML. It focuses on analyzing digital security, safety, and privacy advice for the LGBTQ+ community rather than on adversarial attacks or defenses concerning machine learning systems."
uss_2022_19,"""They Look at Vulnerability and Use That to Abuse You"": Participatory Threat Modelling with Migrant Domestic Workers.","No, the abstract is not related to AML because it focuses on digital privacy and security challenges faced by marginalized groups, without discussing any machine learning system vulnerabilities or adversarial techniques."
uss_2022_20,Networks of Care: Tech Abuse Advocates' Digital Security Practices.,"No, the abstract is not related to AML because it focuses on digital security practices and advocacy for survivors of relationship abuse, rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2022_21,How Long Do Vulnerabilities Live in the Code? A Large-Scale Empirical Measurement Study on FOSS Vulnerability Lifetimes.,"No, the abstract is not related to AML. It focuses on tracking and estimating the lifetime of vulnerabilities in software repositories, rather than discussing attacks, defenses, or manipulation techniques specific to machine learning systems."
uss_2022_22,Expected Exploitability: Predicting the Development of Functional Vulnerability Exploits.,"No. The abstract focuses on software vulnerability exploitability and the challenges in accurately assessing it, rather than discussing adversarial machine learning or machine learning systems manipulation."
uss_2022_23,OS-Aware Vulnerability Prioritization via Differential Severity Analysis.,No. The abstract focuses on improving the vulnerability prioritization process in the Linux kernel using differential severity analysis and does not address adversarial attacks or defenses related to machine learning systems.
uss_2022_24,Arbiter: Bridging the Static and Dynamic Divide in Vulnerability Discovery on Binary Programs.,"No. The abstract is focused on improving binary program analysis for vulnerability detection, rather than discussing adversarial attacks or defenses on machine learning models."
uss_2022_25,Spoki: Unveiling a New Wave of Scanners through a Reactive Network Telescope.,No. The abstract is focused on analyzing internet scan traffic and network security rather than adversarial machine learning techniques or attacks.
uss_2022_26,Many Roads Lead To Rome: How Packet Headers Influence DNS Censorship Measurement.,"No. The abstract focuses on techniques for measuring global Internet censorship and does not mention machine learning models, adversarial attacks, or manipulation related to AML."
uss_2022_27,GET /out: Automated Discovery of Application-Layer Censorship Evasion Strategies.,No. The abstract is focused on evading censorship by manipulating network protocols rather than on adversarial attacks or defenses related to machine learning systems.
uss_2022_28,OpenVPN is Open to VPN Fingerprinting.,"No, the abstract is not related to AML. It focuses on fingerprinting and blocking VPN connections using protocol features, which is more about network security and censorship, rather than manipulating machine learning systems or creating adversarial examples."
uss_2022_29,Pool Inference Attacks on Local Differential Privacy: Quantifying the Privacy Guarantees of Apple's Count Mean Sketch in Practice.,"Yes. The abstract discusses an inference attack on local differential privacy mechanisms, which involves adversarial techniques to exploit user data and infer sensitive information, aligning it with adversarial machine learning themes."
uss_2022_30,Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data.,"Yes. The abstract is related to AML as it discusses poisoning attacks on Local Differential Privacy (LDP) protocols, which involve manipulating data inputs to adversely affect the outcomes of federated data analytics, a classic adversarial machine learning scenario."
uss_2022_31,Communication-Efficient Triangle Counting under Local Differential Privacy.,"No, the abstract is not related to AML. It discusses an algorithm for triangle counting in networks while maintaining privacy through Local Differential Privacy, without mentioning adversarial attacks or defenses in machine learning systems."
uss_2022_32,Twilight: A Differentially Private Payment Channel Network.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on enhancing privacy in payment channel networks using differential privacy and trusted execution environments, without discussing attacks on machine learning models or adversarial defenses."
uss_2022_33,Watching the watchers: bias and vulnerability in remote proctoring software.,"No, the given abstract is not related to AML. It focuses on remote proctoring and examination software in the education sector, specifically discussing concerns about exam integrity, procedural fairness, and the security and privacy of exam-takers, without mentioning adversarial attacks or defenses in machine learning systems."
uss_2022_34,The Antrim County 2020 Election Incident: An Independent Forensic Investigation.,"No. The abstract is about a forensic investigation into election result anomalies caused by operator errors and procedural issues, not about adversarial attacks on machine learning systems."
uss_2022_35,An Audit of Facebook's Political Ad Policy Enforcement.,"No. The abstract focuses on the enforcement and transparency policies of political advertising detection on Facebook, which involves policy implementation rather than adversarial manipulation or attacks related to machine learning systems."
uss_2022_36,"Building an Open, Robust, and Stable Voting-Based Domain Top List.",No. The abstract discusses the issues with domain top lists in terms of transparency and ranking manipulation but does not address machine learning systems or how adversarial techniques might exploit these issues against such systems.
uss_2022_37,AMD Prefetch Attacks through Power and Time.,"No. The abstract is related to hardware security vulnerabilities in operating systems and CPUs, and does not discuss machine learning or adversarial attacks on machine learning systems."
uss_2022_38,Hiding in Plain Sight? On the Efficacy of Power Side Channel-Based Control Flow Monitoring.,"No. The abstract discusses physical side-channel monitoring for intrusion detection in embedded systems, but it does not specifically address adversarial machine learning or manipulating machine learning models."
uss_2022_39,Hertzbleed: Turning Power Side-Channel Attacks Into Remote Timing Attacks on x86.,"No, the abstract is not related to AML. It discusses power side-channel attacks and timing attacks on CPUs, which are more related to hardware security rather than adversarial attacks on machine learning models."
uss_2022_40,Binoculars: Contention-Based Side-Channel Attacks Exploiting the Page Walker.,"No. The abstract is related to microarchitectural side channels, focusing on hardware-level security issues, and does not discuss adversarial attacks or defenses on machine learning models."
uss_2022_41,The Dangers of Human Touch: Fingerprinting Browser Extensions through User Actions.,"No. The abstract discusses browser extension fingerprinting and user-triggered vulnerabilities, which focus on user privacy and safeguarding extensions rather than manipulating machine learning models or their outputs."
uss_2022_42,Unleash the Simulacrum: Shifting Browser Realities for Robust Extension-Fingerprinting Prevention.,"No, the abstract is not related to AML. It focuses on preventing browser fingerprinting for privacy protection by using a defense mechanism in browser extensions, not on adversarial attacks or defenses in the context of machine learning models."
uss_2022_43,Online Website Fingerprinting: Evaluating Website Fingerprinting Attacks on Tor in the Real World.,"No, the given abstract is not related to AML as it focuses on evaluating the effectiveness of website fingerprinting attacks on Tor using realistic traffic data rather than addressing attacks or defenses specifically targeted at machine learning models."
uss_2022_44,QCSD: A QUIC Client-Side Website-Fingerprinting Defence Framework.,"No, the abstract is not related to AML. It discusses website fingerprinting attacks on encryption technologies like VPNs, which pertains to privacy and network security rather than adversarial machine learning techniques or defenses."
uss_2022_45,Secure Poisson Regression.,"No. The abstract is focused on secure two-party computation techniques applied to Poisson regression, which is more aligned with data privacy and computation rather than adversarial machine learning."
uss_2022_46,Cheetah: Lean and Fast Secure Two-Party Deep Neural Network Inference.,"No. The abstract focuses on improving secure two-party computation for neural network inference, which involves privacy protection rather than addressing adversarial machine learning techniques or defenses."
uss_2022_47,Piranha: A GPU Platform for Secure Computation.,"No, the abstract is not related to AML. It focuses on improving the efficiency of secure multi-party computation for privacy-preserving machine learning using GPUs, addressing computation rather than adversarial attacks or defenses."
uss_2022_48,OpenSSLNTRU: Faster post-quantum TLS key exchange.,"No, the abstract is not related to Adversarial Machine Learning (AML). It focuses on integrating post-quantum key-exchange algorithms into TLS protocols, which pertains to cryptographic security rather than manipulating or defending against machine learning models."
uss_2022_49,How Are Your Zombie Accounts? Understanding Users' Practices and Expectations on Mobile App Account Deletion.,"No, the abstract is not related to AML because it focuses on user experiences and usability issues in mobile app account deletion rather than discussing any machine learning models or adversarial attacks."
uss_2022_50,"""How Do You Not Lose Friends?"": Synthesizing a Design Space of Social Controls for Securing Shared Digital Resources Via Participatory Design Jams.","No, the abstract is not related to AML because it focuses on the design of social security and privacy controls for shared digital resources, rather than discussing adversarial attacks or defenses against machine learning systems."
uss_2022_51,Caring about Sharing: User Perceptions of Multiparty Data Sharing.,"No. The abstract focuses on user perceptions of data sharing practices and privacy policies, which is unrelated to adversarial machine learning or malicious attacks on ML systems."
uss_2022_52,Neither Access nor Control: A Longitudinal Investigation of the Efficacy of User Access-Control Solutions on Smartphones.,"No. The abstract focuses on access control models and user authorization needs on smartphones, which are unrelated to adversarial machine learning or attacks on machine learning systems."
uss_2022_53,Jenny: Securing Syscalls for PKU-based Memory Isolation Systems.,"No. The abstract focuses on syscall filtering, isolation primitives, and security for cloud computing and browsers, rather than on adversarial attacks or defenses specifically against machine learning systems."
uss_2022_54,Physical-Layer Attacks Against Pulse Width Modulation-Controlled Actuators.,"No, the abstract is not related to AML because it focuses on the effects of intentional electromagnetic interference (IEMI) on the physical actuation of cyber-physical systems rather than attacking or manipulating machine learning models or algorithms."
uss_2022_55,Branch History Injection: On the Effectiveness of Hardware Mitigations Against Cross-Privilege Spectre-v2 Attacks.,"No. The abstract focuses on a hardware vulnerability related to branch target injection and its mitigations, which pertains more to computer architecture and security, rather than adversarial machine learning."
uss_2022_56,TLB;DR: Enhancing TLB-based Attacks with TLB Desynchronized Reverse Engineering.,"No, the given abstract is not related to AML. It focuses on reverse engineering and understanding the behavior of Translation Lookaside Buffers (TLBs) for microarchitectural attacks, which is more related to computer architecture and security rather than machine learning."
uss_2022_57,FuzzOrigin: Detecting UXSS vulnerabilities in Browsers through Origin Fuzzing.,"No, the given abstract is unrelated to Adversarial Machine Learning because it focuses on a browser vulnerability issue (UXSS) and its challenges, without mentioning any manipulation or attacks related to machine learning systems."
uss_2022_58,BrakTooth: Causing Havoc on Bluetooth Link Manager via Directed Fuzzing.,"No. The abstract focuses on using a fuzzing framework to discover implementation bugs in Bluetooth and other wireless protocols, which relates to security testing and vulnerability detection, not adversarial machine learning."
uss_2022_59,AmpFuzz: Fuzzing for Amplification DDoS Vulnerabilities.,"No, the given abstract is not related to AML. It discusses DDoS amplification attacks, which are network security threats unrelated to manipulating or fooling machine learning models.
"
uss_2022_60,FRAMESHIFTER: Security Implications of HTTP/2-to-HTTP/1 Conversion Anomalies.,"No, the abstract is not related to AML. It discusses the adoption of HTTP/2 and its interaction with reverse proxies, which is a topic related to internet protocols and network communication rather than adversarial machine learning."
uss_2022_61,Your Microphone Array Retains Your Identity: A Robust Voice Liveness Detection System for Smart Speakers.,"No. The abstract focuses on passive liveness detection in smart speakers, which involves distinguishing between live and replayed voices rather than discussing adversarial machine learning attacks or defenses."
uss_2022_62,Lumos: Identifying and Localizing Diverse Hidden IoT Devices in an Unfamiliar Environment.,"No. The abstract focuses on detecting hidden IoT devices in unfamiliar environments, which is more related to security and privacy rather than adversarial machine learning."
uss_2022_63,SkillDetective: Automated Policy-Violation Detection of Voice Assistant Applications in the Wild.,"No. This abstract is not related to AML as it focuses on detecting policy violations in voice-apps through dynamic analysis, rather than exploring adversarial attacks or defenses in machine learning systems."
uss_2022_64,"""OK, Siri"" or ""Hey, Google"": Evaluating Voiceprint Distinctiveness via Content-based PROLE Score.","No. The abstract focuses on analyzing the distinctiveness of voiceprints for voice authentication, rather than discussing adversarial attacks or defenses related to machine learning systems."
uss_2022_65,Helping hands: Measuring the impact of a large threat intelligence sharing community.,"No. The abstract focuses on threat information sharing in a security context, rather than discussing adversarial machine learning or attacks on machine learning models."
uss_2022_66,"A Large-scale Temporal Measurement of Android Malicious Apps: Persistence, Migration, and Lessons Learned.","No. The abstract is about analyzing the persistence and removal dynamics of potentially harmful apps (PHAs) on Android devices, focusing on user and marketplace responses rather than adversarial manipulation or attacks on machine learning systems."
uss_2022_67,A Large-scale and Longitudinal Measurement Study of DKIM Deployment.,"No. The abstract is related to the adoption and security of an email authentication protocol (DKIM), not adversarial attacks or defenses in machine learning systems."
uss_2022_68,A Large-scale Investigation into Geodifferences in Mobile Apps.,"No, the given abstract is not related to AML as it focuses on geodifferences and geoblocking in the mobile app ecosystem rather than adversarial attacks or defenses in machine learning systems."
uss_2022_69,Morphuzz: Bending (Input) Space to Fuzz Virtual Devices.,"No. The abstract is related to vulnerabilities in hypervisors and virtual-devices in the context of cloud computing, not machine learning systems or adversarial attacks on ML models."
uss_2022_70,Fuzzware: Using Precise MMIO Modeling for Effective Firmware Fuzzing.,"No, this abstract focuses on fuzz testing and re-hosting firmware in embedded devices rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2022_71,MundoFuzz: Hypervisor Fuzzing with Statistical Coverage Testing and Grammar Inference.,"No. The abstract is focused on hypervisor security and its implications, rather than on adversarial attacks specifically related to machine learning systems."
uss_2022_72,Drifuzz: Harvesting Bugs in Device Drivers from Golden Seeds.,"No. The abstract discusses improving fuzzing techniques for hardware drivers to identify security vulnerabilities, not specifically targeting adversarial machine learning attacks or defenses involving ML models."
uss_2022_73,LTrack: Stealthy Tracking of Mobile Phones in LTE.,"No. The abstract describes a tracking attack on LTE networks, focusing on location and identifier extraction rather than adversarial attacks or defenses in machine learning systems."
uss_2022_74,Watching the Watchers: Practical Video Identification Attack in LTE Networks.,"No, the given abstract is not related to AML because it focuses on a video identification attack that exploits radio signals in LTE networks, which is more related to network security and privacy rather than adversarial manipulations of machine learning models."
uss_2022_75,DoLTEst: In-depth Downlink Negative Testing Framework for LTE Devices.,"No. The abstract is related to uncovering implementation flaws in LTE control plane protocols through negative testing, which focuses on identifying security vulnerabilities in communication protocols rather than adversarial attacks or defenses in machine learning systems."
uss_2022_76,Ghost Peak: Practical Distance Reduction Attacks Against HRP UWB Ranging.,"No, the abstract is not related to AML. It focuses on a physical-layer attack on distance measurement systems of UWB technology, rather than discussing any manipulation or exploitation of machine learning models or systems."
uss_2022_77,SIMC: ML Inference Secure Against Malicious Clients at Semi-Honest Cost.,"Yes, the abstract is related to AML as it discusses securing machine learning inference against model-extraction attacks, a form of adversarial attack."
uss_2022_78,Efficient Differentially Private Secure Aggregation for Federated Learning via Hardness of Learning with Errors.,"No, the provided abstract is not related to Adversarial Machine Learning. It focuses on privacy and security in federated learning, addressing challenges with differential privacy and secure aggregation, which are more about protecting data confidentiality rather than attacking or defending machine learning models."
uss_2022_79,Label Inference Attacks Against Vertical Federated Learning.,"No. The abstract discusses variants of federated learning, specifically horizontal and vertical federated learning, without mentioning adversarial attacks or defenses related to machine learning systems."
uss_2022_80,FLAME: Taming Backdoors in Federated Learning.,"Yes. The abstract is related to AML as it discusses defending against backdoor attacks in Federated Learning, which is a type of adversarial attack in machine learning."
uss_2022_81,Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture.,"Yes, the abstract is related to AML because it discusses defenses against membership inference attacks, which is a form of adversarial attack on machine learning models aimed at compromising privacy."
uss_2022_82,Synthetic Data - Anonymisation Groundhog Day.,"No. The abstract focuses on privacy-preserving data publishing and the evaluation of synthetic data for privacy gain, but it does not specifically address adversarial attacks or defenses in machine learning systems."
uss_2022_83,Attacks on Deidentification's Defenses.,"Yes, the abstract is related to AML because it describes new attacks on deidentification techniques, which aim to manipulate the system's inputs to compromise data privacy, a key aspect of adversarial machine learning."
uss_2022_84,Birds of a Feather Flock Together: How Set Bias Helps to Deanonymize You via Revealed Intersection Sizes.,"No, the abstract is not related to AML. It focuses on privacy leakage and membership inference in secure two-party protocols, which is more aligned with security and privacy rather than adversarial machine learning."
uss_2022_85,Targeted Deanonymization via the Cache Side Channel: Attacks and Defenses.,"No. The abstract focuses on deanonymization attacks that exploit a cache side channel to reveal user identities, which is more related to privacy and security rather than adversarial machine learning."
uss_2022_86,FReD: Identifying File Re-Delegation in Android System Services.,"No, the abstract is not related to AML. It discusses a static program analysis tool for identifying security vulnerabilities in Android's file access control, focusing on software vulnerabilities rather than adversarial attacks on machine learning models."
uss_2022_87,GhostTouch: Targeted Attacks on Touchscreens without Physical Touch.,"No. The abstract is not related to AML as it describes a physical attack on capacitive touchscreens using electromagnetic interference, not an adversarial attack on machine learning models."
uss_2022_88,SARA: Secure Android Remote Authorization.,"No. The abstract discusses the use of Trusted Execution Environments (TEEs) to enhance security protocols in smartphones, which does not specifically relate to adversarial machine learning or attacks on ML systems."
uss_2022_89,FOAP: Fine-Grained Open-World Android App Fingerprinting.,"Yes. This abstract is related to AML because it describes a method for performing app fingerprinting attacks, which can be used to infer user activities and potentially affect the behavior of encrypted communication systems."
uss_2022_90,Identity Confusion in WebView-based Mobile App-in-app Ecosystems.,"No. The abstract focuses on understanding the access within super-app ecosystems, which is related to privacy and permissions rather than adversarial attacks on machine learning models."
uss_2022_91,Automated Detection of Automated Traffic.,"Yes, the abstract is related to AML as it describes a method to separate abusive traffic from legitimate traffic, which involves dealing with potential adversarial scenarios where abuse traffic manipulates the distribution to mimic benign traffic."
uss_2022_92,Inferring Phishing Intention via Webpage Appearance and Dynamics: A Deep Vision Based Approach.,"Yes, the abstract is related to AML because it discusses phishing detection methods and highlights the potential for adversaries to exploit weaknesses in these methods, which is a consideration in adversarial contexts."
uss_2022_93,Phish in Sheep's Clothing: Exploring the Authentication Pitfalls of Browser Fingerprinting.,No. The abstract discusses browser fingerprinting and authentication mechanisms to enhance security against web threats but does not mention any machine learning model being tricked or manipulated by adversarial attacks.
uss_2022_94,DeepPhish: Understanding User Trust Towards Artificially Generated Profiles in Online Social Networks.,"Yes. The abstract is related to AML as it explores how deepfake media, generated by machine learning models, can impact social engineering by creating deceptive social profiles, and discusses defenses and user interactions with such adversarial content."
uss_2022_95,Hand Me Your PIN! Inferring ATM PINs of Users Typing with a Covered Hand.,"No, the abstract is not related to AML because it discusses vulnerabilities in ATM authentication and shoulder-surfing attacks, which are not specific to adversarial machine learning involving manipulating or attacking machine learning models."
uss_2022_96,Estimating Incidental Collection in Foreign Intelligence Surveillance: Large-Scale Multiparty Private Set Intersection with Union and Sum.,"No, the abstract is not related to Adversarial Machine Learning (AML). It discusses surveillance practices and privacy issues related to Section 702 of the Foreign Intelligence Surveillance Act, without mentioning machine learning or adversarial attacks."
uss_2022_97,Constant-weight PIR: Single-round Keyword PIR via Constant-weight Equality Operators.,"No, the abstract is not related to Adversarial Machine Learning as it focuses on secure computation techniques and private information retrieval, without discussing any manipulation or attack/defense mechanisms on machine learning models."
uss_2022_98,Incremental Offline/Online PIR.,"No, the abstract is not related to AML because it focuses on improving private information retrieval (PIR) schemes rather than addressing or defending against adversarial attacks in machine learning systems."
uss_2022_99,GPU-accelerated PIR with Client-Independent Preprocessing for Large-Scale Applications.,"No. The abstract is about improving the efficiency of Multi-Server Private Information Retrieval (PIR) protocols for secure database querying, which is related to cryptographic security rather than adversarial machine learning."
uss_2022_100,Increasing Adversarial Uncertainty to Scale Private Similarity Testing.,"No, the abstract is not related to AML, as it focuses on privacy-preserving methods for detecting abusive content rather than discussing adversarial attacks or defenses related to machine learning systems."
uss_2022_101,Pre-hijacked accounts: An Empirical Study of Security Failures in User Account Creation on the Web.,"No, the abstract is not related to AML. It focuses on account hijacking and authentication methods, not on manipulating machine learning systems."
uss_2022_102,Leaky Forms: A Study of Email and Password Exfiltration Before Form Submission.,"No, the abstract is not related to AML because it focuses on the misuse of online forms for collecting personal data, such as email addresses, by third-party scripts, rather than on manipulating or attacking machine learning models."
uss_2022_103,Might I Get Pwned: A Second Generation Compromised Credential Checking Service.,"No. The abstract is focused on credential stuffing and tweaking attacks, which are related to cybersecurity rather than adversarial machine learning, as it discusses checking and defending against credential exposure rather than manipulating or attacking a machine learning model."
uss_2022_104,Why Users (Don't) Use Password Managers at a Large Educational Institution.,"No, this abstract is not related to Adversarial Machine Learning, as it focuses on the study of password manager usage and habits rather than addressing machine learning systems or adversarial activities."
uss_2022_105,Gossamer: Securely Measuring Password-based Logins.,"No, the abstract is not related to AML. It focuses on understanding and analyzing user behavior and password submission characteristics in login systems, without discussing adversarial attacks or defenses against machine learning models."
uss_2022_106,DoubleStar: Long-Range Attack Towards Depth Estimation based Obstacle Avoidance in Autonomous Systems.,"Yes, the abstract is related to AML because it discusses a method to exploit vulnerabilities in stereo vision-based depth estimation algorithms, which can be seen as a form of adversarial attack on an autonomous system."
uss_2022_107,Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on Autonomous Vehicles.,"Yes. The abstract is related to AML as it discusses LiDAR spoofing attacks on machine learning-based perception algorithms in autonomous vehicles, introducing a novel ""frustum attack"" that exploits vulnerabilities in sensor fusion and tracking systems."
uss_2022_108,SAID: State-aware Defense Against Injection Attacks on In-vehicle Network.,"Yes, the abstract is related to AML because it discusses detecting and defending against message injection attacks in vehicle networks, which is a type of adversarial attack aiming to manipulate the vehicle's systems."
uss_2022_109,Towards Automatically Reverse Engineering Vehicle Diagnostic Protocols.,"No. The abstract focuses on reverse engineering in-vehicle diagnostic protocols using a cyber-physical system, and does not discuss adversarial attacks or machine learning systems."
uss_2022_110,Rolling Colors: Adversarial Laser Exploits against Traffic Light Recognition.,"Yes, the abstract is related to AML because it describes an adversarial attack technique that manipulates the inputs of a machine learning-based traffic light recognition system to achieve incorrect outcomes, like misclassifying traffic light colors."
uss_2022_111,Provably-Safe Multilingual Software Sandboxing using WebAssembly.,"No, this abstract is not related to AML. It focuses on executing untrusted code safely using WebAssembly and Rust, without addressing adversarial machine learning or manipulating machine learning inputs."
uss_2022_112,Backporting Security Patches of Web Applications: A Prototype Design and Implementation on Injection Vulnerability Patches.,"No, the abstract is unrelated to AML because it focuses on web vulnerabilities and the application of security patches for web frameworks rather than manipulating or defending machine learning models."
uss_2022_113,Experimental Security Analysis of the App Model in Business Collaboration Platforms.,"No, the abstract is not related to AML as it focuses on security vulnerabilities and attacks within business collaboration platforms rather than adversarial attacks or defenses specifically targeting machine learning models."
uss_2022_114,SWAPP: A New Programmable Playground for Web Application Security.,"No, the abstract is not related to AML. It discusses defenses against client-side web attacks like DOM-XSS, which pertain to web security rather than adversarial attacks on machine learning models."
uss_2022_115,The Security Lottery: Measuring Client-Side Web Security Inconsistencies.,"No, the abstract is not related to AML because it focuses on the inconsistencies in web application security policies across different client characteristics, rather than addressing machine learning systems or adversarial attacks against them."
uss_2022_116,PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier.,"Yes, the abstract is related to AML because it discusses an adversarial patch attack against image classification models and presents a defense mechanism called PatchCleanser, which neutralizes the adversarial effect and improves robustness."
uss_2022_117,Transferring Adversarial Robustness Through Robust Representation Matching.,"Yes. The abstract discusses Robust Representation Matching (RRM) as a method to improve adversarial training, which is directly related to adversarial machine learning (AML) as it deals with defenses against adversarial examples in neural networks."
uss_2022_118,How Machine Learning Is Solving the Binary Function Similarity Problem.,"No, the abstract is not related to AML because it discusses the challenges in computing similarity between binary code, which is more aligned with programming language analysis and security, rather than focusing on adversarial attacks or defenses in machine learning."
uss_2022_119,Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks.,"Yes. The abstract discusses query-based black-box attacks on deep learning systems, which are a type of adversarial attack related to adversarial machine learning."
uss_2022_120,DnD: A Cross-Architecture Deep Neural Network Decompiler.,"Yes, the abstract is related to AML because it discusses the potential for security applications such as model extraction, adversarial sample generation, and model hardening when a DNN model is accessible, which are relevant aspects of adversarial machine learning."
uss_2022_121,Measurement by Proxy: On the Accuracy of Online Marketplace Measurements.,No. The abstract is not related to Adversarial Machine Learning as it focuses on the analysis of online marketplaces in the dark web and evaluation of research methodologies rather than on machine learning or adversarial attacks.
uss_2022_122,Behind the Tube: Exploitative Monetization of Content on YouTube.,"No. The abstract focuses on the analysis of illicit monetization exploits on YouTube, which is more about platform abuse for financial gain rather than manipulating machine learning models or adversarial attacks related to AML.
"
uss_2022_123,When Sally Met Trackers: Web Tracking From the Users' Perspective.,"No, the abstract is not related to AML as it focuses on the impact of web tracking from the user's perspective and privacy concerns, rather than discussing adversarial attacks or defenses in a machine learning context."
uss_2022_124,How to Peel a Million: Validating and Expanding Bitcoin Clusters.,"No. The abstract is related to cryptocurrency and anonymity, not about adversarial attacks or defenses on machine learning systems."
uss_2022_125,RapidPatch: Firmware Hotpatching for Real-Time Embedded Devices.,"No, the given abstract is not related to AML as it focuses on developing a framework for patching vulnerabilities in embedded devices, rather than discussing adversarial attacks or defenses in the context of machine learning models."
uss_2022_126,GAROTA: Generalized Active Root-Of-Trust Architecture (for Tiny Embedded Devices).,"No, the abstract is not related to AML. It focuses on security challenges and solutions for embedded devices, specifically how malware can incapacitate devices, without mentioning adversarial attacks or manipulation of machine learning models."
uss_2022_127,ReZone: Disarming TrustZone with TEE Privilege Reduction.,"No. The abstract discusses enhancing the security of TrustZone-assisted TEEs by restructuring architectures to mitigate vulnerabilities, not about adversarial attacks or defenses in machine learning systems."
uss_2022_128,Holistic Control-Flow Protection on Real-Time Embedded Systems with Kage.,"No. The abstract describes a system for protecting control data in embedded systems with security measures like memory region separation and control-flow integrity checks, which falls under general system security rather than adversarial machine learning."
uss_2022_129,Orca: Blocklisting in Sender-Anonymous Messaging.,"No, the given abstract is related to secure messaging and encryption, focusing on sender anonymity and abuse mitigation without mentioning machine learning or adversarial attacks."
uss_2022_130,Adversarial Detection Avoidance Attacks: Evaluating the robustness of perceptual hashing-based client-side scanning.,"Yes. The abstract is related to AML as it discusses adversarial attacks on perceptual hashing-based client-side scanning systems, highlighting their vulnerability to detection avoidance attacks."
uss_2022_131,Hecate: Abuse Reporting in Secure Messengers with Sealed Sender.,"No. The abstract focuses on asymmetric message franking for content moderation in encrypted communication systems, which is related to privacy and security, but not specifically to adversarial machine learning."
uss_2022_132,"End-to-Same-End Encryption: Modularly Augmenting an App with an Efficient, Portable, and Blind Cloud Storage.","No. The abstract discusses privacy and security in cloud storage, specifically focusing on end-to-end encryption and ""cloud-blind storage,"" without mentioning any adversarial attacks or defenses in the context of machine learning."
uss_2022_133,Omnes pro uno: Practical Multi-Writer Encrypted Database.,"No, the given abstract is not related to AML, as it discusses encrypted databases and searchable encryption schemes, which focus on cryptographic techniques for securing data and not on adversarial attacks or defenses related to machine learning systems."
uss_2022_134,Faster Yet Safer: Logging System Via Fixed-Key Blockcipher.,"No, the abstract is not related to AML because it focuses on improving secure logging systems for tamper-proof logs, which involves cryptographic techniques rather than adversarial attacks or defenses in machine learning systems."
uss_2022_135,IHOP: Improved Statistical Query Recovery against Searchable Symmetric Encryption through Quadratic Optimization.,"No, the given abstract is related to cryptography and privacy-preserving techniques for database queries, specifically focusing on Searchable Symmetric Encryption schemes rather than adversarial attacks on machine learning models."
uss_2022_136,Dynamic Searchable Encryption with Optimal Search in the Presence of Deletions.,"No, the given abstract is related to Dynamic Searchable Encryption, which deals with improving the efficiency and privacy of search operations in encrypted databases, not with adversarial attacks or defenses in machine learning systems."
uss_2022_137,ALASTOR: Reconstructing the Provenance of Serverless Intrusions.,"No, the abstract is not related to AML. It discusses security concerns and challenges in serverless computing, focusing on intrusion detection and auditing, but does not involve machine learning systems or adversarial attacks."
uss_2022_138,Back-Propagating System Dependency Impact for Attack Investigation.,"No, the given abstract is not related to AML as it focuses on causality analysis and dependency graph reduction for system attack investigation, rather than adversarial machine learning or manipulating machine learning models."
uss_2022_139,Ground Truth for Binary Disassembly is Not Easy.,"No. The abstract discusses challenges in validating and evaluating disassembly tools, which is outside the scope of adversarial machine learning and does not mention any interactions with machine learning systems or adversarial attacks."
uss_2022_140,FreeWill: Automatically Diagnosing Use-after-free Bugs via Reference Miscounting Detection on Binaries.,"No. The abstract discusses a security issue related to memory-safety and vulnerability exploitation in operating systems, and does not mention anything about machine learning systems or adversarial attacks."
uss_2022_141,PolyCruise: A Cross-Language Dynamic Information Flow Analysis.,"No. The abstract is focused on security techniques for multilingual software systems and vulnerability discovery through dynamic information flow analysis, not on adversarial attacks or defenses related to machine learning systems."
uss_2022_142,SYMSAN: Time and Space Efficient Concolic Execution via Dynamic Data-flow Analysis.,"No. The abstract discusses improvements in concolic execution and dynamic data-flow analysis for software testing, but it does not mention or address adversarial machine learning or attacks on machine learning models."
uss_2022_143,CellIFT: Leveraging Cells for Scalable and Precise Dynamic Information Flow Tracking in RTL.,"No. The abstract focuses on Dynamic Information Flow Tracking for hardware to analyze system behavior and detect security violations, but does not discuss machine learning models or adversarial attacks on them, which are core aspects of AML."
uss_2022_144,FlowMatrix: GPU-Assisted Information-Flow Analysis through Matrix-Based Representation.,"No. The abstract focuses on improving the efficiency of Dynamic Information Flow Tracking (DIFT) for security and privacy analysis, without mentioning machine learning systems or adversarial attacks and defenses."
uss_2022_145,Bedrock: Programmable Network Support for Secure RDMA Systems.,"No, the abstract is not related to AML. It focuses on addressing security vulnerabilities and defenses in RDMA networking technology, not on adversarial attacks or defenses in machine learning systems."
uss_2022_146,Creating a Secure Underlay for the Internet.,"No, the abstract is unrelated to AML because it focuses on secure routing solutions for Internet communication rather than discussing adversarial attacks or defenses specific to machine learning systems."
uss_2022_147,Off-Path Network Traffic Manipulation via Revitalized ICMP Redirect Attacks.,"No, the abstract is not related to AML because it focuses on network security issues related to ICMP redirect attacks and does not involve machine learning systems or adversarial manipulation of such systems."
uss_2022_148,VerLoc: Verifiable Localization in Decentralized Systems.,"No. The abstract focuses on verifying geolocations in decentralized networks and detecting adversarial timing manipulations, which is more about network security and geolocation verification than adversarial machine learning techniques."
uss_2022_149,Towards More Robust Keyword Spotting for Voice Assistants.,Yes. The abstract is related to AML because it discusses the use of adversarial examples to trigger misactivations in voice assistants and presents a defense mechanism called EKOS to protect against such adversarial attacks.
uss_2022_150,Seeing is Living? Rethinking the Security of Facial Liveness Verification in the Deepfake Era.,"Yes. The abstract is related to AML as it discusses the security challenges faced by Facial Liveness Verification systems due to synthetic media techniques like deepfakes, which can be considered as adversarial inputs aimed at deceiving these systems."
uss_2022_151,Who Are You (I Really Wanna Know)? Detecting Audio DeepFakes Through Vocal Tract Reconstruction.,"Yes. The abstract is related to AML as it focuses on detecting audio deepfakes, which are maliciously generated content using machine learning, and explores methods to counteract this type of adversarial attack."
uss_2022_152,DeepDi: Learning a Relational Graph Convolutional Network Model on Instructions for Fast and Accurate Disassembly.,"No. The abstract describes a novel disassembly approach using a graph neural network model for binary analysis, which primarily focuses on improving accuracy and efficiency of disassembly and mentions robustness against adversarial attacks, but does not directly engage in adversarial machine learning techniques or defense mechanisms."
uss_2022_153,RE-Mind: a First Look Inside the Mind of a Reverse Engineer.,"No. The abstract is related to binary reverse engineering in the security domain, not specifically about adversarial machine learning attacks or defenses."
uss_2022_154,Characterizing the Security of Github CI Workflows.,"No. The abstract discusses security risks related to CI/CD platforms and their access to secrets and infrastructure, but it does not specifically address adversarial machine learning or attacks on machine learning systems."
uss_2022_155,Decomperson: How Humans Decompile and What We Can Learn From It.,No. The abstract is focused on understanding the processes used in reverse engineering binary programs for security tasks and does not mention anything about adversarial attacks or machine learning systems.
uss_2022_156,99% False Positives: A Qualitative Study of SOC Analysts' Perspectives on Security Alarms.,"No. The abstract is related to the quality and validation of security alarms in Security Operation Centers, focusing on reducing false positives, rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2022_157,HyperDegrade: From GHz to MHz Effective CPU Frequencies.,"No. The abstract is related to side-channel attacks and performance degradation techniques, which focus on exploiting hardware vulnerabilities rather than attacking or manipulating machine learning systems."
uss_2022_158,Pacer: Comprehensive Network Side-Channel Mitigation in the Cloud.,"No, the abstract is not related to AML as it focuses on preventing network side-channel leaks in cloud environments, rather than discussing adversarial attacks or defenses specific to machine learning models or systems."
uss_2022_159,Composable Cachelets: Protecting Enclaves from Cache Side-Channel Attacks.,"No, the given abstract is not related to AML. It focuses on securing isolated execution architectures from side-channel attacks at the hardware level, rather than addressing adversarial attacks on machine learning models."
uss_2022_160,Don't Mesh Around: Side-Channel Attacks and Mitigations on Mesh Interconnects.,"No, the abstract is not related to AML. It discusses microarchitectural side-channel attacks and mitigations focused on hardware in Intel processors, rather than adversarial techniques or defenses in the context of machine learning systems."
uss_2022_161,WebGraph: Capturing Advertising and Tracking Information Flows for Robust Blocking.,"Yes. The abstract is related to AML because it discusses the susceptibility of a state-of-the-art ad and tracker blocker to adversarial evasion techniques and introduces a new tool, WebGraph, that is more robust against such adversarial attacks."
uss_2022_162,Automating Cookie Consent and GDPR Violation Detection.,"No, the abstract is not related to AML because it focuses on analyzing GDPR violations in cookie banners rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2022_163,Khaleesi: Breaker of Advertising and Tracking Request Chains.,"No, the abstract is not related to AML. It focuses on detecting advertising and tracking request chains using machine learning, rather than discussing adversarial attacks or defenses against malicious manipulations of ML systems."
uss_2022_164,Practical Data Access Minimization in Trigger-Action Platforms.,"No. The abstract focuses on addressing privacy concerns in Trigger-Action Platforms (TAPs) by minimizing data access, which is related to data privacy and security rather than adversarial machine learning."
uss_2022_165,Shuffle-based Private Set Union: Faster and More Secure.,"No, the given abstract is not related to AML. It focuses on Private Set Union (PSU), which is a cryptographic technique for privacy-preserving data operations, rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2022_166,Polynomial Commitment with a One-to-Many Prover and Applications.,"No. The abstract is related to cryptographic techniques and secure communication methods in multi-party computation and blockchain, rather than adversarial machine learning or attacks on ML systems."
uss_2022_167,ppSAT: Towards Two-Party Private SAT Solving.,"No. This abstract focuses on developing a privacy-preserving SAT solver using secure two-party computation techniques, which are more relevant to cryptography and privacy rather than adversarial machine learning."
uss_2022_168,Hyperproofs: Aggregating and Maintaining Proofs in Vector Commitments.,"No, the given abstract is not related to AML. It discusses the development of a new vector commitment scheme called Hyperproofs, which focuses on proof maintenance and aggregation efficiency, without any mention of machine learning models or adversarial attacks."
uss_2022_169,COMRace: Detecting Data Race Vulnerabilities in COM Objects.,"No, the abstract is not related to AML because it focuses on detecting data race vulnerabilities in COM objects, which is a software engineering and security issue, rather than addressing adversarial attacks on machine learning systems."
uss_2022_170,MOVERY: A Precise Approach for Modified Vulnerable Code Clone Discovery from Modified Open-Source Software Components.,"No. The abstract discusses vulnerabilities in open-source software components and their propagation due to modifications, but it does not mention machine learning systems or adversarial attacks."
uss_2022_171,Loki: Hardening Code Obfuscation Against Automated Attacks.,"No. The abstract is related to software obfuscation and securing code against deobfuscation attacks, which are not specifically about adversarial attacks on machine learning models or systems."
uss_2022_172,Oops... Code Execution and Content Spoofing: The First Comprehensive Analysis of OpenDocument Signatures.,"No. The abstract discusses the OpenDocument Format (ODF) and its interoperability across office suite applications, which is not related to adversarial machine learning or attacks on machine learning systems."
uss_2022_173,Playing Without Paying: Detecting Vulnerable Payment Verification in Native Binaries of Unity Mobile Games.,"No, the abstract is not related to Adversarial Machine Learning (AML). It focuses on the identification of vulnerabilities in in-app purchasing implementations within mobile games, rather than exploring adversarial attacks or defenses related to machine learning models."
uss_2022_174,Repurposing Segmentation as a Practical LVI-NULL Mitigation in SGX.,"No, the abstract is focused on hardware security vulnerabilities related to Load Value Injection and mitigation techniques, which are not directly related to adversarial machine learning."
uss_2022_175,A Hardware-Software Co-design for Efficient Intra-Enclave Isolation.,"No. The abstract is not related to AML as it focuses on enhancing security and performance in enclave computing, specifically using Intel MPK and SGX, without discussing machine learning systems or adversarial attacks."
uss_2022_176,SGXFuzz: Efficiently Synthesizing Nested Structures for SGX Enclave Fuzzing.,"No, this abstract is not related to AML. It discusses the security analysis challenges of Intel's SGX enclaves and the use of fuzzing, but it does not specifically address adversarial attacks or defenses within machine learning systems."
uss_2022_177,SecSMT: Securing SMT Processors against Contention-Based Covert Channels.,"No, the abstract is not related to AML as it focuses on contention-based security vulnerabilities and mitigation strategies in simultaneous multithreaded processors, rather than on adversarial attacks or defenses related to machine learning systems."
uss_2022_178,Rendering Contention Channel Made Practical in Web Browsers.,"No. The abstract focuses on browser rendering and side channel attacks, which involve exploiting hardware resource contention rather than manipulating machine learning models or processes."
uss_2022_179,SyzScope: Revealing High-Risk Security Impacts of Fuzzer-Exposed Bugs in Linux kernel.,"No, this abstract is not related to AML as it focuses on fuzzing for bug detection and evaluating security impact in software systems, and does not mention machine learning or adversarial attacks."
uss_2022_180,TheHuzz: Instruction Fuzzing of Processors Using Golden-Reference Models for Finding Software-Exploitable Vulnerabilities.,"No. The abstract is focused on hardware verification and security vulnerabilities in processors, which are not directly related to adversarial machine learning or attacks on machine learning systems."
uss_2022_181,Fuzzing Hardware Like Software.,"No. The abstract is focused on hardware design verification and testing, not on adversarial machine learning or attacks on machine learning systems."
uss_2022_182,Stateful Greybox Fuzzing.,"No. The abstract is focused on fuzzing techniques for detecting stateful bugs in protocol implementations, which is more related to software testing and debugging rather than adversarial machine learning."
uss_2022_183,StateFuzz: System Call-Based State-Aware Linux Driver Fuzzing.,"No, the given abstract is not related to AML. It discusses a method for improving software testing through coverage-guided fuzzing, which is not directly associated with machine learning models or adversarial attacks."
uss_2022_184,How to Abuse and Fix Authenticated Encryption Without Key Commitment.,"No, the given abstract is not related to AML because it focuses on the cryptographic aspect of authenticated encryption and key commitment rather than adversarial attacks or defenses in machine learning systems."
uss_2022_185,Private Signaling.,"No. The abstract is focused on a cryptographic problem related to private signaling and message delivery efficiency, without any mention or implication of manipulating or attacking machine learning systems."
uss_2022_186,Batched Differentially Private Information Retrieval.,"No. The given abstract discusses Private Information Retrieval (PIR) techniques which focus on maintaining privacy during database queries, rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2022_187,Practical Privacy-Preserving Authentication for SSH.,"No. The abstract discusses privacy issues related to public-key authentication in SSH, which is more related to cryptography and network security rather than adversarial machine learning."
uss_2022_188,One-off Disclosure Control by Heterogeneous Generalization.,No. The abstract discusses privacy protection techniques and their limitations but does not explicitly address adversarial attacks or defenses on machine learning models.
uss_2022_189,Understanding and Improving Usability of Data Dashboards for Simplified Privacy Control of Voice Assistant Data.,"No, the given abstract is not related to AML. It focuses on user perceptions and privacy concerns with voice assistant data collection, rather than adversarial attacks or manipulations of machine learning models."
uss_2022_190,Security and Privacy Perceptions of Third-Party Application Access for Google Accounts.,"No, the abstract is not related to AML. It focuses on users' perceptions of privacy and security risks associated with third-party API access rather than adversarial attacks or defenses on machine learning systems."
uss_2022_191,"Empirical Understanding of Deletion Privacy: Experiences, Expectations, and Measures.","No. The abstract discusses privacy concerns and potential adversarial exploitation related to content deletion on social platforms, but it does not specifically address adversarial attacks or defenses within the context of manipulating machine learning models."
uss_2022_192,Security at the End of the Tunnel: The Anatomy of VPN Mental Models Among Experts and Non-Experts in a Corporate Context.,"No, the abstract is unrelated to AML as it focuses on the usage and characteristics of corporate and public VPNs due to the COVID-19 pandemic, with no mention of machine learning, adversarial attacks, or defenses."
uss_2022_193,How and Why People Use Virtual Private Networks.,"No. The abstract is focused on user awareness and usage habits of VPNs and does not discuss adversarial attacks, modifications, or defenses related to machine learning systems."
uss_2022_194,CamShield: Securing Smart Cameras through Physical Replication and Isolation.,"No. The abstract describes a privacy protection device for smart home security cameras, focusing on physical isolation and secure data transmission rather than addressing adversarial machine learning attacks or defenses."
uss_2022_195,SCRAPS: Scalable Collective Remote Attestation for Pub-Sub IoT Networks with Untrusted Proxy Verifier.,"No. The abstract discusses a security mechanism for detecting malicious presence in IoT devices using remote attestation, rather than adversarial attacks or defenses in machine learning systems."
uss_2022_196,An Experimental Study of GPS Spoofing and Takeover Attacks on UAVs.,"No, this abstract is not related to AML because it focuses on GPS spoofing attacks to manipulate UAV navigation systems, which are outside the scope of manipulating machine learning models or systems."
uss_2022_197,"Smart Home Privacy Policies Demystified: A Study of Availability, Content, and Coverage.",No. The abstract focuses on analyzing the state of smart home privacy policies and does not address adversarial attacks or defenses related to machine learning systems.
uss_2022_198,MaDIoT 2.0: Modern High-Wattage IoT Botnet Attacks and Defenses.,"No, the given abstract is not related to AML because it focuses on vulnerabilities and attacks in IoT devices and the power grid, rather than attacking or manipulating machine learning systems."
uss_2022_199,AutoDA: Automated Decision-based Iterative Adversarial Attacks.,"Yes. The abstract is related to AML as it discusses decision-based black-box adversarial attacks, which are a type of adversarial method used to fool deep learning models in security-sensitive applications."
uss_2022_200,Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks.,"Yes. The abstract discusses the challenges of defending deep learning systems against adversarial attacks and proposes forensic tools as a complement to existing defenses, which is directly related to adversarial machine learning."
uss_2022_201,Teacher Model Fingerprinting Attacks Against Transfer Learning.,"Yes. The abstract discusses potential security and privacy threats related to transfer learning, which can be linked to adversarial machine learning concerns regarding model confidentiality and potential vulnerabilities."
uss_2022_202,Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation.,"Yes. The abstract discusses the vulnerability of deep neural networks to backdoor attacks in the context of natural language processing, which involves adversarial manipulation of inputs to deceive the model into exhibiting unexpected behaviors."
uss_2022_203,PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning.,"Yes, the abstract is related to AML because it describes a data poisoning attack on contrastive learning, aiming to manipulate the outcomes of downstream machine learning tasks, which is a core aspect of adversarial machine learning."
uss_2022_204,Double Trouble: Combined Heterogeneous Attacks on Non-Inclusive Cache Hierarchies.,"No, the abstract is not related to AML, as it discusses the integration of domain-specific accelerators with general-purpose processors, focusing on hardware architecture rather than machine learning adversarial attacks or defenses."
uss_2022_205,QuORAM: A Quorum-Replicated Fault Tolerant ORAM Datastore.,"No, the abstract is not related to AML because it focuses on improving privacy and fault tolerance in data storage with Oblivious RAM (ORAM) rather than addressing adversarial attacks on machine learning systems."
uss_2022_206,"Post-Quantum Cryptography with Contemporary Co-Processors: Beyond Kronecker, Schnhage-Strassen & Nussbaumer.","No, the given abstract is unrelated to AML as it focuses on cryptographic challenges and solutions for IoT devices, without discussing adversarial attacks or defenses against machine learning systems."
uss_2022_207,FIXREVERTER: A Realistic Bug Injection Methodology for Benchmarking Fuzz Testing.,"No, the abstract is not related to AML as it focuses on fuzz testing and bug injection for benchmarking fuzzers, rather than on manipulating or attacking machine learning systems."
uss_2022_208,Tightly Seal Your Sensitive Pointers with PACTight.,"No, the abstract is not related to AML. It discusses security features specific to ARM architecture and pointer integrity rather than malicious attacks or defenses involving machine learning models."
uss_2022_209,Total Eclipse of the Heart - Disrupting the InterPlanetary File System.,"No, the abstract is not related to AML because it primarily discusses vulnerabilities in the IPFS network, focusing on network attacks and censorship evasion rather than adversarial attacks or defenses on machine learning systems."
uss_2022_210,PrivGuard: Privacy Regulation Compliance Made Easier.,"No. The abstract is focused on improving compliance with privacy regulations through static analysis and security protections, without explicitly addressing or involving adversarial attacks or defenses in machine learning."
uss_2022_211,Stick It to The Man: Correcting for Non-Cooperative Behavior of Subjects in Experiments on Social Networks.,"No. The abstract is focused on the influence of non-cooperative nodes in network systems, particularly in the context of estimating treatment effects, rather than discussing manipulation or attacks on machine learning systems."
uss_2022_212,OVRseen: Auditing Network Traffic and Privacy Policies in Oculus VR.,"No, the abstract is not related to AML. It focuses on analyzing privacy risks and data exposure in VR apps, specifically looking at network traffic and privacy policies, rather than adversarial attacks or defenses in machine learning systems."
uss_2022_213,Half-Double: Hammering From the Next Row Over.,"No. The abstract discusses a hardware vulnerability related to DRAM called Rowhammer, which involves physical memory disturbances rather than adversarial manipulation or attacks on machine learning models.
"
uss_2022_214,RETBLEED: Arbitrary Speculative Code Execution with Return Instructions.,"No, the abstract is not related to AML as it focuses on hardware attacks and defenses related to microarchitectural vulnerabilities, rather than attacking or defending machine learning models."
uss_2022_215,PISTIS: Trusted Computing Architecture for Low-end Embedded Systems.,"No, the abstract is not related to AML because it focuses on developing a software-based trusted computing architecture for embedded devices without mentioning adversarial attacks or defenses specific to machine learning systems."
uss_2022_216,Rapid Prototyping for Microarchitectural Attacks.,"No, the abstract is not related to AML because it focuses on microarchitectural attacks, which are hardware-level attacks, rather than specifically targeting or manipulating machine learning models or their inputs."
uss_2022_217,ProFactory: Improving IoT Security via Formalized Protocol Customization.,"No, the abstract is not related to AML. It focuses on designing and implementing secure IoT protocols to prevent vulnerabilities, rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2022_218,Using Trt to tame Adversarial Synchronization.,"No. The abstract describes synchronization attacks on the Linux kernel to harm performance, which relates to operating systems and security rather than adversarial machine learning or manipulating ML models."
uss_2022_219,PIC Leak: Architecturally Leaking Uninitialized Data from the Microarchitecture.,"No. The abstract is focused on CPU vulnerabilities and architectural issues, which are more related to hardware security rather than adversarial machine learning."
uss_2022_220,"SAPIC+: protocol verifiers of the world, unite!","No, the abstract is not related to AML because it focuses on protocol verification and the use of tools like SAPIC+, PROVERIF, and TAMARIN for verifying security protocols, rather than addressing adversarial machine learning or techniques for attacking or defending machine learning models."
uss_2022_221,On the Security Risks of AutoML.,"No, the abstract does not specifically mention adversarial attacks, defenses, or anything related to manipulating or extracting information from machine learning models, which are central to adversarial machine learning."
uss_2022_222,Dos and Don'ts of Machine Learning in Computer Security.,"Yes. The abstract discusses the challenges and potential pitfalls of using machine learning in security, which suggests concerns related to adversarial machine learning and its impact on the performance of learning-based security systems."
uss_2022_223,Exploring the Security Boundary of Data Reconstruction via Neuron Exclusivity Analysis.,"Yes. The abstract discusses privacy attacks on neural network gradients, specifically data reconstruction attacks, which are relevant to adversarial machine learning as they exploit vulnerabilities to infer or reconstruct private information from a model."
uss_2022_224,On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning.,"No. The given abstract discusses ""machine unlearning,"" which focuses on forgetting training data for privacy reasons, rather than on adversarially manipulating or attacking machine learning models."
uss_2022_225,"""The Same PIN, Just Longer"": On the (In)Security of Upgrading PINs from 4 to 6 Digits.","No, the abstract is not related to AML. It focuses on the security and usability trade-offs of requiring longer numeric PINs for smartphone security, rather than discussing adversarial attacks or machine learning systems."
uss_2022_226,Where to Recruit for Security Development Studies: Comparing Six Software Developer Samples.,"No. The abstract is focused on studying platforms for recruiting software developers for security development research, rather than on studying adversarial machine learning or related attacks and defenses."
uss_2022_227,Investigating State-of-the-Art Practices for Fostering Subjective Trust in Online Voting through Interviews.,No. The abstract focuses on evaluating voters' subjective trust in online voting systems and does not involve discussing attacks on or defenses for machine learning models.
uss_2022_228,"Electronic Monitoring Smartphone Apps: An Analysis of Risks from Technical, Human-Centered, and Legal Perspectives.","No. The abstract discusses the use of smartphone applications for electronic monitoring as an alternative to incarceration, but it does not address any machine learning models or adversarial techniques."
uss_2022_229,MAGE: Mutual Attestation for a Group of Enclaves without Trusted Third Parties.,"No. The abstract focuses on a framework for mutual attestation of enclaves using Intel SGX, which is about secure computation rather than adversarial machine learning."
uss_2022_230,Elasticlave: An Efficient Memory Model for Enclaves.,"No. The abstract is focused on improving the memory model for trusted execution environments and enhancing performance in data sharing workloads, rather than addressing adversarial attacks or defenses within machine learning systems."
uss_2022_231,SGXLock: Towards Efficiently Establishing Mutual Distrust Between Host Application and Enclave for SGX.,"No. The abstract focuses on securing applications using Intel SGX by confining untrusted enclaves, which is more related to secure computing and not specifically about adversarial attacks or defenses in machine learning systems."
uss_2022_232,Minefield: A Software-only Protection for SGX Enclaves against DVFS Attacks.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it discusses manipulating voltage or frequency to affect CPU function, specifically in relation to Intel SGX enclaves, without any mention of machine learning attacks or defenses."
uss_2022_233,Counting in Regexes Considered Harmful: Exposing ReDoS Vulnerability of Nonbacktracking Matchers.,"No, the abstract is not related to AML as it focuses on studying the performance of regex matchers and their vulnerability to ReDoS attacks, which involves regular expression processing rather than machine learning systems."
uss_2022_234,RegexScalpel: Regular Expression Denial of Service (ReDoS) Defense by Localize-and-Fix.,"No, the abstract is not related to AML. This abstract discusses denial of service attacks targeting regular expressions, which is more about software security vulnerabilities rather than adversarial attacks specific to machine learning systems."
uss_2022_235,Anycast Agility: Network Playbooks to Fight DDoS.,"No. The abstract focuses on using IP anycast and BGP for handling DDoS attacks, which is related to network management and defense strategies rather than adversarial machine learning."
uss_2022_236,Regulator: Dynamic Analysis to Detect ReDoS.,"No. The abstract discusses the potential vulnerabilities of regular expressions to denial-of-service attacks due to their running-time characteristics, which relates to application security, but it does not involve any manipulation or adversarial attack specifically targeting a machine learning system."
uss_2022_237,Aardvark: An Asynchronous Authenticated Dictionary with Applications to Account-based Cryptocurrencies.,"No, the abstract is unrelated to AML because it focuses on designing an efficient authenticated dictionary for reducing storage and transmission costs in cryptocurrency transaction validation, without any mention of adversarial attacks or manipulating machine learning systems."
uss_2022_238,Zero-Knowledge Middleboxes.,"No. The abstract is related to cryptography and network security, focusing on zero-knowledge proofs for enforcing policies on encrypted traffic, and does not involve adversarial interactions or manipulations in machine learning systems."
uss_2022_239,Efficient Representation of Numerical Optimization Problems for SNARKs.,"No. The abstract is not related to AML as it focuses on a compiler for zero-knowledge proofs in numerical optimization problems, without mentioning any machine learning systems or adversarial manipulation."
uss_2022_240,Experimenting with Collaborative zk-SNARKs: Zero-Knowledge Proofs for Distributed Secrets.,"No, the given abstract is not related to Adversarial Machine Learning (AML) as it discusses zk-SNARKs, a cryptographic concept focusing on proving statements without revealing information, rather than addressing manipulation or vulnerability issues in machine learning models."
uss_2022_241,Detecting Logical Bugs of DBMS with Coverage-based Guidance.,"No, the abstract is not related to AML. It focuses on testing techniques for detecting bugs in database management systems and does not involve adversarial attacks or defenses in machine learning systems."
uss_2022_242,Augmenting Decompiler Output with Learned Variable Names and Types.,"No. The abstract is about decompilers and reverse-engineering binaries, which is a topic related to software engineering and security, but not specifically about adversarial machine learning or attacks on machine learning systems."
uss_2022_243,Debloating Address Sanitizer.,"No. The abstract discusses a tool for detecting memory errors and its associated runtime overhead, but it does not involve machine learning systems or adversarial attacks on such systems."
uss_2022_244,Ferry: State-Aware Symbolic Execution for Exploring State-Dependent Program Paths.,"No. The abstract discusses symbolic execution and fuzz testing for program analysis, focusing on their limitations in exploring state-dependent branches, without mentioning any aspects related to adversarial machine learning."
uss_2022_245,Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel.,"Yes. The abstract is related to AML as it discusses the vulnerability of neural networks deployed as black boxes, which aligns with exploring adversarial approaches to understanding or manipulating machine learning models."
uss_2022_246,Lamphone: Passive Sound Recovery from a Desk Lamp's Light Bulb Vibrations.,"No, the given abstract is unrelated to AML as it describes an optical side-channel attack to recover sound from light bulbs, which is more related to physical security and eavesdropping, rather than manipulating or attacking machine learning systems."
uss_2022_247,Automated Side Channel Analysis of Media Software with Manifold Learning.,"Yes, the abstract is related to AML as it discusses a method to reconstruct confidential media inputs using side channel analyses and proposes a defensive technique to mitigate these adversarial learning attacks."
uss_2022_248,Lend Me Your Ear: Passive Remote Physical Side Channels on PCs.,"No. The given abstract is related to side-channel attacks involving electromagnetic leakage and unintended data capture, not adversarial attacks on machine learning systems."
uss_2022_249,Stalloris: RPKI Downgrade Attack.,"No. The abstract describes security vulnerabilities in the RPKI (Resource Public Key Infrastructure) and BGP (Border Gateway Protocol) systems, which are related to network security rather than adversarial machine learning."
uss_2022_250,XDRI Attacks - and - How to Enhance Resilience of Residential Routers.,"No, the abstract is not related to AML as it focuses on security vulnerabilities and cache poisoning attacks in residential routers, which are not specific to machine learning systems."
uss_2022_251,V'CER: Efficient Certificate Validation in Constrained Networks.,"No, the abstract is not related to AML. It focuses on the problem of trust establishment and device revocation in constrained networks, which is more related to network security rather than adversarial machine learning."
uss_2022_252,Themis: Accelerating the Detection of Route Origin Hijacking by Distinguishing Legitimate and Illegitimate MOAS.,"No, the abstract is related to addressing route hijacking security issues in Internet routing rather than focusing on adversarial attacks or defenses within a machine learning context."
uss_2022_253,ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models.,"Yes, the abstract is related to AML because it discusses various inference attacks on machine learning models, which are a category of adversarial attacks aimed at extracting sensitive information."
uss_2022_254,Inference Attacks Against Graph Neural Networks.,"Yes, this abstract is related to AML because it discusses inference attacks on graph embeddings, which aim to exploit machine learning model outputs to gain unauthorized insights about the underlying data, and the abstract also proposes a defense mechanism to counteract these attacks."
uss_2022_255,Membership Inference Attacks and Defenses in Neural Network Pruning.,"Yes, the abstract is related to AML because it mentions privacy risks associated with neural network pruning, which could potentially be exploited through adversarial attacks like inference attacks."
uss_2022_256,Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models.,"Yes. The abstract is related to AML because it discusses model inversion attacks, a type of adversarial attack aimed at inferring sensitive information from machine learning models."
