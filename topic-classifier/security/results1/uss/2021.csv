uuid,title,response
uss_2021_0,"30th USENIX Security Symposium, USENIX Security 2021, August 11-13, 2021.","No. The abstract ""nan"" does not provide any information about its content, making it impossible to determine if it is related to Adversarial Machine Learning."
uss_2021_1,"Susan Landau, Tufts University.",No. The abstract describes the timeline and impact of the COVID-19 pandemic and does not relate to adversarial machine learning or any form of attack or defense in ML systems.
uss_2021_2,"Effect of Mood, Location, Trust, and Presence of Others on Video-Based Social Authentication.","No. The abstract focuses on exploring social authentication using video chat as a fallback mechanism, which is related to human-computer interaction and authentication, not adversarial machine learning or attacks against ML systems."
uss_2021_3,'Passwords Keep Me Safe' - Understanding What Children Think about Passwords.,"No, the given abstract is not related to AML as it focuses on children's password practices and cybersecurity education rather than discussing adversarial attacks or defenses on machine learning systems."
uss_2021_4,On the Usability of Authenticity Checks for Hardware Security Tokens.,"No. The abstract is related to the security and authenticity of hardware security tokens, rather than adversarial attacks on machine learning systems."
uss_2021_5,Inexpensive Brainwave Authentication: New Techniques and Insights on User Acceptance.,"No. The abstract discusses brainwave authentication using consumer devices, focusing on biometric identification and performance improvements, not on manipulating or defending against machine learning models."
uss_2021_6,Why Older Adults (Don't) Use Password Managers.,"No. The abstract focuses on the adoption and use of password managers among older adults, rather than discussing adversarial attacks, defenses, or the manipulation of machine learning models."
uss_2021_7,"""It's Stored, Hopefully, on an Encrypted Server"": Mitigating Users' Misconceptions About FIDO2 Biometric WebAuthn.","No, the abstract is not related to AML as it focuses on understanding misconceptions and improving usability of biometric WebAuthn, a passwordless authentication protocol, without discussing adversarial attacks or defenses on machine learning systems."
uss_2021_8,Driving 2FA Adoption at Scale: Optimizing Two-Factor Authentication Notification Design Patterns.,"No. The abstract is focused on examining the adoption of two-factor authentication to enhance security, rather than discussing the manipulation or defense of machine learning systems against adversarial attacks."
uss_2021_9,Hiding the Access Pattern is Not Enough: Exploiting Search Pattern Leakage in Searchable Encryption.,"No, the abstract is not related to AML. It focuses on encryption and privacy issues in secure data search, not on attacking or defending machine learning systems."
uss_2021_10,A Highly Accurate Query-Recovery Attack against Searchable Encryption using Non-Indexed Documents.,"No, this abstract is not related to AML because it focuses on query recovery attacks in searchable encryption schemes, which involves data security and encryption rather than manipulating or extracting information from machine learning models."
uss_2021_11,Fragment and Forge: Breaking Wi-Fi Through Frame Aggregation and Fragmentation.,"No, the abstract is not related to Adversarial Machine Learning. It focuses on design flaws in the 802.11 standard for Wi-Fi security, rather than on attacks or defenses related to manipulating machine learning systems."
uss_2021_12,Card Brand Mixup Attack: Bypassing the PIN in non-Visa Cards by Using Them for Visa Transactions.,"No, the abstract is not related to AML because it describes a security vulnerability in EMV payment systems and card brand mixup attacks, rather than adversarial manipulation or defenses specific to machine learning models."
uss_2021_13,Partitioning Oracle Attacks.,"No, this abstract is not related to AML because it focuses on cryptographic attacks involving partitioning oracles and decryption, rather than manipulation or exploitation of machine learning models."
uss_2021_14,Raccoon Attack: Finding and Exploiting Most-Significant-Bit-Oracles in TLS-DH(E).,"No. The abstract discusses cryptographic key exchange methods and their security aspects, which are related to cryptography and secure communications, not adversarial machine learning."
uss_2021_15,A Side Journey To Titan.,"No. The abstract focuses on a side-channel attack on a hardware security device, which falls under hardware security rather than adversarial machine learning."
uss_2021_16,PASAN: Detecting Peripheral Access Concurrency Bugs within Bare-Metal Embedded Applications.,"No, the abstract is not related to AML because it focuses on concurrency bugs and the challenges in protecting embedded systems from concurrent accesses, rather than adversarial machine learning attacks or defenses.
"
uss_2021_17,On the Design and Misuse of Microcoded (Embedded) Processors - A Cautionary Note.,"No. The abstract is focused on security issues and attack vectors related to microcode in microprocessors, rather than adversarial attacks or defenses on machine learning models."
uss_2021_18,M2MON: Building an MMIO-based Security Reference Monitor for Unmanned Vehicles.,"No, the abstract is focused on building a security framework for unmanned vehicles to defend against attacks through monitoring I/O activities, which is more related to cybersecurity rather than adversarial machine learning."
uss_2021_19,Sharing More and Checking Less: Leveraging Common Input Keywords to Detect Bugs in Embedded Systems.,"No. The abstract discusses security vulnerabilities in IoT devices and embedded systems, but does not mention any machine learning models or adversarial attacks related to these vulnerabilities."
uss_2021_20,Jetset: Targeted Firmware Rehosting for Embedded Systems.,"No. The abstract is focused on rehosting firmware for embedded systems via emulation, which is more related to vulnerability testing rather than adversarial machine learning."
uss_2021_21,LIGHTBLUE: Automatic Profile-Aware Debloating of Bluetooth Stacks.,"No, the abstract is not related to AML. It discusses security vulnerabilities in Bluetooth implementations but does not mention machine learning systems or adversarial attacks on them."
uss_2021_22,PACStack: an Authenticated Call Stack.,"No, the abstract is not related to AML. It discusses control-flow integrity and shadow stacks, which are concerned with general program security and protection against run-time attacks, rather than adversarial attacks on machine learning systems."
uss_2021_23,"""It's stressful having all these phones"": Investigating Sex Workers' Safety Goals, Risks, and Practices Online.","No, the given abstract is not related to AML because it focuses on how sex workers manage their digital privacy and security, rather than discussing adversarial attacks or defenses on machine learning systems."
uss_2021_24,"""Now I'm a bit angry: "" Individuals' Awareness, Perception, and Responses to Data Breaches that Affected Them.","No. The abstract focuses on individuals' awareness and responses to data breaches rather than discussing manipulation or attacks on machine learning models, which is the focus of adversarial machine learning."
uss_2021_25,"""It's the Company, the Government, You and I"": User Perceptions of Responsibility for Smart Home Privacy and Security.","No. The abstract focuses on users' perception of responsibility and concerns about privacy and security in smart home technology, but it does not discuss adversarial attacks or the manipulation of machine learning systems."
uss_2021_26,The Role of Computer Security Customer Support in Helping Survivors of Intimate Partner Violence.,"No. The abstract focuses on addressing tech-enabled intimate partner violence and improving customer support practices, which is unrelated to adversarial machine learning techniques or attacks."
uss_2021_27,Evaluating In-Workflow Messages for Improving Mental Models of End-to-End Encryption.,"No. The abstract focuses on improving users' understanding of end-to-end encryption in messaging apps, which is unrelated to adversarial machine learning or attacks on machine learning systems."
uss_2021_28,PriSEC: A Privacy Settings Enforcement Controller.,"No, the abstract is not related to AML as it focuses on enhancing user control over online privacy settings using machine learning techniques, rather than discussing any form of adversarial attacks or defenses in machine learning."
uss_2021_29,Are Privacy Dashboards Good for End Users? Evaluating User Perceptions and Reactions to Google's My Activity.,"No. The abstract discusses privacy transparency tools and user perceptions of data collection, but it does not involve adversarial attacks or defense strategies related to machine learning systems."
uss_2021_30,Mystique: Efficient Conversions for Zero-Knowledge Proofs with Applications to Machine Learning.,"No, the abstract is not related to AML. It focuses on improving the efficiency of zero-knowledge proofs for large-scale computations, which is more about cryptographic methods rather than adversarial attacks or defenses in machine learning."
uss_2021_31,Poseidon: A New Hash Function for Zero-Knowledge Proof Systems.,"No. The abstract focuses on computational integrity proof systems and their application in cryptographic hash functions, particularly in the context of cryptocurrencies, which is not related to adversarial machine learning."
uss_2021_32,Dynamic proofs of retrievability with low server storage.,"No. The abstract focuses on Proofs of Retrievability protocols, which are related to data integrity and cloud storage verification, not adversarial machine learning."
uss_2021_33,Where's Crypto?: Automated Identification and Classification of Proprietary Cryptographic Primitives in Binary Code.,"No. The abstract is focused on security evaluation of proprietary cryptography in embedded systems, which is not directly related to adversarial machine learning attacks or defenses."
uss_2021_34,Towards Formal Verification of State Continuity for Enclave Programs.,"No, the given abstract is not related to AML as it focuses on verifying state continuity in Intel SGX enclave programs, which pertains to hardware and software security rather than adversarial machine learning attacks or defenses."
uss_2021_35,Protecting Cryptography Against Compelled Self-Incrimination.,"No, this abstract is not related to Adversarial Machine Learning because it focuses on legal and privacy issues surrounding compelled decryption and self-incrimination, rather than attacks or defenses related to machine learning systems."
uss_2021_36,CSProp: Ciphertext and Signature Propagation Low-Overhead Public-Key Cryptosystem for IoT Environments.,"No, the abstract is not related to AML because it focuses on introducing a cryptographic primitive to improve security and efficiency for IoT devices, without any mention of adversarial attacks, defenses, or machine learning systems."
uss_2021_37,Automatic Extraction of Secrets from the Transistor Jungle using Laser-Assisted Side-Channel Attacks.,"No. The abstract is focused on side-channel attacks and physical security of hardware devices, not on adversarial attacks or defenses related to machine learning systems."
uss_2021_38,Lord of the Ring(s): Side Channel Attacks on the CPU On-Chip Ring Interconnect Are Practical.,"No, this abstract is not related to Adversarial Machine Learning as it discusses microarchitectural side-channel attacks on CPU ring interconnects rather than adversarial attacks or defenses within machine learning systems."
uss_2021_39,Frontal Attack: Leaking Control-Flow in SGX via the CPU Frontend.,"No. The abstract describes a side-channel attack on Intel CPUs, specifically targeting instruction execution times and SGX enclaves, but does not involve manipulating or attacking a machine learning system or model."
uss_2021_40,Charger-Surfing: Exploiting a Power Line Side-Channel for Smartphone Information Leakage.,"No, the abstract is not related to AML because it focuses on a side-channel attack that leverages power line leakage to infer touchscreen interactions, rather than attacks that manipulate or extract information from machine learning models."
uss_2021_41,VoltPillager: Hardware-based fault injection attacks against Intel SGX Enclaves using the SVID voltage scaling interface.,"No, the given abstract is related to hardware-based fault injection attacks on Intel CPUs, specifically using the VoltPillager tool, rather than discussing attacks or defenses related to machine learning systems."
uss_2021_42,CIPHERLEAKS: Breaking Constant-time Cryptography on AMD SEV via the Ciphertext Side Channel.,"No, the given abstract is related to hardware and encryption vulnerabilities in AMD's Secure Encrypted Virtualization technology, not to adversarial attacks or defenses in machine learning."
uss_2021_43,Cross-VM and Cross-Processor Covert Channels Exploiting Processor Idle Power Management.,"No, the given abstract is not related to Adversarial Machine Learning. It discusses power-efficient computing and a covert channel threat in multi-core processors, which pertains to hardware security rather than adversarial attacks on machine learning systems."
uss_2021_44,Can Systems Explain Permissions Better? Understanding Users' Misperceptions under Smartphone Runtime Permission Model.,"No, the abstract is not related to AML as it focuses on user permission management in smartphone operating systems, which pertains to privacy and user control rather than adversarial attacks or defenses in machine learning systems."
uss_2021_45,"""Shhh...be quiet!"" Reducing the Unwanted Interruptions of Notification Permission Prompts on Chrome.","No. The abstract is about improving the user interface and mechanism for notification permission prompts in Chrome, focusing on user experience rather than adversarial attacks or defenses in machine learning systems."
uss_2021_46,Explanation Beats Context: The Effect of Timing & Rationales on Users' Runtime Permission Decisions.,"No, the abstract is not related to AML because it focuses on user decision-making regarding mobile app permissions, not on adversarial machine learning techniques or defenses."
uss_2021_47,"A Large Scale Study of User Behavior, Expectations and Engagement with Android Permissions.","No. The abstract is about studying user behavior regarding Android app permissions and privacy decisions, which is not related to adversarial machine learning attacks or defenses."
uss_2021_48,Reducing Bias in Modeling Real-world Password Strength via Deep Learning and Dynamic Dictionaries.,"No, the given abstract is not related to AML because it focuses on analyzing password security and dictionary attacks without addressing machine learning systems or adversarial attacks against them."
uss_2021_49,Using Amnesia to Detect Credential Database Breaches.,"No. The abstract focuses on a framework for detecting and managing credential database breaches using decoy passwords, which is more related to cybersecurity and does not involve adversarial attacks or defenses within a machine learning context."
uss_2021_50,Incrementally Updateable Honey Password Vaults.,No. The abstract discusses a security mechanism related to password vaults and does not involve machine learning models or adversarial attacks and defenses.
uss_2021_51,Private Blocklist Lookups with Checklist.,"No, the abstract is not related to Adversarial Machine Learning (AML) because it focuses on improving privacy in blocklist lookups rather than addressing adversarial attacks or defenses in a machine learning context."
uss_2021_52,Identifying Harmful Media in End-to-End Encrypted Communication: Efficient Private Membership Computation.,"No. The abstract focuses on the challenges posed by end-to-end encryption for detecting harmful media, which is a security and privacy issue rather than an adversarial machine learning problem."
uss_2021_53,Fuzzy Labeled Private Set Intersection with Applications to Private Real-Time Biometric Search.,"No, the abstract is not related to AML because it focuses on private querying and secure set intersection for biometric data rather than discussing adversarial techniques or attacks on machine learning systems."
uss_2021_54,PrivSyn: Differentially Private Data Synthesis.,"No, the abstract is not related to AML. It focuses on generating synthetic datasets using differential privacy techniques for preserving privacy in data sharing, rather than addressing issues related to adversarial attacks or defenses in machine learning systems."
uss_2021_55,Data Poisoning Attacks to Local Differential Privacy Protocols.,"No. The abstract discusses Local Differential Privacy (LDP) protocols in the context of privacy-preserving data analysis, focusing on security and utility rather than adversarial manipulation or attacks on machine learning models."
uss_2021_56,"How to Make Private Distributed Cardinality Estimation Practical, and Get Differential Privacy for Free.","No. The abstract discusses secure computation and sketches for scalable data processing and differential privacy, but does not mention adversarial attacks or machine learning."
uss_2021_57,Locally Differentially Private Analysis of Graph Statistics.,"No. The abstract is focused on differentially private analysis of graphs in a decentralized model, which pertains to privacy and security concerns rather than adversarial manipulation or attacks on machine learning systems."
uss_2021_58,SMASH: Synchronized Many-sided Rowhammer Attacks from JavaScript.,No. The abstract is focused on exploiting Rowhammer vulnerabilities in hardware memory modules via JavaScript rather than describing attacks or defenses specifically targeting machine learning models.
uss_2021_59,Database Reconstruction from Noisy Volumes: A Cache Side-Channel Attack on SQLite.,"No, the abstract is not related to AML because it describes a cache side-channel attack on a database system, which is more closely associated with security vulnerabilities rather than manipulating or attacking machine learning models."
uss_2021_60,PTAuth: Temporal Memory Safety via Robust Points-to Authentication.,No. The abstract focuses on software vulnerabilities and memory corruption issues rather than machine learning systems or adversarial attacks.
uss_2021_61,Does logic locking work with EDA tools?,"No, the abstract is not related to AML as it focuses on logic locking techniques for hardware security, which involves protecting Boolean circuits at the hardware level rather than dealing with adversarial attacks on machine learning models."
uss_2021_62,CURE: A Security Architecture with CUstomizable and Resilient Enclaves.,"No. The abstract is about the security limitations of Trusted Execution Environments (TEEs) in general, not specifically about adversarial machine learning or how ML models can be attacked or defended against adversarial inputs."
uss_2021_63,DICE*: A Formally Verified Implementation of DICE Measured Boot.,"No. The abstract is related to ensuring secure boot processes in devices using the DICE standard, focusing on verification and memory safety, rather than adversarial machine learning or attacks on machine learning models."
uss_2021_64,PEARL: Plausibly Deniable Flash Translation Layer using WOM coding.,"No. The abstract is focused on plausible deniability and the protection of encrypted data, not on adversarial attacks or defenses concerning machine learning systems."
uss_2021_65,Examining the Efficacy of Decoy-based and Psychological Cyber Deception.,"No. The abstract focuses on cyber deception and its effects on attacker behavior in general, without specifically discussing techniques or strategies related to adversarial machine learning or attacks targeted at machine learning systems."
uss_2021_66,"Helping Users Automatically Find and Manage Sensitive, Expendable Files in Cloud Storage.","No, the abstract focuses on developing a tool for classifying and managing cloud-stored files based on perceived sensitivity and usefulness, rather than exploring adversarial machine learning attacks or defenses."
uss_2021_67,Adapting Security Warnings to Counter Online Disinformation.,"No. The abstract focuses on designing and evaluating warnings for disinformation on the internet, which pertains more to information security and user awareness rather than adversarial attacks or defenses specific to machine learning models."
uss_2021_68,"""Why wouldn't someone think of democracy as a target?"": Security practices & challenges of people involved with U.S. political campaigns.",No. The abstract focuses on digital security practices and challenges faced by political campaigns rather than on adversarial attacks or defenses against machine learning systems.
uss_2021_69,Security Obstacles and Motivations for Small Businesses from a CISO's Perspective.,"No. The abstract focuses on the challenges faced by CISOs in guiding small businesses against online threats and improving the usability of security guidance, but it does not address adversarial machine learning or related attack/defense mechanisms."
uss_2021_70,Strategies and Perceived Risks of Sending Sensitive Documents.,"No. The abstract is focused on the methods and perceptions of transmitting sensitive documents securely, rather than any aspects of adversarial machine learning or manipulating machine learning models."
uss_2021_71,A Large-Scale Interview Study on Information Security in and Attacks against Small and Medium-sized Enterprises.,"No, the abstract is not related to AML because it focuses on the general cybersecurity challenges and information security measures in SMEs, without addressing adversarial machine learning attacks or defenses on machine learning systems."
uss_2021_72,On the Routing-Aware Peering against Network-Eclipse Attacks in Bitcoin.,"No. The abstract focuses on safeguarding blockchain networks against network attacks, specifically the Erebus attack, and does not involve manipulating or defending machine learning models against adversarial inputs."
uss_2021_73,EOSAFE: Security Analysis of EOSIO Smart Contracts.,"No, the abstract is not related to AML. The focus is on analyzing and detecting vulnerabilities in EOSIO smart contracts on a blockchain platform, rather than discussing adversarial attacks or defenses specific to machine learning systems."
uss_2021_74,EVMPatch: Timely and Automated Patching of Ethereum Smart Contracts.,"No, the abstract is not related to AML, as it focuses on smart contract vulnerabilities and their mitigation in blockchain technology rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2021_75,Evil Under the Sun: Understanding and Discovering Attacks on Ethereum Decentralized Applications.,"No. The abstract focuses on security risks and cybercrime related to Ethereum decentralized applications, rather than machine learning systems or adversarial attacks on them."
uss_2021_76,Smart Contract Vulnerabilities: Vulnerable Does Not Imply Exploited.,"No. The abstract is related to vulnerabilities in smart contracts on the Ethereum blockchain, rather than adversarial machine learning attacks or defenses."
uss_2021_77,Frontrunner Jones and the Raiders of the Dark Forest: An Empirical Study of Frontrunning on the Ethereum Blockchain.,"No. The abstract is related to blockchain and cryptocurrency security, specifically focusing on frontrunning attacks in Ethereum transactions, rather than adversarial machine learning."
uss_2021_78,SmarTest: Effectively Hunting Vulnerable Transaction Sequences in Smart Contracts through Language Model-Guided Symbolic Execution.,"No. The abstract focuses on symbolic execution techniques and detecting vulnerabilities in smart contracts, which does not specifically involve adversarial attacks or defenses against machine learning models."
uss_2021_79,MIRAGE: Mitigating Conflict-Based Cache Attacks with a Practical Fully-Associative Design.,"No. The abstract discusses side-channel attacks on processor caches, which pertain more to hardware security rather than adversarial machine learning."
uss_2021_80,DOLMA: Securing Speculation with the Principle of Transient Non-Observability.,"No. The abstract is related to microarchitectural and speculative execution vulnerabilities in processors, not adversarial machine learning attacks or defenses."
uss_2021_81,Osiris: Automated Discovery of Microarchitectural Side Channels.,"No, the abstract is not related to AML. It focuses on side-channel attacks targeting CPUs and cryptographic implementations, which are more relevant to hardware security rather than adversarial machine learning."
uss_2021_82,Swivel: Hardening WebAssembly against Spectre.,"No, the abstract is focused on hardening WebAssembly against Spectre attacks, which are related to microarchitectural vulnerabilities, rather than adversarial machine learning attacks or defenses."
uss_2021_83,Rage Against the Machine Clear: A Systematic Analysis of Machine Clears and Their Implications for Transient Execution Attacks.,"No, the abstract is not directly related to AML as it focuses on transient execution attacks related to hardware vulnerabilities, rather than on adversarial manipulations or defenses against machine learning models."
uss_2021_84,Coco: Co-Design and Co-Verification of Masked Software Implementations on CPUs.,"No. The abstract focuses on protecting cryptographic implementations from power analysis attacks, which are hardware-based side-channel attacks, and does not involve manipulating or attacking machine learning models."
uss_2021_85,Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers.,"Yes, the abstract is related to AML as it discusses the susceptibility of machine learning-based malware classifiers to backdoor poisoning attacks and explores the creation of effective backdoor triggers to manipulate ML models."
uss_2021_86,Blind Backdoors in Deep Learning Models.,"Yes, the abstract is related to AML because it discusses the development of sophisticated backdoor attacks on machine learning models, which is a form of adversarial attack."
uss_2021_87,Graph Backdoor.,"Yes, the abstract is related to AML as it discusses the vulnerability of neural networks, specifically graph neural networks, to backdoor attacks, which are a form of adversarial attack."
uss_2021_88,Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection.,"Yes, the abstract is related to AML because it discusses a data contamination attack on deep neural networks, a type of adversarial attack, and explores vulnerabilities in existing defenses against such attacks."
uss_2021_89,You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion.,No. The abstract discusses code autocompletion using neural language models but does not mention any adversarial attacks or defenses related to machine learning systems.
uss_2021_90,Poisoning the Unlabeled Dataset of Semi-Supervised Learning.,"No, the abstract is not related to AML as it discusses semi-supervised learning efficiencies, with no mention of adversarial attacks or defenses."
uss_2021_91,Double-Cross Attacks: Subverting Active Learning Systems.,"No. The abstract discusses active learning, which is a technique for optimizing data labeling processes for machine learning, but it does not mention or relate to adversarial attacks or defenses."
uss_2021_92,Fine Grained Dataflow Tracking with Proximal Gradients.,"No. The abstract focuses on Dynamic Taint Analysis (DTA), which is a method used in systems security for tracking dataflows, and does not mention or relate to adversarial attacks or defenses against machine learning systems."
uss_2021_93,Static Detection of Unsafe DMA Accesses in Device Drivers.,"No. The abstract focuses on the challenges and risks associated with Direct Memory Access in hardware I/O performance and driver code, rather than adversarial machine learning attacks or defenses."
uss_2021_94,MAZE: Towards Automated Heap Feng Shui.,"No. The abstract discusses automated heap layout manipulation and exploit generation related to memory corruption vulnerabilities, which pertains to software security and exploitation rather than adversarial machine learning."
uss_2021_95,SelectiveTaint: Efficient Data Flow Tracking With Static Binary Rewriting.,"No, the abstract is not related to AML. It focuses on improving the efficiency of taint analysis using static binary rewriting, which is more relevant to software security and binary analysis rather than adversarial machine learning."
uss_2021_96,Breaking Through Binaries: Compiler-quality Instrumentation for Better Binary-only Fuzzing.,"No, the abstract is not related to Adversarial Machine Learning. It focuses on improving binary-only fuzzing techniques for software security testing, which is concerned with finding software vulnerabilities but does not directly involve machine learning models or adversarial attacks on them."
uss_2021_97,MBA-Blast: Unveiling and Simplifying Mixed Boolean-Arithmetic Obfuscation.,"No, the given abstract is not related to AML. It primarily focuses on obfuscation techniques for hiding code and data, which are more related to software security and reverse engineering rather than adversarial attacks on machine learning systems."
uss_2021_98,VScape: Assessing and Escaping Virtual Call Protections.,"No. The abstract is focused on control-flow integrity (CFI) solutions and the challenges in assessing their security guarantees, which are more related to system security rather than adversarial machine learning."
uss_2021_99,Pretty Good Phone Privacy.,No. The abstract focuses on privacy violations and data handling in cellular networks rather than discussing attacks or defenses related to machine learning models.
uss_2021_100,KeyForge: Non-Attributable Email from Forward-Forgeable Signatures.,"No. The abstract discusses issues related to email security, particularly the implications of email breaches and DKIM's impact on message authenticity, but it does not address adversarial attacks or defenses within machine learning systems."
uss_2021_101,Express: Lowering the Cost of Metadata-hiding Communication with Cryptographic Privacy.,No. The abstract focuses on a communication system for metadata-hiding with cryptographic security and does not discuss adversarial attacks or machine learning systems.
uss_2021_102,KalÎµido: Real-Time Privacy Control for Eye-Tracking Systems.,No. The abstract focuses on privacy protection for eye-tracking data and does not discuss adversarial machine learning attacks or defenses on machine learning models.
uss_2021_103,Communication-Computation Trade-offs in PIR.,"No, the abstract is related to private information retrieval (PIR) and does not discuss any aspects of adversarial machine learning, attacks, or defenses involving machine learning systems."
uss_2021_104,"I Always Feel Like Somebody's Sensing Me! A Framework to Detect, Identify, and Localize Clandestine Wireless Sensors.","No, the abstract is not related to Adversarial Machine Learning (AML) because it focuses on detecting and localizing wireless sensors in the environment for privacy concerns, rather than discussing malicious attacks or defenses on machine learning systems."
uss_2021_105,The Complexities of Healing in Secure Group Messaging: Why Cross-Group Effects Matter.,"No, the abstract is not related to AML. It focuses on secure messaging protocols and post-compromise security, which are more relevant to cryptography and secure communications rather than adversarial machine learning attacks or defenses."
uss_2021_106,SLAP: Improving Physical Adversarial Examples with Short-Lived Adversarial Perturbations.,"Yes, the abstract is related to Adversarial Machine Learning (AML) because it discusses adversarial examples and patches, which are methods used to perform adversarial attacks on machine learning systems."
uss_2021_107,Adversarial Policy Training against Deep Reinforcement Learning.,"Yes, the abstract is related to AML because it discusses adversarial attacks on deep reinforcement learning agents, highlighting how these attacks can manipulate the agent's behavior by altering inputs or exploiting weaknesses."
uss_2021_108,DRMI: A Dataset Reduction Technology based on Mutual Information for Black-box Attacks.,"Yes, the abstract is related to AML as it discusses black-box attacks against deep neural networks, focusing on improving the efficiency of adversarial queries and enhancing attack effectiveness through data reduction techniques."
uss_2021_109,Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush Deep Neural Network in Multi-Tenant FPGA.,"Yes, the abstract is related to AML as it describes an adversarial attack framework, Deep-Dup, which targets DNN model vulnerabilities in multi-tenant FPGAs to manipulate DNN functionalities."
uss_2021_110,Entangled Watermarks as a Defense against Model Extraction.,"Yes, the abstract is related to AML because it discusses model extraction attacks and how watermarking can be used as a defense strategy, both of which are aspects of adversarial machine learning."
uss_2021_111,Mind Your Weight(s): A Large-scale Study on Insufficient Machine Learning Model Protection in Mobile Apps.,"No. The abstract focuses on the protection and potential theft of on-device ML models on mobile apps, rather than directly addressing adversarial attacks on the models themselves."
uss_2021_112,Hermes Attack: Steal DNN Models with Lossless Inference Accuracy.,"Yes, the given abstract is related to AML because it describes the Hermes Attack, a novel model-extraction attack that targets DNN models, which pertains to adversarial efforts to exploit machine learning systems."
uss_2021_113,ARCUS: Symbolic Root Cause Analysis of Exploits in Production Systems.,"No. The abstract discusses a framework for root cause analysis and bug localization in execution flagged by end-host monitors, but it does not specifically address adversarial machine learning or attacks on machine learning models."
uss_2021_114,Automatic Firmware Emulation through Invalidity-guided Knowledge Inference.,"No. The abstract focuses on emulating firmware for microcontrollers and improving firmware analysis techniques, rather than discussing adversarial attacks or defenses related to machine learning systems."
uss_2021_115,Finding Bugs Using Your Own Code: Detecting Functionally-similar yet Inconsistent Code.,"No, the abstract is not related to AML because it describes a machine learning-based bug detection technique without mentioning any adversarial attacks or defenses against such attacks on machine learning systems."
uss_2021_116,Understanding and Detecting Disordered Error Handling with Precise Function Pairing.,"No, the given abstract is not related to AML. It focuses on error handling in software programs rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2021_117,Precise and Scalable Detection of Use-after-Compacting-Garbage-Collection Bugs.,"No, the abstract is not related to AML because it discusses memory management and garbage collection issues in computer systems rather than adversarial attacks or defenses involving machine learning models."
uss_2021_118,Reducing Test Cases with Attention Mechanism of Neural Networks.,"No. The abstract focuses on test case reduction for crash triage in software testing, which is unrelated to manipulating or defending machine learning models against adversarial attacks."
uss_2021_119,FlowDist: Multi-Staged Refinement-Based Dynamic Information Flow Analysis for Distributed Software Systems.,"No. The abstract is not related to AML as it focuses on dynamic information flow analysis for distributed software, primarily addressing issues of applicability, portability, and scalability rather than adversarial machine learning attacks or defenses."
uss_2021_120,Privacy and Integrity Preserving Computations with CRISP.,"No, the abstract is not related to AML because it focuses on privacy, integrity, and encryption techniques rather than on adversarial attacks or defenses in machine learning systems."
uss_2021_121,Senate: A Maliciously-Secure MPC Platform for Collaborative Analytics.,"No. The abstract discusses the challenges of data sharing across organizations due to privacy, regulatory, or competition concerns, but does not mention adversarial attacks or techniques for manipulating or defending against machine learning models."
uss_2021_122,GForce: GPU-Friendly Oblivious and Rapid Neural Network Inference.,"No, the abstract is not related to AML. It focuses on privacy-preserving methods (oblivious inference) in neural networks using cryptographic solutions, without mentioning adversarial attacks or manipulations to the model's inputs."
uss_2021_123,ABY2.0: Improved Mixed-Protocol Secure Two-Party Computation.,"No. The abstract is about improving the efficiency of secure multi-party computation, which is more related to cryptography and privacy rather than adversarial machine learning."
uss_2021_124,Fantastic Four: Honest-Majority Four-Party Secure Computation With Malicious Security.,"No, the abstract is not related to AML because it focuses on developing a multi-party computation (MPC) protocol for secure computation, which is more aligned with cryptographic techniques rather than adversarial machine learning."
uss_2021_125,Muse: Secure Inference Resilient to Malicious Clients.,"No. The abstract addresses the development of secure inference protocols for preserving privacy during machine learning inference, but it does not focus on adversarial attacks or manipulations typical of adversarial machine learning."
uss_2021_126,ObliCheck: Efficient Verification of Oblivious Algorithms with Unobservable State.,"No. The abstract discusses encryption and data security, focusing on how an adversary might infer information from access patterns, rather than engaging with adversarial attacks or defenses in machine learning systems."
uss_2021_127,PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking.,"Yes, the abstract is related to AML as it discusses defenses against adversarial patches, which are a type of attack that manipulates inputs to mislead machine learning models."
uss_2021_128,T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification.,"Yes. The abstract is related to AML as it discusses Trojan or backdoor attacks on Deep Neural Network classifiers, highlighting vulnerabilities and mentioning defenses specifically in the context of text domain classifiers."
uss_2021_129,WaveGuard: Understanding and Mitigating Audio Adversarial Examples.,"Yes. The abstract is related to AML because it discusses a defense framework, WaveGuard, for detecting adversarial inputs targeting deep learning-based automatic speech recognition (ASR) systems, which is a direct example of adversarial machine learning."
uss_2021_130,Cost-Aware Robust Tree Ensembles for Security Applications.,"Yes, the abstract is related to AML because it discusses increasing the attack cost for evading classifiers by implementing a robust cost-aware training method, which is a defense strategy against adversarial attacks on machine learning models."
uss_2021_131,Dompteur: Taming Audio Adversarial Examples.,"Yes. The abstract is related to AML because it discusses adversarial examples and their impact on machine learning systems, specifically highlighting the threat they pose to Automatic Speech Recognition (ASR) systems."
uss_2021_132,CADE: Detecting and Explaining Concept Drift Samples for Security Applications.,"Yes. The abstract is related to AML because it discusses the challenge of concept drift in security problems, highlighting the dynamic changes in attacker behavior that can affect the performance and reliability of machine learning models."
uss_2021_133,SIGL: Securing Software Installations Through Deep Graph Learning.,"No, the abstract is not related to AML because it focuses on detecting malicious behavior in software installation using system call activity and data provenance graphs, rather than addressing adversarial attacks or defenses specifically targeting machine learning models."
uss_2021_134,ExpRace: Exploiting Kernel Races through Raising Interrupts.,"No, the given abstract is not related to AML as it discusses kernel data races and privilege escalation attacks, which are security vulnerabilities rather than adversarial attacks on machine learning models."
uss_2021_135,Undo Workarounds for Kernel Bugs.,"No, the abstract is not related to AML as it primarily focuses on developing a technique to mitigate kernel bugs and vulnerabilities, without involving adversarial attacks or defenses in machine learning systems."
uss_2021_136,An Analysis of Speculative Type Confusion Vulnerabilities in the Wild.,"No, the given abstract is not related to AML. It discusses a hardware-based security vulnerability, Spectre v1, which exploits branch misprediction, rather than focusing on attacks or defenses in the context of machine learning systems."
uss_2021_137,Blinder: Partition-Oblivious Hierarchical Scheduling.,"No. The abstract discusses temporal isolation and covert timing channels in hierarchical scheduling, which pertains to operating systems and security rather than adversarial machine learning."
uss_2021_138,SHARD: Fine-Grained Kernel Specialization with Context-Aware Hardening.,"No, the abstract is not related to AML. It discusses kernel specialization and debloating for security purposes, but does not involve any aspect of machine learning or adversarial interactions."
uss_2021_139,Preventing Use-After-Free Attacks with Fast Forward Allocation.,"No. The abstract discusses memory safety issues and vulnerabilities in programming languages, which are related to cybersecurity, but it does not mention or involve adversarial attacks or defenses in machine learning systems."
uss_2021_140,Detecting Kernel Refcount Bugs with Two-Dimensional Consistency Checking.,"No. The abstract discusses reference counting bugs within the Linux kernel related to resource management and security impacts, not adversarial machine learning or attacks on ML systems."
uss_2021_141,"Effective Notification Campaigns on the Web: A Matter of Trust, Framing, and Support.","No, the abstract is not related to AML. It focuses on evaluating the effectiveness of security notifications for website misconfigurations, which is unrelated to adversarial machine learning attacks or defenses."
uss_2021_142,Fingerprinting in Style: Detecting Browser Extensions via Injected Style Sheets.,"No. The abstract focuses on privacy issues and online tracking related to browser extensions, but it does not specifically address adversarial attacks or defenses in the context of machine learning systems."
uss_2021_143,JAW: Studying Client-side CSRF with Hybrid Property Graphs and Declarative Traversals.,"No, the abstract is not related to AML. It focuses on a new type of Cross-Site Request Forgery (CSRF) vulnerability in JavaScript-based web applications and does not discuss attacks or defenses related to machine learning models."
uss_2021_144,AdCube: WebVR Ad Fraud and Practical Confinement of Third-Party Ads.,"No. The abstract focuses on ad fraud attacks in WebVR technology and proposes a solution to mitigate these threats, which is more relevant to web security than adversarial machine learning."
uss_2021_145,CACTI: Captcha Avoidance via Client-side TEE Integration.,"No, the abstract is not related to Adversarial Machine Learning (AML) because it discusses the use of Trusted Execution Environments (TEEs) to potentially replace or improve CAPTCHA mechanisms, without mentioning any specific adversarial attacks or defense mechanisms on machine learning systems."
uss_2021_146,PolyScope: Multi-Policy Access Control Analysis to Compute Authorized Attack Operations in Android Systems.,"No, the abstract is not related to Adversarial Machine Learning because it focuses on filesystem access control policies and vulnerabilities in Android systems without discussing attacks or defenses specific to machine learning models."
uss_2021_147,Nyx: Greybox Hypervisor Fuzzing using Fast Snapshots and Affine Types.,"No. The abstract is related to cloud infrastructure security and focuses on detecting vulnerabilities in hypervisors, but it does not discuss machine learning systems or adversarial machine learning attacks or defenses."
uss_2021_148,Systematic Evaluation of Privacy Risks of Machine Learning Models.,"Yes, this abstract is related to AML because it focuses on membership inference attacks, a type of adversarial attack on machine learning models, and discusses methods to evaluate and defend against these privacy risks."
uss_2021_149,Extracting Training Data from Large Language Models.,"Yes, the abstract is related to AML because it discusses an adversarial attack, specifically a training data extraction attack, which targets machine learning models to recover private training data."
uss_2021_150,SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning.,"No. The abstract discusses a privacy-preserving machine learning framework that ensures output delivery even in the presence of adversaries, but it does not address the manipulation or exploitation of machine learning models as studied in adversarial machine learning."
uss_2021_151,Stealing Links from Graph Neural Networks.,"Yes, the abstract is related to Adversarial Machine Learning because it proposes attacks to infer confidential information from the outputs of a Graph Neural Network (GNN) model, which aligns with the concept of understanding or manipulating the behavior of machine learning systems."
uss_2021_152,Leakage of Dataset Properties in Multi-Party Machine Learning.,"Yes. The abstract is related to AML as it discusses an attack that leaks sensitive global dataset properties in a secure multi-party machine learning setting, which can infer private information about other parties' data."
uss_2021_153,Defeating DNN-Based Traffic Analysis Systems in Real-Time With Blind Adversarial Perturbations.,"Yes. The abstract is related to AML because it discusses the vulnerability of deep neural networks to adversarial examples, specifically in the context of traffic analysis, which is a form of adversarial attack."
uss_2021_154,Cerebro: A Platform for Multi-Party Cryptographic Collaborative Learning.,"No. The abstract is about a collaborative learning platform using secure multi-party computation (MPC) to protect sensitive data during joint ML computations, which is focused on data privacy and security rather than adversarial attacks on machine learning systems."
uss_2021_155,SyzVegas: Beating Kernel Fuzzing Odds with Reinforcement Learning.,"No, the abstract is not related to AML. It describes improvements to a kernel fuzzing tool (SYZVEGAS) for better coverage and crash discovery, without mentioning adversarial attacks or manipulation of machine learning models."
uss_2021_156,Android SmartTVs Vulnerability Discovery via Log-Guided Fuzzing.,"No. The abstract is focused on evaluating the security of Android SmartTVs through dynamic fuzzing, but it does not discuss or involve adversarial attacks or defenses specifically related to machine learning systems."
uss_2021_157,UNIFUZZ: A Holistic and Pragmatic Metrics-Driven Platform for Evaluating Fuzzers.,"No, the abstract is not related to AML because it focuses on evaluating and improving fuzzing tools for detecting software vulnerabilities, without specifically addressing machine learning models or adversarial attacks and defenses."
uss_2021_158,Token-Level Fuzzing.,No. The abstract discusses fuzzing techniques in the context of identifying bugs in interpreters but does not involve machine learning systems or adversarial attacks on them.
uss_2021_159,APICraft: Fuzz Driver Generation for Closed-source SDK Libraries.,"No, the abstract is not related to AML as it discusses techniques for automatically generating fuzz drivers for fuzzing closed-source libraries, which is more related to software testing and security rather than adversarial machine learning."
uss_2021_160,The Use of Likely Invariants as Feedback for Fuzzers.,"No, the given abstract is not related to AML because it discusses fuzz testing, a technique for finding software bugs, without mentioning any adversarial attacks or machine learning aspects."
uss_2021_161,ICSFuzz: Manipulating I/Os and Repurposing Binary Code to Enable Instrumented Fuzzing in ICS Control Applications.,"No. The abstract is related to security evaluation of industrial control systems and vulnerability exploitation, but it does not discuss manipulating machine learning models or systems, which is central to adversarial machine learning."
uss_2021_162,"Prime+Probe 1, JavaScript 0: Overcoming Browser-based Side-Channel Defenses.","No. The abstract focuses on cache-based side-channel attacks related to browser security and countermeasures, which are not directly related to adversarial machine learning."
uss_2021_163,Saphire: Sandboxing PHP Applications with Tailored System Call Allowlists.,"No. The abstract focuses on vulnerabilities and privilege separation issues in interpreted languages like PHP, which are more relevant to software security rather than adversarial machine learning."
uss_2021_164,SandTrap: Securing JavaScript-driven Trigger-Action Platforms.,"No. The abstract focuses on security and privacy concerns of Trigger-Action Platforms and the development of a tool for secure JavaScript integration, but does not specifically address adversarial machine learning or attacks on machine learning models."
uss_2021_165,Can I Take Your Subdomain? Exploring Same-Site Attacks in the Modern Web.,"No, the abstract is not related to AML. It is focused on related-domain attackers and their impact on web application security, which involves web vulnerabilities and cybersecurity rather than adversarial machine learning attacks or defenses."
uss_2021_166,U Can't Debug This: Detecting JavaScript Anti-Debugging Techniques in the Wild.,No. The abstract discusses security threats related to browser exploits and evasive malware but does not mention machine learning models or adversarial attacks related to them.
uss_2021_167,Abusing Hidden Properties to Attack the Node.js Ecosystem.,"No. The abstract discusses the security risks associated with sharing objects in Node.js and JavaScript programs, which pertains to general software security rather than adversarial machine learning."
uss_2021_168,mID: Tracing Screen Photos via MoirÃ© Patterns.,"No. The abstract discusses a watermarking technique to trace file leakage via screen photographs, which focuses on digital security rather than adversarial machine learning or manipulating machine learning models."
uss_2021_169,SEAL: Storage-efficient Causality Analysis on Enterprise Logs with Query-friendly Compression.,"No, the abstract is not related to AML. It focuses on causality analysis for attack forensics and behavioral detection in network systems, rather than addressing adversarial attacks or defenses in machine learning models."
uss_2021_170,ATLAS: A Sequence-based Learning Approach for Attack Investigation.,"Yes. The abstract is related to AML because it involves using machine learning techniques to analyze and identify patterns in attack behaviors, which is a common approach in adversarial machine learning for detecting malicious activities."
uss_2021_171,ELISE: A Storage Efficient Logging System Powered by Redundancy Reduction and Representation Learning.,"No, the abstract is not related to AML as it primarily discusses a logging system for efficient storage and compression of logs, rather than the manipulation or defense of a machine learning system against adversarial attacks."
uss_2021_172,V0Finder: Discovering the Correct Origin of Publicly Reported Software Vulnerabilities.,"No, the given abstract is not related to Adversarial Machine Learning (AML) as it focuses on the correctness of CVE reports for software vulnerabilities, which concerns cybersecurity and software reliability rather than machine learning systems or adversarial attacks against them."
uss_2021_173,Minerva- An Efficient Risk-Limiting Ballot Polling Audit.,No. The abstract focuses on the integrity and auditing processes of election outcomes rather than on adversarial attacks or defenses related to machine learning systems.
uss_2021_174,Security Analysis of the Democracy Live Online Voting System.,No. The abstract discusses concerns about the security of an online voting system but does not address adversarial machine learning or introduce any ML-related attacks or defenses.
uss_2021_175,Hopper: Modeling and Detecting Lateral Movement.,"No. The abstract focuses on detecting lateral movement in enterprise networks using login activity logs and anomaly scoring, which is more relevant to cybersecurity than adversarial machine learning."
uss_2021_176,LZR: Identifying Unexpected Internet Services.,"No, the abstract is not related to AML. It focuses on identifying and analyzing the deployment of internet services on non-standard ports and their security implications, rather than discussing manipulation or exploitation of machine learning systems."
uss_2021_177,Blind In/On-Path Attacks and Applications to VPNs.,"No. The abstract focuses on network security attacks on VPN protocols, specifically related to spoofing and hijacking in network contexts rather than manipulating or exploiting machine learning models."
uss_2021_178,The Hijackers Guide To The Galaxy: Off-Path Taking Over Internet Resources.,No. The abstract discusses the control and importance of internet resources in digital society but does not address adversarial machine learning or manipulation of machine learning models.
uss_2021_179,Injection Attacks Reloaded: Tunnelling Malicious Payloads over DNS.,"No, the abstract is not related to Adversarial Machine Learning (AML) because it focuses on the transparency and compliance of DNS resolvers in handling DNS records, which pertains to network protocols rather than machine learning security or adversarial attacks."
uss_2021_180,Causal Analysis for Software-Defined Networking Attacks.,"No, the abstract is not related to AML. It focuses on the security challenges in software-defined networking (SDN) and network forensics, without specifically addressing adversarial attacks or defenses in the context of machine learning systems."
uss_2021_181,Weak Links in Authentication Chains: A Large-scale Analysis of Email Sender Spoofing Attacks.,"No, the abstract is not related to AML. It discusses email security and the vulnerabilities in email authentication chains rather than machine learning systems and adversarial attacks."
uss_2021_182,Automated Discovery of Denial-of-Service Vulnerabilities in Connected Vehicle Protocols.,No. The abstract primarily focuses on the security concerns and potential vulnerabilities in the communication networks of connected vehicles rather than discussing machine learning models or adversarial attacks specifically related to them.
uss_2021_183,Too Good to Be Safe: Tricking Lane Detection in Autonomous Driving with Crafted Perturbations.,Yes. The abstract is related to AML as it discusses exploiting vulnerabilities in the lane detection module of autonomous vehicles using adversarial attacks to manipulate driving decisions.
uss_2021_184,Acoustics to the Rescue: Physical Key Inference Attack Revisited.,"No. The abstract is not related to AML because it focuses on a physical security technique for inferring lock key bittings using audio and video, not on manipulating or defending machine learning systems."
uss_2021_185,Messy States of Wiring: Vulnerabilities in Emerging Personal Payment Systems.,"No. The abstract focuses on studying vulnerabilities in personal payment systems and presents attack methods specific to payment protocols, not machine learning systems."
uss_2021_186,Research on the Security of Visual Reasoning CAPTCHA.,"Yes, the abstract is related to AML because it discusses attacks on CAPTCHA systems, which involve exploiting machine learning techniques to bypass security mechanisms intended to distinguish between humans and bots."
uss_2021_187,Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack.,"Yes, the abstract is related to AML because it discusses the security vulnerabilities and adversarial attacks on deep learning-based Automated Lane Centering systems using physical-world perturbations."
uss_2021_188,Domain Shadowing: Leveraging Content Delivery Networks for Robust Blocking-Resistant Communications.,"No, the abstract is not related to AML. It focuses on a censorship evasion technique using content delivery networks (CDNs) to bypass internet restrictions, and does not involve adversarial attacks or defenses against machine learning systems."
uss_2021_189,Weaponizing Middleboxes for TCP Reflected Amplification.,"No, the abstract is not related to AML. It discusses TCP-based reflective amplification attacks, which are related to network security and DDoS attacks, rather than adversarial attacks on machine learning models."
uss_2021_190,Collective Information Security in Large-Scale Urban Protests: the Case of Hong Kong.,"No. The abstract focuses on the information security practices of protesters during the protests in Hong Kong, particularly communication strategies and technologies, and does not mention or imply any interactions with adversarial machine learning."
uss_2021_191,How Great is the Great Firewall? Measuring China's DNS Censorship.,No. The abstract is not related to AML as it focuses on monitoring changes in China's DNS filtering behavior rather than exploring adversarial machine learning attacks or defenses.
uss_2021_192,Balboa: Bobbing and Weaving around Network Censorship.,"No. The abstract describes a framework for obfuscating network traffic for censorship circumvention, which is unrelated to adversarial machine learning as it does not involve machine learning models or attacks on them."
uss_2021_193,Once is Never Enough: Foundations for Sound Statistical Inference in Tor Network Experimentation.,"No. The abstract focuses on evaluating the performance and statistical significance of simulations in the Tor network, which is more related to network performance and anonymity rather than adversarial machine learning."
uss_2021_194,Rollercoaster: An Efficient Group-Multicast Scheme for Mix Networks.,"No, the abstract is not related to AML. It discusses mix network designs and their impact on message delivery rates, which is more about anonymity and message delays rather than adversarial attacks or defenses in machine learning."
uss_2021_195,Obfuscation-Resilient Executable Payload Extraction From Packed Malware.,"No. The abstract focuses on challenges related to malware analysis and reverse engineering, specifically addressing API obfuscation and unpacking, but does not discuss adversarial attacks or defenses against machine learning systems."
uss_2021_196,DeepReflect: Discovering Malicious Functionality through Binary Reconstruction.,"No, the abstract is not related to AML as it discusses the challenges of using machine learning for malware classification and the limitations of supervised approaches without mentioning any adversarial attacks or manipulations on the machine learning model."
uss_2021_197,When Malware Changed Its Mind: An Empirical Study of Variable Program Behaviors in the Real World.,"No, the given abstract is not related to Adversarial Machine Learning (AML) because it focuses on the limitations of behavioral program analysis and variability in malware behavior across executions, rather than on techniques to manipulate or attack machine learning models specifically."
uss_2021_198,The Circle Of Life: A Large-Scale Study of The IoT Malware Lifecycle.,No. The abstract is about analyzing and defending against IoT malware and does not involve adversarial attacks or interactions with machine learning systems.
uss_2021_199,Forecasting Malware Capabilities From Cyber Attack Memory Images.,"No. The abstract focuses on predicting malware capabilities using a probabilistic model and symbolic analysis, which is related to cybersecurity but not specifically to adversarial machine learning attacks or defenses."
uss_2021_200,YARIX: Scalable YARA-based Malware Intelligence.,"No, the abstract is not related to AML. It discusses the use of YARA for malware identification and its performance challenges, but it does not mention adversarial attacks or defenses in the context of machine learning systems."
uss_2021_201,Constraint-guided Directed Greybox Fuzzing.,"No, the abstract is about improving the efficiency of directed greybox fuzzing for software testing and crash reproduction, which is related to software security testing rather than adversarial machine learning."
uss_2021_202,PrivateDrop: Practical Privacy-Preserving Authentication for Apple AirDrop.,No. This abstract is related to privacy and security concerns in the AirDrop protocol; it does not involve adversarial machine learning attacks or defenses on a machine learning system.
uss_2021_203,Privacy-Preserving and Standard-Compatible AKA Protocol for 5G.,"No. The abstract discusses vulnerabilities and privacy concerns in the 5G-AKA protocol for mobile communication, focusing on privacy-preserving techniques and linkability attacks, which are not specific to adversarial machine learning."
uss_2021_204,SEApp: Bringing Mandatory Access Control to Android Apps.,"No, the given abstract is not related to AML. It discusses enhancing security in Android systems using Mandatory Access Control for app developers, which is more about operating system security rather than adversarial attacks on machine learning models."
uss_2021_205,A11y and Privacy don't have to be mutually exclusive: Constraining Accessibility Service Misuse on Android.,"No. The abstract discusses the misuse of Android accessibility features for malicious purposes, which pertains to mobile security rather than adversarial attacks on machine learning systems."
uss_2021_206,An Investigation of the Android Kernel Patch Ecosystem.,"No, the abstract is not related to AML. It focuses on the delays in patch propagation in the Android kernel ecosystem, which exposes systems to potential security vulnerabilities, rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2021_207,"Share First, Ask Later (or Never?) Studying Violations of GDPR's Explicit Consent in Android Apps.","No, the abstract is not related to AML. The abstract focuses on GDPR compliance and data privacy in mobile services, rather than adversarial machine learning attacks or defenses."
uss_2021_208,DEFInit: An Analysis of Exposed Android Init Routines.,No. The abstract is focused on analyzing and detecting security vulnerabilities related to Android Init routines and not on attacking or defending machine learning systems.
uss_2021_209,Scalable Detection of Promotional Website Defacements in Black Hat SEO Campaigns.,"No. The abstract is not related to AML as it focuses on detecting website defacements using non-machine learning techniques, such as jargon normalization and tag embedding, rather than exploring adversarial or manipulative interactions with machine learning models."
uss_2021_210,Compromised or Attacker-Owned: A Large Scale Classification and Study of Hosting Domains of Malicious URLs.,"No, the abstract is not related to AML. It discusses strategies for blocking malicious websites based on their hosting structure, which pertains more to cybersecurity measures rather than adversarial machine learning."
uss_2021_211,Assessing Browser-level Defense against IDN-based Phishing.,"No. The abstract discusses IDN homograph attacks and browser defense policies, which are more related to web security and phishing, rather than adversarial machine learning."
uss_2021_212,Catching Phishers By Their Bait: Investigating the Dutch Phishing Landscape through Phishing Kit Detection.,"No, the given abstract is not related to Adversarial Machine Learning (AML) because it focuses on analyzing and understanding phishing kits and their impact on phishing activities, rather than on adversarial attacks or defenses involving machine learning systems."
uss_2021_213,PhishPrint: Evading Phishing Detection Crawlers by Prior Profiling.,"Yes. The abstract is related to AML because PhishPrint is used to evaluate web security crawlers against cloaking attacks, which involves understanding and potentially manipulating the behavior of these machine learning systems."
uss_2021_214,Phishpedia: A Hybrid Deep Learning Based Approach to Visually Identify Phishing Webpages.,"No. The abstract discusses phishing detection and visual identification techniques, which are more related to cybersecurity and brand protection rather than specifically focusing on adversarial machine learning attacks and defenses."
uss_2021_215,Is Real-time Phishing Eliminated with FIDO? Social Engineering Downgrade Attacks against FIDO Protocols.,"No, the abstract is not related to AML as it focuses on security vulnerabilities in web-authentication mechanisms rather than adversarial attacks on machine learning models."
uss_2021_216,Jaqen: A High-Performance Switch-Native Approach for Detecting and Mitigating Volumetric DDoS Attacks with Programmable Switches.,"No. The abstract focuses on using programmable switches for defending against volumetric DDoS attacks, which is related to network security rather than adversarial machine learning."
uss_2021_217,ReDoSHunter: A Combined Static and Dynamic Approach for Regular Expression DoS Detection.,"No, the given abstract is not related to AML because it focuses on regular expression Denial of Service (ReDoS) attacks and detection, which are more related to software security and algorithmic complexity rather than adversarial interactions with machine learning models."
uss_2021_218,"Ripple: A Programmable, Decentralized Link-Flooding Defense Against Adaptive Adversaries.","No, the abstract is not related to AML. It discusses link-flooding attacks (LFAs) targeting network infrastructure, rather than adversarial tactics specifically against machine learning systems."
uss_2021_219,Accurately Measuring Global Risk of Amplification Attacks using AmpMap.,"No. The abstract is not related to AML as it focuses on detecting and mitigating DDoS attacks using network monitoring, rather than attacking or defending machine learning models."
uss_2021_220,A Stealthy Location Identification Attack Exploiting Carrier Aggregation in Cellular Networks.,No. The abstract focuses on a side-channel attack for location tracking in cellular networks rather than manipulating machine learning models or exploiting their vulnerabilities.
uss_2021_221,"Disrupting Continuity of Apple's Wireless Ecosystem Security: New Tracking, DoS, and MitM Attacks on iOS and macOS Through Bluetooth Low Energy, AWDL, and Wi-Fi.","No, the abstract is not related to AML because it focuses on reverse-engineering and identifying security vulnerabilities in Apple's Continuity services, without addressing any machine learning models or adversarial attacks/defenses against them."
uss_2021_222,Stars Can Tell: A Robust Method to Defend against GPS Spoofing Attacks using Off-the-shelf Chipset.,"No. This abstract focuses on GPS spoofing attacks and their detection methods, which relate to cybersecurity and signal integrity rather than adversarial attacks on machine learning systems."
uss_2021_223,Formally Verified Memory Protection for a Commodity Multiprocessor Hypervisor.,"No, the abstract is not related to AML because it focuses on the formal verification of a hypervisor's security and correctness, which is more relevant to system security rather than machine learning or adversarial attacks on ML systems."
uss_2021_224,Automatic Policy Generation for Inter-Service Access Control of Microservices.,"No, the abstract is about automating access control policy generation for microservices and does not discuss adversarial machine learning or attacks on machine learning systems."
uss_2021_225,CLARION: Sound and Clear Provenance Tracking for Microservice Deployments.,"No. The abstract focuses on provenance-based security analysis and tracking techniques in container network environments, which is unrelated to adversarial machine learning."
uss_2021_226,Virtual Secure Platform: A Five-Stage Pipeline Processor over TFHE.,"No, this abstract is unrelated to AML as it focuses on developing a secure computation platform using Fully Homomorphic Encryption for Secure Multi-Party Computation, without addressing machine learning models, adversarial attacks, or defenses."
uss_2021_227,Searching Encrypted Data with Size-Locked Indexes.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on secure search over encrypted documents and addresses concerns related to data leakage and injection attacks in the context of encryption rather than machine learning models."
uss_2021_228,Blitz: Secure Multi-Hop Payments Without Two-Phase Commits.,"No, the abstract is not related to AML as it focuses on addressing scalability and security issues within payment-channel networks related to blockchains, without mentioning any machine learning models or adversarial attacks."
uss_2021_229,Reducing HSM Reliance in Payments through Proxy Re-Encryption.,"No, the abstract is not related to AML. It focuses on the security processes involved in the management of PINs in payment systems using Hardware Security Modules, which is more about cryptographic security rather than adversarial machine learning."
uss_2021_230,Risky Business? Investigating the Security Practices of Vendors on an Online Anonymous Market using Ground-Truth Data.,No. The abstract focuses on investigating security practices on an online market rather than the manipulation or defense of machine learning models.
uss_2021_231,Deep Entity Classification: Abusive Account Detection for Online Social Networks.,"Yes. The abstract is related to AML as it discusses the use of machine learning classifiers to defend against adversarial attacks in online social networks, highlighting the need for robust feature engineering and adversarial manipulation considerations."
uss_2021_232,SocialHEISTing: Understanding Stolen Facebook Accounts.,"No. The abstract focuses on understanding attacker behavior in stolen social accounts based on demographic attributes, rather than on how to manipulate or defend against machine learning models."
uss_2021_233,Understanding Malicious Cross-library Data Harvesting on Android.,"No. The abstract focuses more on security risks and privacy implications of third-party libraries and SDKs in mobile apps, rather than discussing adversarial attacks on machine learning systems."
uss_2021_234,Swiped: Analyzing Ground-truth Data of a Marketplace for Stolen Debit and Credit Cards.,"No, the abstract is not related to AML. It primarily focuses on analyzing the operations of an underground economy selling stolen credit and debit card data, without discussing any adversarial attacks or defenses against machine learning systems."
uss_2021_235,Having Your Cake and Eating It: An Analysis of Concession-Abuse-as-a-Service.,"No, the abstract is not related to AML because it focuses on scams and frauds in online retail through social engineering and systemic abuse of return policies, rather than attacks on machine learning systems."
uss_2021_236,Capture: Centralized Library Management for Heterogeneous IoT Devices.,"No. This abstract is focused on the security vulnerabilities and management practices of IoT devices and their firmware, rather than adversarial attacks or defenses specific to machine learning models."
uss_2021_237,MPInspector: A Systematic and Automatic Approach for Evaluating the Security of IoT Messaging Protocols.,No. The abstract focuses on the security of messaging protocols in IoT platforms rather than adversarial attacks or defenses related to machine learning systems.
uss_2021_238,HAWatcher: Semantics-Aware Anomaly Detection for Appified Smart Homes.,"No, this abstract is not related to AML as it focuses on anomaly detection in smart homes using semantics-aware techniques, rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2021_239,Exposing New Vulnerabilities of Error Handling Mechanism in CAN.,"No. The abstract focuses on vulnerabilities and attacks within the Controller Area Network (CAN) used in vehicles, rather than adversarial attacks on machine learning systems."
uss_2021_240,CANARY - a reactive defense mechanism for Controller Area Networks based on Active RelaYs.,"No, the abstract is not related to AML as it discusses a reactive defense mechanism for the CAN bus to address physical DoS attacks, which is focused on network security rather than adversarial machine learning."
uss_2021_241,ReDMArk: Bypassing RDMA Security Mechanisms.,"No, the abstract is not related to AML because it focuses on security vulnerabilities and attacks in RDMA technologies, rather than adversarial attacks or defenses in the context of machine learning systems."
uss_2021_242,ALPACA: Application Layer Protocol Confusion - Analyzing and Mitigating Cracks in TLS Authentication.,"No, this abstract is not related to Adversarial Machine Learning (AML) as it focuses on vulnerabilities involving TLS and man-in-the-middle attacks, which are more relevant to network security rather than manipulating or attacking machine learning models."
uss_2021_243,Experiences Deploying Multi-Vantage-Point Domain Validation at Let's Encrypt.,"No. The abstract focuses on improving the security of TLS certificate issuance through multi-vantage-point domain validation, which is related to network security rather than adversarial attacks on machine learning systems."
uss_2021_244,SiamHAN: IPv6 Address Correlation Attacks on TLS Encrypted Traffic via Siamese Heterogeneous Graph Attention Network.,"No. The abstract focuses on user privacy and correlation of IPv6 addresses, rather than on adversarial attacks or defenses in the context of machine learning."
uss_2021_245,Why Eve and Mallory Still Love Android: Revisiting TLS (In)Security in Android Applications.,No. The abstract discusses vulnerabilities in Android applications related to man-in-the-middle attacks and Google's solutions but does not address adversarial machine learning or attacks on machine learning systems.
uss_2021_246,Why TLS is better without STARTTLS: A Security Analysis of STARTTLS in the Email Context.,"No, the abstract is not related to AML. It discusses encryption technology and its implementation challenges, which are related to security vulnerabilities, but not specifically to adversarial machine learning attacks or defenses."
uss_2021_247,What's in a Name? Exploring CA Certificate Control.,"No, the abstract is not related to AML as it focuses on improving the reliability and understanding of public key infrastructure (PKI) and certificate authority (CA) management, rather than on adversarial machine learning or the manipulation of ML systems."
