uuid,title,response
uss_2023_0,"32nd USENIX Security Symposium, USENIX Security 2023, Anaheim, CA, USA, August 9-11, 2023.","No, the input ""nan"" is not a valid abstract and provides no information related to adversarial machine learning."
uss_2023_1,PhyAuth: Physical-Layer Message Authentication for ZigBee Networks.,"No. The abstract is not related to AML as it focuses on securing communication in ZigBee networks from packet-injection attacks using PHY hop-by-hop message authentication, rather than discussing manipulations or defenses involving machine learning models."
uss_2023_2,Time for Change: How Clocks Break UWB Secure Ranging.,"No. The abstract is related to Ultra-Wide Band (UWB) technology vulnerabilities and transceiver clock imperfections, not on adversarial attacks on machine learning systems."
uss_2023_3,Formal Analysis and Patching of BLE-SC Pairing.,"No, the given abstract is not related to AML. It focuses on a security issue within the BLE-SC pairing protocol, which is a cryptographic and protocol-level flaw, rather than anything related to manipulating or defending against machine learning models."
uss_2023_4,Framing Frames: Bypassing Wi-Fi Encryption by Manipulating Transmit Queues.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it primarily discusses vulnerabilities in Wi-Fi security protocols and frames handling rather than attacks or methods related to manipulating or understanding machine learning systems."
uss_2023_5,Abuse Vectors: A Framework for Conceptualizing IoT-Enabled Interpersonal Abuse.,"No. The abstract is focused on understanding and addressing tech-enabled interpersonal abuse through smart devices, rather than on adversarial attacks or defenses related to machine learning systems."
uss_2023_6,The Digital-Safety Risks of Financial Technologies for Survivors of Intimate Partner Violence.,"No, the abstract is not related to AML as it focuses on digital financial technologies in the context of intimate partner violence (IPV), rather than on manipulating machine learning models or systems."
uss_2023_7,"""It's the Equivalent of Feeling Like You're in Jail"": Lessons from Firsthand and Secondhand Accounts of IoT-Enabled Intimate Partner Abuse.","No, the abstract is not related to Adversarial Machine Learning because it focuses on the misuse of IoT devices for intimate partner violence, rather than discussing or addressing malicious attacks on machine learning systems."
uss_2023_8,Sneaky Spy Devices and Defective Detectors: The Ecosystem of Intimate Partner Surveillance with Covert Devices.,"No. The abstract focuses on the prevalence and detection of covert spy devices used in intimate partner surveillance, rather than on adversarial attacks or machine learning systems."
uss_2023_9,Towards a General Video-based Keystroke Inference Attack.,"Yes. The abstract is related to AML because it discusses a keystroke inference attack that uses machine learning models to extract typed content, which is an example of an adversarial inference attack on a system to compromise privacy."
uss_2023_10,Going through the motions: AR/VR keylogging from user head motions.,Yes. The abstract is related to AML because it discusses a method to infer sensitive text input using machine learning and highlights a security vulnerability in AR/VR systems.
uss_2023_11,Auditory Eyesight: Demystifying Î¼s-Precision Keystroke Tracking Attacks on Unconstrained Keyboard Inputs.,"No. The abstract discusses revealing keyboard inputs through auditory interfaces, not manipulating machine learning systems or extracting insights about their behaviors."
uss_2023_12,Watch your Watch: Inferring Personality Traits from Wearable Activity Trackers.,"No, the given abstract is not related to AML because it focuses on the correlation between wearable activity tracker data and personality traits, without discussing any adversarial attacks or defenses in machine learning systems."
uss_2023_13,Squint Hard Enough: Attacking Perceptual Hashing with Adversarial Machine Learning.,"Yes. The abstract discusses evaluating perceptual hash functions from an adversarial perspective, which involves examining potential vulnerabilities and misuses relevant to Adversarial Machine Learning."
uss_2023_14,How to Cover up Anomalous Accesses to Electronic Health Records.,"Yes, the abstract is related to AML because it discusses the use of adversarial machine learning strategies, such as evasion and poisoning attacks, to manipulate and evaluate the effectiveness of anomaly detection systems in hospital access logs."
uss_2023_15,KENKU: Towards Efficient and Stealthy Black-box Adversarial Attacks against ASR Systems.,"Yes, the abstract is related to AML as it discusses the vulnerabilities of automatic speech recognition (ASR) systems to adversarial examples and critiques existing attack methods."
uss_2023_16,Tubes Among Us: Analog Attack on Automatic Speaker Identification.,"Yes. The abstract discusses the vulnerability of machine learning systems used in acoustics-enabled personal devices to adversarial examples created by humans, highlighting a new form of attack on ML models for tasks like speaker identification."
uss_2023_17,Efficient Unbalanced Private Set Intersection Cardinality and User-friendly Privacy-preserving Contact Tracing.,"No, the abstract is unrelated to AML because it focuses on creating a protocol for secure set intersection using cryptographic techniques without discussing machine learning or adversarial attacks."
uss_2023_18,"Near-Optimal Oblivious Key-Value Stores for Efficient PSI, PSU and Volume-Hiding Multi-Maps.","No, the given abstract is unrelated to AML as it focuses on oblivious key-value stores and data encoding efficiency, which does not involve adversarial attacks or defenses in machine learning contexts."
uss_2023_19,Distance-Aware Private Set Intersection.,"No. The abstract focuses on developing a cryptographic protocol for private set intersection in metric spaces, which does not involve adversarial attacks or defenses in machine learning systems."
uss_2023_20,Linear Private Set Union from Multi-Query Reverse Private Membership Test.,"No. The abstract discusses private set union protocols, which are concerned with securely computing the union of datasets without revealing the underlying data, a topic related to cryptography and privacy, not adversarial machine learning."
uss_2023_21,Auditing Frameworks Need Resource Isolation: A Systematic Study on the Super Producer Threat to System Auditing and Its Mitigation.,"No, the given abstract is not related to AML because it focuses on system auditing frameworks to counter APT attacks and discusses architectural improvements for data isolation rather than adversarial attacks or defenses on machine learning systems."
uss_2023_22,AIRTAG: Towards Automated Attack Investigation by Unsupervised Learning with Log Texts.,No. The abstract discusses improving the efficiency and accuracy of attack investigation using deep learning techniques without directly addressing adversarial attacks or defenses in machine learning systems.
uss_2023_23,Rethinking System Audit Architectures for High Event Coverage and Synchronous Log Availability.,"No. The abstract focuses on improving the integrity and availability of system audit logs in the presence of operating system compromises, and does not explicitly discuss adversarial attacks or defenses in the context of machine learning systems."
uss_2023_24,Improving Logging to Reduce Permission Over-Granting Mistakes.,"No. The abstract focuses on access control configurations and the challenges faced by system administrators, which is more related to security and access management rather than adversarial attacks or defenses in a machine learning context."
uss_2023_25,Diving into Robocall Content with SnorCall.,"No. The abstract is related to analyzing the content of robocalls to identify trends and improve defenses against them, but it does not involve manipulating or attacking a machine learning system, which is a key aspect of adversarial machine learning."
uss_2023_26,UCBlocker: Unwanted Call Blocking Using Anonymous Authentication.,"No. The abstract focuses on a system to block unwanted phone calls using caller authentication and policy definition, and does not involve attacking or defending machine learning models, which is central to adversarial machine learning."
uss_2023_27,Combating Robocalls with Phone Virtual Assistant Mediated Interaction.,No. This abstract is not related to Adversarial Machine Learning as it discusses a defense mechanism against robocalls using NLP and machine learning but does not mention any adversarial attacks or manipulations against machine learning models.
uss_2023_28,"BotScreen: Trust Everybody, but Cut the Aimbots Yourself.","No. The abstract is about detecting aimbots in a video game using deep learning for unusual behavior, but it doesn't involve manipulating or attacking a machine learning system itself to exploit or influence its behavior, which is a core aspect of adversarial machine learning."
uss_2023_29,"""If I could do this, I feel anyone could: "" The Design and Evaluation of a Secondary Authentication Factor Manager.","No, the given abstract is not related to AML because it focuses on improving user experience and efficiency with two-factor authentication management, rather than discussing adversarial attacks or defenses on machine learning systems."
uss_2023_30,Exploring Privacy and Incentives Considerations in Adoption of COVID-19 Contact Tracing Apps.,"No, the abstract is not related to AML because it focuses on improving the adoption and design of mHealth apps for contact tracing by analyzing privacy concerns and user preferences, without addressing adversarial attacks or defenses in machine learning systems."
uss_2023_31,Exploring Tenants' Preferences of Privacy Negotiation in Airbnb.,No. This abstract is related to privacy negotiation in smart homes and does not discuss adversarial attacks or the manipulation of machine learning systems.
uss_2023_32,"Know Your Cybercriminal: Evaluating Attacker Preferences by Measuring Profile Sales on an Active, Leading Criminal Market for User Impersonation at Scale.","No. While the abstract discusses cybercrime and user impersonation, it does not directly address adversarial attacks or manipulations against machine learning models, which are central to AML."
uss_2023_33,HorusEye: A Realtime IoT Malicious Traffic Detection Framework using Programmable Switches.,"No, the abstract is not related to AML. It discusses an anomaly detection framework for IoT traffic, but does not involve adversarial machine learning techniques, attacks, or defenses."
uss_2023_34,An Input-Agnostic Hierarchical Deep Learning Framework for Traffic Fingerprinting.,"No. The abstract discusses a deep learning framework for traffic fingerprinting, focusing on feature extraction and input processing heterogeneity, without mentioning any adversarial attacks or defenses related to machine learning systems."
uss_2023_35,Subverting Website Fingerprinting Defenses with Robust Traffic Representation.,"Yes, the abstract is related to AML because it discusses a novel website fingerprinting attack aimed at bypassing defenses and fingerprinting Tor traffic, which involves adversarial techniques against machine learning-based defenses."
uss_2023_36,Rosetta: Enabling Robust TLS Encrypted Traffic Classification in Diverse Network Environments with TCP-Aware Traffic Augmentation.,"No, the abstract is not related to AML because it focuses on improving the robustness of deep learning models for encrypted traffic classification in diverse network environments, rather than discussing adversarial attacks or defenses against machine learning models."
uss_2023_37,Towards Targeted Obfuscation of Adversarial Unsafe Images using Reconstruction and Counterfactual Super Region Attribution Explainability.,"Yes, the abstract is related to AML because it discusses the use of adversarial attacks to evade AI/ML-based detectors on social networks and presents a system to address these adversarial attack threats."
uss_2023_38,TPatch: A Triggered Physical Adversarial Patch.,"Yes, the abstract is related to AML because it discusses the development of a physical adversarial patch (TPatch) designed to manipulate perception models in autonomous vehicles, demonstrating an attack on their machine learning components and considering defenses."
uss_2023_39,CAPatch: Physical Adversarial Patch against Image Captioning Systems.,"Yes, the abstract is related to AML because it discusses the creation of a physical adversarial patch, CAPatch, designed to fool multi-modal image captioning systems, which is a form of adversarial attack in machine learning."
uss_2023_40,Hard-label Black-box Universal Adversarial Patch Attack.,"Yes, the given abstract is related to AML because it discusses a novel method for generating adversarial patches to manipulate deep learning model outputs, raising concerns about the security and robustness of these models."
uss_2023_41,Anatomy of a High-Profile Data Breach: Dissecting the Aftermath of a Crypto-Wallet Case.,"No. The given abstract focuses on data breaches and their impact on individuals, particularly concerning the secure storage of crypto-assets, rather than discussing adversarial attacks or defenses related to machine learning systems."
uss_2023_42,Glimpse: On-Demand PoW Light Client with Constant-Size Storage for DeFi.,"No, the given abstract is not related to AML, as it focuses on blockchain interoperability and does not discuss adversarial attacks, manipulation, or defenses related to machine learning systems.
"
uss_2023_43,Mixed Signals: Analyzing Ground-Truth Data on the Users and Economics of a Bitcoin Mixing Service.,"No, the abstract is related to Bitcoin mixing and privacy concerns, not to adversarial attacks or machine learning systems, so it is not related to AML."
uss_2023_44,Is Your Wallet Snitching On You? An Analysis on the Privacy Implications of Web3.,"No, the abstract is not related to AML because it focuses on privacy implications and information exposure in Web3 technologies, rather than the manipulation or attack of machine learning systems."
uss_2023_45,Capstone: A Capability-based Foundation for Trustless Secure Memory Access.,"No, the abstract is not related to AML. It discusses architectural capability designs for memory isolation, focusing on security and efficiency, not on adversarial attacks or defenses for machine learning systems."
uss_2023_46,FloatZone: Accelerating Memory Error Detection using the Floating Point Unit.,"No, the abstract is unrelated to AML as it discusses memory sanitizers for detecting programming errors, rather than adversarial attacks or defenses in machine learning systems."
uss_2023_47,PUMM: Preventing Use-After-Free Using Execution Unit Partitioning.,"No, the abstract is not related to AML because it focuses on memory security in software written in memory unsafe languages and does not involve machine learning models or their vulnerabilities."
uss_2023_48,MTSan: A Feasible and Practical Memory Sanitizer for Fuzzing COTS Binaries.,"No. The abstract is focused on fuzzing as a technique for finding vulnerabilities in binary programs, which is more related to software testing and debugging rather than adversarial machine learning."
uss_2023_49,"Hidden Reality: Caution, Your Hand Gesture Inputs in the Immersive Virtual World are Visible to All!",No. The abstract focuses on a side-channel attack targeting VR device interactions rather than exploiting or manipulating machine learning systems.
uss_2023_50,LocIn: Inferring Semantic Location from Spatial Maps in Mixed Reality.,"Yes, the abstract is related to AML because it describes a location inference attack that uses a machine learning model to extract and exploit features from 3D spatial maps, which aligns with the concept of adversarially extracting information from machine learning systems."
uss_2023_51,"Unique Identification of 50, 000+ Virtual Reality Users from Head & Hand Motion Data.","No. The abstract is focused on identifying users based on biometric data within virtual reality environments, which pertains more to privacy concerns rather than adversarial attacks in machine learning."
uss_2023_52,Exploring User Reactions and Mental Models Towards Perceptual Manipulation Attacks in Mixed Reality.,"Yes, the abstract is related to AML as it discusses perceptual manipulation attacks in mixed reality, which involves altering user input to influence judgments and actions, akin to adversarial attacks in machine learning."
uss_2023_53,Erebus: Access Control for Augmented Reality Systems.,"No, the abstract is not related to AML because it focuses on access control and permission management for AR platforms rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2023_54,No Single Silver Bullet: Measuring the Accuracy of Password Strength Meters.,"No. The abstract is related to improving password strength meters and evaluating their accuracy, but it doesn't discuss adversarial attacks or defenses in the context of machine learning."
uss_2023_55,Password Guessing Using Random Forest.,"No. The abstract describes research on password guessing using classical machine learning, which does not specifically involve manipulating or attacking machine learning models as in adversarial machine learning."
uss_2023_56,Pass2Edit: A Multi-Step Generative Model for Guessing Edited Passwords.,"No. The abstract focuses on password tweaking attacks and how users modify passwords, which is related to security but does not explicitly address adversarial machine learning or attacks on machine learning models."
uss_2023_57,Improving Real-world Password Guessing Attacks via Bi-directional Transformers.,"No. The abstract discusses password guessing attacks using NLP techniques, but it does not specifically address adversarial attacks or defenses related to machine learning models."
uss_2023_58,AraÃ±a: Discovering and Characterizing Password Guessing Attacks in Practice.,No. The abstract is related to analyzing and understanding password guessing attacks rather than adversarial techniques specifically targeting machine learning models.
uss_2023_59,PoliGraph: Automated Privacy Policy Analysis using Knowledge Graphs.,"No. The abstract discusses an NLP-based tool for analyzing privacy policies, which focuses on extracting and analyzing text regarding data collection but does not address adversarial attacks or defenses in machine learning systems."
uss_2023_60,Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with Crowdsourcing and Active Learning.,"No. The abstract focuses on developing a cost-effective method for generating training data for privacy policies using techniques like automatic text selection and active learning, rather than discussing adversarial attacks or defenses in machine learning."
uss_2023_61,POLICYCOMP: Counterpart Comparison of Privacy Policies Uncovers Overbroad Personal Data Collection Practices.,"No. The abstract focuses on evaluating the necessity of personal data collection practices in mobile apps' privacy policies in relation to data minimization principles, rather than addressing adversarial machine learning or attacks on ML systems."
uss_2023_62,Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy Labels.,"No, the given abstract is not related to AML. It discusses the accuracy and compliance of privacy labels for iOS apps and does not mention any manipulation or attacks on machine learning systems."
uss_2023_63,Automated Cookie Notice Analysis and Enforcement.,"No, the given abstract is not related to AML because it focuses on detecting and interacting with cookie notices on websites to improve privacy compliance, rather than manipulating or extracting information from machine learning systems."
uss_2023_64,Continuous Learning for Android Malware Detection.,"No, the abstract is not related to AML. It discusses the issue of concept drift affecting the performance of malware classifiers, but it does not mention any adversarial attacks or defense mechanisms."
uss_2023_65,Humans vs. Machines in Malware Classification.,"No, the abstract is not related to AML. It discusses the process of file classification using machine learning and other methods without referencing any adversarial techniques or defenses against such attacks."
uss_2023_66,Adversarial Training for Raw-Binary Malware Classifiers.,Yes. The abstract is related to Adversarial Machine Learning (AML) because it discusses creating and using adversarial examples to evaluate and improve the robustness of malware classification models against evasion attacks.
uss_2023_67,Black-box Adversarial Example Attack towards FCG Based Android Malware Detection under Incomplete Feature Information.,"Yes, the abstract is related to AML as it discusses the design of a black-box adversarial example attack against an Android malware detection system, which involves manipulating machine learning inputs to produce misleading outcomes."
uss_2023_68,Evading Provenance-Based ML Detectors with Adversarial System Actions.,Yes. The abstract is related to AML because it discusses a framework designed to generate adversarial attacks that aim to evade machine learning security detectors.
uss_2023_69,TreeSync: Authenticated Group Management for Messaging Layer Security.,"No. The abstract is related to the security and integrity of group messaging protocols, specifically focusing on Messaging Layer Security (MLS), and does not discuss adversarial attacks or defenses related to machine learning systems."
uss_2023_70,Formal Analysis of Session-Handling in Secure Messaging: Lifting Security from Sessions to Conversations.,"No, the abstract is not related to AML. It focuses on the security properties of messaging protocols, specifically discussing secure communication aspects like Forward Secrecy and Post-Compromise Security, rather than dealing with adversarial attacks or defenses in machine learning."
uss_2023_71,Cryptographic Administration for Secure Group Messaging.,"No, the given abstract is not related to AML because it focuses on cryptographic approaches to improve group messaging systems' security rather than addressing attacks or defenses specific to machine learning systems."
uss_2023_72,Wink: Deniable Secure Messaging.,"No, the abstract is not related to Adversarial Machine Learning as it focuses on enhancing message confidentiality within end-to-end encrypted messaging systems using plausible deniability techniques, rather than discussing attacks or defenses related to machine learning models."
uss_2023_73,Three Lessons From Threema: Analysis of a Secure Messenger.,"No, the abstract is not related to AML as it focuses on the cryptographic analysis and security of an encrypted messaging application, rather than manipulating or defending against machine learning systems."
uss_2023_74,MorFuzz: Fuzzing Processor via Runtime Instruction Morphing enhanced Synchronizable Co-simulation.,"No. The abstract is about hardware fuzzing techniques used to verify processor designs, which does not relate to adversarial machine learning or attacks on machine learning models."
uss_2023_75,ÂµFUZZ: Redesign of Parallel Fuzzing using Microservice Architecture.,"No, the given abstract is not related to AML. It discusses software testing techniques for detecting software bugs, rather than attacks or defenses related to machine learning models."
uss_2023_76,FISHFUZZ: Catch Deeper Bugs by Throwing Larger Nets.,"No, the abstract is related to software testing and bug discovery through fuzzing techniques rather than adversarial machine learning or manipulating machine learning systems."
uss_2023_77,HyPFuzz: Formal-Assisted Processor Fuzzing.,"No. The abstract is about hardware fuzzers detecting security vulnerabilities in processors, which relates to hardware security rather than adversarial machine learning."
uss_2023_78,PolyFuzz: Holistic Greybox Fuzzing of Multi-Language Systems.,"No, the given abstract is not related to AML because it focuses on software security testing through fuzzing for multi-language systems, rather than on manipulating or securing machine learning models against adversarial attacks."
uss_2023_79,VIPER: Spotting Syscall-Guard Variables for Data-Only Attacks.,"No. The abstract is focused on data-only attacks and control-flow protection techniques within general software security, not on adversarial attacks or defenses specific to machine learning systems."
uss_2023_80,AURC: Detecting Errors in Program Code and Documentation.,"No. The abstract discusses error detection in program code and documentation, focusing on discovering vulnerabilities and inconsistencies, but it does not address manipulating machine learning models or adversarial attacks."
uss_2023_81,Not All Data are Created Equal: Data and Pointer Prioritization for Scalable Protection Against Data-Oriented Attacks.,"No, the given abstract is not related to AML as it focuses on data-oriented attacks within operating systems and proposes a framework for prioritizing data objects for protection, but does not address attacks or defenses specifically in the context of machine learning systems."
uss_2023_82,SAFER: Efficient and Error-Tolerant Binary Instrumentation.,"No, this abstract is not related to adversarial machine learning (AML) because it focuses on binary instrumentation techniques to improve performance and safety in code transformation, rather than addressing any machine learning models or adversarial attacks on them."
uss_2023_83,Reassembly is Hard: A Reflection on Challenges and Strategies.,"No. The abstract discusses static binary rewriting and error detection in reassemblers, which are not directly related to adversarial machine learning techniques or attacks."
uss_2023_84,Measuring Up to (Reasonable) Consumer Expectations: Providing an Empirical Basis for Holding IoT Manufacturers Legally Responsible.,"No, the abstract is not related to AML because it focuses on consumer expectations and responses to security and privacy incidents in IoT devices, rather than discussing adversarial attacks or defenses related to machine learning systems."
uss_2023_85,Are Consumers Willing to Pay for Security and Privacy of IoT Devices?,"No, the abstract is not related to AML because it focuses on consumer behavior and preferences regarding IoT device security and privacy features, rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2023_86,Examining Consumer Reviews to Understand Security and Privacy Issues in the Market of Smart Home Devices.,"No, the abstract is not related to Adversarial Machine Learning (AML). It focuses on analyzing customer reviews for IoT devices to understand consumer concerns about security and privacy, rather than discussing attacks or defenses related to machine learning models."
uss_2023_87,"Internet Service Providers' and Individuals' Attitudes, Barriers, and Incentives to Secure IoT.","No. The abstract is about the attitudes and incentives of ISPs and individuals regarding the security of IoT devices, which is not directly related to adversarial machine learning attacks or defenses."
uss_2023_88,Detecting and Handling IoT Interaction Threats in Multi-Platform Multi-Control-Channel Smart Homes.,"No. The abstract focuses on detecting and handling IoT interaction threats in smart homes, which involves device interaction conflicts and platform integration, but does not mention or relate to adversarial attacks or defenses in machine learning systems."
uss_2023_89,Private Proof-of-Stake Blockchains using Differentially-Private Stake Distortion.,"No. The given abstract is related to private proof-of-stake blockchains and discusses safety, liveness, and privacy concerns, but does not address adversarial attacks or defenses in the context of machine learning."
uss_2023_90,"PrivateFL: Accurate, Differentially Private Federated Learning via Personalized Data Transformation.","Yes. The abstract discusses inference attacks on federated learning, which are a type of adversarial attack focused on extracting sensitive information from local training data."
uss_2023_91,What Are the Chances? Explaining the Epsilon Parameter in Differential Privacy.,"No. The abstract is focused on the communication of differential privacy guarantees to end-users, which is related to privacy and data protection, rather than adversarial machine learning."
uss_2023_92,Tight Auditing of Differentially Private Machine Learning.,"No, this abstract is related to privacy audits and mechanisms for differential privacy estimation in machine learning algorithms, not about adversarial attacks on machine learning models."
uss_2023_93,PrivTrace: Differentially Private Trajectory Synthesis by Adaptive Markov Models.,"No, the abstract is not related to AML. It focuses on using differential privacy and Markov chain models to address privacy concerns in publishing trajectory data, rather than discussing adversarial attacks or manipulation of machine learning systems."
uss_2023_94,Meta-Sift: How to Sift Out a Clean Subset in the Presence of Data Poisoning?,"Yes, the abstract is related to AML as it discusses data poisoning risks and defenses, which are key concepts in adversarial machine learning."
uss_2023_95,Towards A Proactive ML Approach for Detecting Backdoor Poison Samples.,"Yes. The abstract is related to AML because it discusses detecting and mitigating backdoor attacks, which are a form of adversarial attack affecting deep learning models."
uss_2023_96,PORE: Provably Robust Recommender Systems against Data Poisoning Attacks.,"Yes, the abstract is related to AML because it discusses data poisoning attacks on recommender systems and proposes a framework to make them robust against such attacks, which is a core aspect of adversarial machine learning."
uss_2023_97,Every Vote Counts: Ranking-Based Training of Federated Learning to Resist Poisoning Attacks.,"Yes, the abstract is related to AML because it discusses poisoning attacks in federated learning, where malicious clients contribute harmful updates to degrade the accuracy of a machine learning model."
uss_2023_98,Fine-grained Poisoning Attack to Local Differential Privacy Protocols for Mean and Variance Estimation.,"Yes, the abstract is related to AML as it describes a scenario where an attacker uses a data poisoning attack to manipulate data within a local differential privacy (LDP) framework, which is a type of adversarial attack."
uss_2023_99,Your Exploit is Mine: Instantly Synthesizing Counterattack Smart Contract.,"No. The abstract discusses the use of runtime defense mechanisms to protect smart contracts from exploitation, which is focused on security in blockchain technology rather than adversarial machine learning attacks on ML models."
uss_2023_100,Smart Learning to Find Dumb Contracts.,"No. The abstract focuses on detecting vulnerabilities in Ethereum smart contracts using deep learning, but it does not address adversarial attacks or defenses in the context of machine learning systems."
uss_2023_101,Confusum Contractum: Confused Deputy Vulnerabilities in Ethereum Smart Contracts.,No. The abstract focuses on the security considerations of smart contracts on blockchain systems and does not explicitly address adversarial attacks or defenses in the context of machine learning systems.
uss_2023_102,Panda: Security Analysis of Algorand Smart Contracts.,"No, the abstract is not related to AML. It focuses on identifying and analyzing security vulnerabilities in Algorand smart contracts through static analysis, which is about blockchain security rather than adversarial machine learning."
uss_2023_103,Proxy Hunting: Understanding and Characterizing Proxy-based Upgradeable Smart Contracts in Blockchains.,"No. The abstract focuses on upgradeable smart contracts and their security implications within blockchain technology, rather than on machine learning systems or adversarial attacks associated with AML."
uss_2023_104,Fuzztruction: Using Fault Injection-based Fuzzing to Leverage Implicit Domain Knowledge.,"No. The abstract discusses fuzz testing in the context of digital communication protocols and data formats, not adversarial machine learning or attacks on ML systems."
uss_2023_105,FuzzJIT: Oracle-Enhanced Fuzzing for JavaScript Engine JIT Compiler.,"No. The abstract is about a fuzzing technique for identifying bugs in JavaScript Just-In-Time (JIT) compilers, and it does not discuss adversarial attacks or machine learning systems."
uss_2023_106,GLeeFuzz: Fuzzing WebGL Through Error Message Guided Mutation.,"No. The abstract is related to security testing of WebGL interfaces through fuzzing techniques, which focuses on vulnerability discovery and is not associated with adversarial attacks or manipulating machine learning systems."
uss_2023_107,autofz: Automated Fuzzer Composition at Runtime.,"No. The abstract discusses fuzzing, a technique for detecting software vulnerabilities, which is not directly related to adversarial machine learning or attacks on machine learning models."
uss_2023_108,CarpetFuzz: Automatic Program Option Constraint Extraction from Documentation for Fuzzing.,"No. The abstract is related to improving a fuzzing technique for software vulnerability detection using NLP to analyze program options, but it does not discuss adversarial machine learning or techniques intended to manipulate or deceive machine learning models."
uss_2023_109,SCARF - A Low-Latency Block Cipher for Secure Cache-Randomization.,"No, the abstract is related to microarchitecture security via randomized cache design rather than adversarial machine learning, which involves manipulating machine learning models or their inputs."
uss_2023_110,The Gates of Time: Improving Cache Attacks with Transient Execution.,"No. The given abstract is focused on cache attacks and transient-execution attacks in computer security, but it does not discuss manipulating or attacking machine learning models, which is essential for AML."
uss_2023_111,Synchronization Storage Channels (S2C): Timer-less Cache Side-Channel Attacks on the Apple M1 via Hardware Synchronization Instructions.,"No. The abstract is related to side-channel attacks on shared caches, not to adversarial machine learning, as it focuses on observing cache state changes rather than manipulating or attacking machine learning models."
uss_2023_112,ClepsydraCache - Preventing Cache Attacks with Time-Based Evictions.,"No, the abstract is not related to AML because it focuses on hardware-level defenses against microarchitectural CPU cache attacks, which are more related to computer architecture and security rather than machine learning."
uss_2023_113,CacheQL: Quantifying and Localizing Cache Side-Channel Vulnerabilities in Production Software.,"No. The abstract is related to cache side-channel attacks which focus on exploiting hardware vulnerabilities, rather than manipulating machine learning models."
uss_2023_114,InfinityGauntlet: Expose Smartphone Fingerprint Authentication to Brute-force Attack.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on threats and attacks specific to smartphone fingerprint authentication systems, such as presentation attacks and specific model vulnerabilities, rather than adversarial attacks or defenses targeting machine learning models."
uss_2023_115,A Study of Multi-Factor and Risk-Based Authentication Availability.,"No, the abstract is not related to AML because it focuses on the availability and prevalence of authentication methods like MFA, RBA, and SSO, rather than any adversarial machine learning attacks or defenses related to manipulating or understanding machine learning systems."
uss_2023_116,A Large-Scale Measurement of Website Login Policies.,"No. The abstract discusses evaluating and understanding website login policies and their security implications, rather than focusing on adversarial tactics or defenses in a machine learning context."
uss_2023_117,Security and Privacy Failures in Popular 2FA Apps.,"No. The abstract focuses on the security and privacy analyses of backup mechanisms in TOTP apps, which are not related to adversarial machine learning attacks or defenses."
uss_2023_118,"Multi-Factor Key Derivation Function (MFKDF) for Fast, Flexible, Secure, & Practical Key Management.","No, this abstract is not related to AML as it focuses on improving key derivation functions for cryptographic security, rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2023_119,"Log: It's Big, It's Heavy, It's Filled with Personal Data! Measuring the Logging of Sensitive Information in the Android Ecosystem.",No. The given abstract discusses the logging policy and security mechanisms in Android regarding system logs and does not relate to adversarial techniques or vulnerabilities specific to machine learning systems.
uss_2023_120,CodexLeaks: Privacy Leaks from Code Generation Language Models in GitHub Copilot.,"Yes, the abstract is related to AML because it discusses the potential issue of models inadvertently exposing sensitive personal information from the training data, which is a concern in adversarial settings related to inference attacks."
uss_2023_121,Freaky Leaky SMS: Extracting User Locations by Analyzing SMS Timings.,"Yes, the abstract is related to AML because it describes the use of a machine learning model to perform an inference attack, inferring the location of an SMS recipient based on timing data, which is a characteristic of adversarial machine learning."
uss_2023_122,The Writing on the Wall and 3D Digital Twins: Personal Information in (not so) Private Real Estate.,"No. The abstract is not related to AML as it focuses on the privacy implications of 3D virtual tours in online real estate, rather than discussing attacks or defenses related to machine learning systems."
uss_2023_123,Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models.,"Yes. The abstract describes the use of ""style cloaks"" to apply perturbations on training data, which is a form of adversarial defense against style-mimicking attacks by generative models, making it related to adversarial machine learning."
uss_2023_124,Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants.,"No, the abstract is not related to AML. It focuses on the impact of LLM-assisted coding on software security, rather than describing adversarial attacks or defenses on machine learning models."
uss_2023_125,Two-in-One: A Model Hijacking Attack Against Text Generation Models.,"Yes. The abstract discusses a new model hijacking attack in machine learning, which falls under the broader category of adversarial machine learning by manipulating text classification and generation models."
uss_2023_126,PTW: Pivotal Tuning Watermarking for Pre-Trained Image Generators.,"Yes, the abstract is related to AML because it discusses both the creation and detection of deepfakes, including the security implication of watermarking as a defense mechanism against adversarial white-box attacks."
uss_2023_127,Lessons Lost: Incident Response in the Age of Cyber Insurance and Breach Attorneys.,"No. The abstract is focused on the impacts of cyber insurance and legal influence on incident response processes, rather than discussing adversarial machine learning or related attacks on machine learning systems."
uss_2023_128,Bug Hunters' Perspectives on the Challenges and Benefits of the Bug Bounty Ecosystem.,"No, the abstract is not related to AML. It focuses on understanding the perspectives and motivations of bug hunters in the bug-bounty ecosystem, which is unrelated to adversarial attacks or machine learning systems."
uss_2023_129,Work-From-Home and COVID-19: Trajectories of Endpoint Security Management in a Security Operations Center.,"No. The abstract discusses the impact of increased WFH practices on endpoint security monitoring and the management challenges faced by Security Operations Centers (SOCs), but it does not address adversarial attacks or defenses in machine learning systems."
uss_2023_130,"""Employees Who Don't Accept the Time Security Takes Are Not Aware Enough"": The CISO View of Human-Centred Security.","No, the abstract is not related to Adversarial Machine Learning, as it focuses on the role of Chief Information Security Officers (CISOs) in human-centered security and does not discuss any form of adversarial attacks or defenses related to machine learning systems."
uss_2023_131,Aegis: Mitigating Targeted Bit-flip Attacks against Deep Neural Networks.,"Yes. The abstract discusses bit-flip attacks and defenses in the context of deep neural networks, which are a type of adversarial attack aimed at compromising machine learning models, thus it is related to adversarial machine learning (AML)."
uss_2023_132,Rethinking White-Box Watermarks on Deep Learning Models under Neural Structural Obfuscation.,"No. The abstract focuses on DNN watermarking for copyright protection and securing model ownership, rather than discussing attacks or countermeasures specific to adversarial manipulation or threats."
uss_2023_133,PELICAN: Exploiting Backdoors of Naturally Trained Deep Learning Models In Binary Code Analysis.,"Yes. The abstract is related to AML as it discusses exploiting backdoor vulnerabilities in deep learning models used for binary analysis to induce misclassification, aligning with adversarial attack concepts."
uss_2023_134,IvySyn: Automated Vulnerability Discovery in Deep Learning Frameworks.,"Yes, the abstract is related to AML as it discusses the discovery and exploitation of memory error vulnerabilities in Deep Learning frameworks, which could be leveraged by attackers in adversarial settings."
uss_2023_135,"Hey Kimya, Is My Smart Speaker Spying on Me? Taking Control of Sensor Privacy Through Isolation and Amnesia.","No, the abstract is not related to AML. It focuses on a framework for ensuring data privacy and accountability in devices with event-triggered sensors, without discussing adversarial attacks or defenses involving machine learning."
uss_2023_136,Spying through Your Voice Assistants: Realistic Voice Command Fingerprinting.,"Yes. The abstract is related to AML because it involves analyzing and fingerprinting encrypted traffic to infer user activities, which can pose privacy and security risks, akin to an inference attack on machine learning-enhanced voice assistants."
uss_2023_137,QFA2SR: Query-Free Adversarial Transfer Attacks to Speaker Recognition Systems.,"Yes. The abstract describes an adversarial attack method, QFA2SR, aimed at exploiting speaker recognition systems by leveraging the transferability of adversarial voices, which is directly related to adversarial machine learning."
uss_2023_138,Learning Normality is Enough: A Software-based Mitigation against Inaudible Voice Attacks.,"Yes. The abstract is related to AML as it focuses on detecting inaudible voice attacks, which manipulate inputs to compromise machine learning systems in voice-controlled devices, aligning with the notion of adversarial attacks in AML."
uss_2023_139,Powering for Privacy: Improving User Trust in Smart Speaker Microphones with Intentional Powering and Perceptible Assurance.,"No. The abstract focuses on physical privacy features and perceptible assurance in smart speakers, without addressing adversarial attacks or defenses in machine learning systems."
uss_2023_140,"To Cloud or not to Cloud: A Qualitative Study on Self-Hosters' Motivation, Operation, and Security Mindset.","No. The abstract focuses on the behaviors and challenges of self-hosting services, particularly in terms of data security and operations, without discussing any adversarial machine learning concepts or attacks."
uss_2023_141,"""I wouldn't want my unsafe code to run my pacemaker"": An Interview Study on the Use, Comprehension, and Perceived Risks of Unsafe Rust.","No, the given abstract is not related to Adversarial Machine Learning (AML). The abstract focuses on memory safety issues and security vulnerabilities in the Rust programming language, rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2023_142,Pushed by Accident: A Mixed-Methods Study on Strategies of Handling Secret Information in Source Code Repositories.,"No, the abstract is not related to AML. It focuses on secure code secret management in version control systems and does not address adversarial attacks or defenses related to machine learning models."
uss_2023_143,A Mixed-Methods Study of Security Practices of Smart Contract Developers.,No. The abstract focuses on the security perceptions and practices of smart contract developers and does not discuss adversarial attacks or defenses related to machine learning systems.
uss_2023_144,The Role of Professional Product Reviewers in Evaluating Security and Privacy.,"No. The abstract is not related to Adversarial Machine Learning as it focuses on evaluating consumer product security and privacy by professional reviewers, rather than discussing attacks or defenses on machine learning models."
uss_2023_145,Network Responses to Russia's Invasion of Ukraine in 2022: A Cautionary Tale for Internet Freedom.,"No, the abstract is unrelated to Adversarial Machine Learning (AML) as it discusses geopolitical events, sanctions, and Internet freedom, rather than any specific adversarial attacks or defenses in the context of machine learning systems."
uss_2023_146,A Study of China's Censorship and Its Evasion Through the Lens of Online Gaming.,"Yes, the abstract is related to AML as it discusses evasion techniques used by young online gamers to bypass addiction prevention systems, which aligns with the evasion attack type in adversarial machine learning."
uss_2023_147,DeResistor: Toward Detection-Resistant Probing for Evasion of Internet Censorship.,"No. The abstract is about censorship evasion and detection in internet communication, which relates to network security and privacy rather than adversarial machine learning."
uss_2023_148,Timeless Timing Attacks and Preload Defenses in Tor's DNS Cache.,"No. The abstract is related to a timing attack on the Tor network's DNS cache and does not involve machine learning systems, adversarial attacks on ML models, or defenses related to AML."
uss_2023_149,How the Great Firewall of China Detects and Blocks Fully Encrypted Traffic.,"No, the abstract is not related to AML. It focuses on censorship circumvention and detection by the Great Firewall of China, which is not directly connected to adversarial attacks or defenses on machine learning models."
uss_2023_150,A Data-free Backdoor Injection Approach in Neural Networks.,"Yes, the abstract is related to AML as it discusses a novel backdoor attack method on deep neural networks, focusing on embedding backdoors efficiently using substitute data, which influences the modelâs behavior intentionally."
uss_2023_151,Sparsity Brings Vulnerabilities: Exploring New Metrics in Backdoor Attacks.,"Yes, the abstract is related to AML as it discusses a clean-label backdoor attack exploiting vulnerabilities in AI-based malware detectors."
uss_2023_152,Aliasing Backdoor Attacks on Pre-trained Models.,"Yes, the abstract is related to AML because it discusses a novel backdoor attack that exploits aliasing errors in neural networks to manipulate model predictions, which aligns with the notion of adversarial machine learning."
uss_2023_153,ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms.,"Yes. The abstract discusses methods for detecting backdoor data in various learning settings, which is directly related to adversarial machine learning as backdoor attacks are a form of adversarial attack."
uss_2023_154,VILLAIN: Backdoor Attacks Against Vertical Split Learning.,"Yes, the abstract is related to AML as it discusses the use of backdoor attacks in vertical split learning, which is a type of adversarial attack aimed at manipulating machine learning models."
uss_2023_155,ARI: Attestation of Real-time Mission Execution Integrity.,"No. The abstract focuses on remote attestation for verifying the integrity of cyber-physical systems, rather than addressing adversarial machine learning attacks or defenses in the context of autonomous systems."
uss_2023_156,Design of Access Control Mechanisms in Systems-on-Chip with Formal Integrity Guarantees.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on formal verification methodologies for system-on-chip (SoC) hardware access control systems, rather than machine learning models or adversarial attacks on them."
uss_2023_157,HashTag: Hash-based Integrity Protection for Tagged Architectures.,"No, the abstract is not related to AML because it focuses on enhancing error-correcting codes for data integrity in DRAM systems, rather than addressing adversarial attacks or defenses in machine learning models."
uss_2023_158,XCheck: Verifying Integrity of 3D Printed Patient-Specific Devices via Computing Tomography.,"No, the abstract is not related to AML since it does not discuss attacks or defenses specific to machine learning systems."
uss_2023_159,Demystifying Pointer Authentication on Apple M1.,"No, the given abstract is not related to AML. It focuses on hardware-level security through pointer authentication rather than adversarial attacks or defenses on machine learning systems."
uss_2023_160,DDRace: Finding Concurrency UAF Vulnerabilities in Linux Drivers with Directed Fuzzing.,"No, the abstract is focused on discovering concurrency use-after-free vulnerabilities in Linux drivers using greybox fuzzing, which is more related to software security and testing rather than adversarial machine learning."
uss_2023_161,Automata-Guided Control-Flow-Sensitive Fuzz Driver Generation.,"No. The abstract is about generating fuzz drivers for fuzzing library APIs, which is related to software testing, not adversarial machine learning."
uss_2023_162,Hoedur: Embedded Firmware Fuzzing using Multi-Stream Inputs.,"No. The abstract is related to security and vulnerability analysis in embedded systems rather than adversarial machine learning, as it focuses on the use of fuzzing for vulnerability assessments, not on manipulating machine learning models."
uss_2023_163,Forming Faster Firmware Fuzzers.,"No. The abstract focuses on rehosting and fuzzing for security vulnerability analysis in embedded systems, which is not specifically related to adversarial machine learning."
uss_2023_164,ReUSB: Replay-Guided USB Driver Fuzzing.,"No. The abstract discusses vulnerabilities in USB drivers and the use of fuzzing techniques to find them, which is more related to software security and testing, rather than adversarial machine learning or attacks on machine learning systems."
uss_2023_165,"Exorcising ""Wraith"": Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks.","Yes, the abstract is related to AML as it discusses adversarial attacks on automated driving systems that exploit weaknesses in 3D object detectors by crafting fake obstacles, which is a common topic in adversarial machine learning."
uss_2023_166,Discovering Adversarial Driving Maneuvers against Autonomous Vehicles.,"Yes, the abstract is related to AML because it describes the development of a framework, Acero, that discovers adversarial maneuvers targeting autonomous vehicle systems to exploit vulnerabilities, which relates to adversarial machine learning attacks."
uss_2023_167,Understand Users' Privacy Perception and Decision of V2X Communication in Connected Autonomous Vehicles.,"No, the abstract is not related to AML. It focuses on privacy perceptions and data-sharing decisions of drivers in connected autonomous vehicles rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2023_168,You Can't See Me: Physical Removal Attacks on LiDAR-based Autonomous Vehicles Driving Frameworks.,"Yes, the abstract is related to AML because it describes a physical attack on LiDAR-based object detection systems in autonomous vehicles that manipulates input data to deceive perception models, which is a form of adversarial attack. "
uss_2023_169,PatchVerif: Discovering Faulty Patches in Robotic Vehicles.,No. The abstract focuses on identifying faulty software patches in robotic vehicles rather than exploring adversarial attacks or defenses in a machine learning context.
uss_2023_170,Fast IDentity Online with Anonymous Credentials (FIDO-AC).,"No, this abstract is not related to AML because it focuses on improving the authentication process in web environments using cryptographic and biometric methods, without discussing adversarial attacks or defenses on machine learning systems."
uss_2023_171,How to Bind Anonymous Credentials to Humans.,"No, the abstract is not related to AML because it focuses on privacy-preserving digital credentials and authentication mechanisms, without mentioning machine learning or adversarial attacks."
uss_2023_172,Inducing Authentication Failures to Bypass Credit Card PINs.,"No, the abstract is not related to AML. It discusses integrity checks in credit card transactions and cryptographic mechanisms, but it does not involve machine learning systems or adversarial attacks on them."
uss_2023_173,An Empirical Study & Evaluation of Modern CAPTCHAs.,"No. The abstract discusses the development and analysis of CAPTCHAS for user verification and not manipulating machine learning models or their inputs, which is central to adversarial machine learning."
uss_2023_174,Account Verification on Social Media: User Perceptions and Paid Enrollment.,"No. The abstract focuses on user perceptions and changes in social media account verification practices, specifically on Twitter, and does not involve adversarial machine learning or attacks on ML systems."
uss_2023_175,User Awareness and Behaviors Concerning Encrypted DNS Settings in Web Browsers.,"No, the abstract is not related to AML. It focuses on encryption and privacy issues in DNS configurations, rather than adversarial methods or attacks on machine learning systems."
uss_2023_176,Two Sides of the Shield: Understanding Protective DNS adoption factors.,No. The abstract is related to the adoption of Protective DNS (PDNS) for filtering harmful DNS requests and does not discuss adversarial attacks or defenses in machine learning systems.
uss_2023_177,The Maginot Line: Attacking the Boundary of DNS Caching Protection.,"No. The abstract describes a cache poisoning attack specific to DNS servers, which is more related to network security rather than adversarial machine learning, as it does not involve manipulating machine learning model inputs or behavior."
uss_2023_178,Fourteen Years in the Life: A Root Server's Perspective on DNS Resolver Security.,"No, the abstract is unrelated to AML because it focuses on the adoption of security and privacy mechanisms in DNS, which is more relevant to internet security rather than adversarial attacks or machine learning systems."
uss_2023_179,NRDelegationAttack: Complexity DDoS attack on DNS Recursive Resolvers.,"No. The abstract describes a distributed denial-of-service (DDoS) attack targeting DNS resolvers, which is a network security issue rather than an adversarial machine learning attack."
uss_2023_180,Inductive Graph Unlearning.,No. The abstract is primarily focused on machine unlearning techniques and frameworks for graph data rather than on adversarial machine learning attacks or defenses.
uss_2023_181,GAP: Differentially Private Graph Neural Networks with Aggregation Perturbation.,"No, the abstract is not related to AML as it focuses on developing a differentially private GNN technique to protect data privacy, rather than discussing or addressing adversarial attacks or defenses."
uss_2023_182,PrivGraph: Differentially Private Graph Data Publication by Exploiting Community Information.,"No. The abstract focuses on privacy-preserving graph synthesis using differential privacy, which is more related to data privacy rather than adversarial machine learning."
uss_2023_183,On the Security Risks of Knowledge Graph Reasoning.,"Yes. The abstract is related to AML as it highlights potential security risks in knowledge graph reasoning, which could involve adversarial manipulation or attacks in security-critical domains."
uss_2023_184,The Case for Learned Provenance Graph Storage Systems.,"No, the abstract is not related to AML because it focuses on using DNNs for improving storage and query efficiency of provenance graphs rather than discussing any adversarial attacks or defenses related to machine learning systems."
uss_2023_185,A Large Scale Study of the Ethereum Arbitrage Ecosystem.,"No. The abstract is related to decentralized exchanges and arbitrage in blockchain systems, which do not involve or address adversarial attacks in machine learning systems."
uss_2023_186,ACon 2 : Adaptive Conformal Consensus for Provable Blockchain Oracles.,"No, the abstract is not related to AML because it focuses on addressing the oracle problem in blockchain systems using an adaptive conformal consensus algorithm, which is about achieving data consistency and security in smart contracts rather than adversarially attacking or defending machine learning models."
uss_2023_187,Snapping Snap Sync: Practical Attacks on Go Ethereum Synchronising Nodes.,"No, the abstract is not related to AML because it focuses on blockchain network attacks and consensus mechanisms, rather than attacks or defenses involving machine learning systems."
uss_2023_188,"Token Spammers, Rug Pulls, and Sniper Bots: An Analysis of the Ecosystem of Tokens in Ethereum and in the Binance Smart Chain (BNB).","No; the abstract focuses on analyzing blockchain tokens and liquidity pools, and the prevalence of rug pull scams, rather than adversarial attacks or defenses in machine learning systems."
uss_2023_189,Automated Inference on Financial Security of Ethereum Smart Contracts.,"No, this abstract is not related to AML because it focuses on analyzing and verifying the financial security of Ethereum smart contracts rather than discussing adversarial attacks or defenses on machine learning models."
uss_2023_190,LibScan: Towards More Precise Third-Party Library Identification for Android Applications.,"No, the abstract is not related to AML. It focuses on detecting third-party libraries in Android apps that may be vulnerable or malicious, rather than discussing adversarial attacks or defenses specific to machine learning models."
uss_2023_191,Union under Duress: Understanding Hazards of Duplicate Resource Mismediation in Android Software Supply Chain.,"No. The abstract is focused on the security risks posed by third-party libraries in the Android software supply chain, not on adversarial attacks or defenses in the context of machine learning systems."
uss_2023_192,UVSCAN: Detecting Third-Party Component Usage Violations in IoT Firmware.,"No, the abstract is related to detecting vulnerabilities in third-party component integrations in IoT firmware, which is a security issue but not specifically related to adversarial machine learning."
uss_2023_193,Beyond Typosquatting: An In-depth Look at Package Confusion.,"No. The abstract is related to supply chain security and package confusion incidents, which deal with misleading package imports rather than directly involving adversarial attacks or manipulations specific to machine learning models."
uss_2023_194,SandDriller: A Fully-Automated Approach for Testing Language-Based JavaScript Sandboxes.,"No. This abstract is related to detecting security vulnerabilities in language-based sandboxes for JavaScript code, which is a focus on software security but not specifically on adversarial machine learning attacks or defenses."
uss_2023_195,Instructions Unclear: Undefined Behaviour in Cellular Network Specifications.,No. The abstract is focused on the underspecification and potential security vulnerabilities in cellular network specifications rather than discussing adversarial attacks or defenses on machine learning models.
uss_2023_196,MobileAtlas: Geographically Decoupled Measurements in Cellular Networks for Security and Privacy Research.,"No. The abstract is focused on the study of cellular networks and their privacy and security in the context of roaming, without mentioning machine learning systems or adversarial attacks."
uss_2023_197,Eavesdropping Mobile App Activity via Radio-Frequency Energy Harvesting.,"Yes, the abstract is related to AML because it describes a novel side-channel attack that uses RF energy harvesting signals to infer mobile app activities, which involves manipulating inputs to extract sensitive information from a system."
uss_2023_198,Sherlock on Specs: Building LTE Conformance Tests through Automated Reasoning.,"No, this abstract is not related to AML. It focuses on developing automated conformance test generation for security requirements in carrier network systems, rather than adversarial attacks or defenses on machine learning models."
uss_2023_199,BASECOMP: A Comparative Analysis for Integrity Protection in Cellular Baseband Software.,"No, this abstract is unrelated to AML because it focuses on baseband software analysis for detecting implementation bugs and integrity protection in cellular communication, which does not involve adversarial attacks or defenses on machine learning models."
uss_2023_200,Investigating Verification Behavior and Perceptions of Visual Digital Certificates.,"No. The abstract is about the perception and verification of visual digital certificates with QR codes, which is not related to adversarial machine learning or attacks on ML systems."
uss_2023_201,"""My Privacy for their Security"": Employees' Privacy Perspectives and Expectations when using Enterprise Security Software.","No. The abstract is focused on exploring the privacy implications and perceptions of data collection by Enterprise Security Software, which does not involve adversarial attacks or defenses in machine learning systems."
uss_2023_202,"Account Security Interfaces: Important, Unintuitive, and Untrustworthy.",No. The abstract is about user-facing interfaces for displaying account security information and does not discuss any adversarial attacks or defenses on machine learning systems.
uss_2023_203,"Defining ""Broken"": User Experiences and Remediation Tactics When Ad-Blocking or Tracking-Protection Tools Break a Website's User Experience.","No, the abstract is not related to AML. It focuses on user experiences with ad-blocking tools and their effects on web page functionality, without discussing any adversarial attacks, defenses, or manipulation of machine learning systems."
uss_2023_204,Cryptographic Deniability: A Multi-perspective Study of User Perceptions and Expectations.,"No, the given abstract is not related to AML as it deals with the concept of cryptographic deniability and its social and legal implications rather than adversarial attacks or defenses within machine learning systems."
uss_2023_205,Silent Bugs Matter: A Study of Compiler-Introduced Security Bugs.,"No, the abstract is not related to AML. It discusses security bugs introduced by compilers due to semantic assumptions and language specifications, but does not address adversarial machine learning or attacks on machine learning models."
uss_2023_206,A Bug's Life: Analyzing the Lifecycle and Mitigation Process of Content Security Policy Bugs.,"No. The abstract is focused on the challenges and complexities of maintaining Content Security Policy (CSP) for web security, specifically addressing cross-site scripting, rather than discussing adversarial attacks or defenses in machine learning models."
uss_2023_207,Remote Code Execution from SSTI in the Sandbox: Automatically Detecting and Exploiting Template Escape Bugs.,"No, the abstract is not related to Adversarial Machine Learning. It discusses server-side template injection (SSTI) and remote code execution (RCE), which are security concerns in web development, rather than machine learning model manipulation or defense."
uss_2023_208,Detecting API Post-Handling Bugs Using Code and Description in Patches.,"No, the given abstract is unrelated to Adversarial Machine Learning as it focuses on detecting API Post-Handling bugs using patches and does not address manipulating or defending machine learning models."
uss_2023_209,Place Your Locks Well: Understanding and Detecting Lock Misuse Bugs.,"No. The abstract is focused on detecting lock misuses in multi-threaded software systems and concurrency errors, which is unrelated to adversarial machine learning."
uss_2023_210,The Space of Adversarial Strategies.,"Yes. The abstract is related to AML as it discusses the characterization and evaluation of adversarial examples, which are intentionally crafted inputs designed to exploit machine learning models, and proposes new methods to analyze and assess their effectiveness."
uss_2023_211,"""Security is not my field, I'm a stats guy"": A Qualitative Root Cause Analysis of Barriers to Adversarial Machine Learning Defenses in Industry.","Yes. The abstract is related to AML as it discusses the challenges and barriers that organizations face in deploying adversarial machine learning defenses, highlighting the potential risks and issues associated with AML."
uss_2023_212,X-Adv: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection.,"Yes, the abstract is related to AML as it discusses the development and evaluation of adversarial attacks specifically targeting deep learning models used for X-ray security inspections, highlighting the threats posed in safety-critical scenarios."
uss_2023_213,SMACK: Semantically Meaningful Adversarial Audio Attack.,"Yes. The abstract is related to AML as it discusses creating adversarial audio attacks to manipulate speech and speaker recognition systems, representing a new method of evading defenses in machine learning systems."
uss_2023_214,URET: Universal Robustness Evaluation Toolkit (for Evasion).,"Yes. The abstract is related to AML as it discusses the development of a framework to generate adversarial inputs across various machine learning tasks and input types, addressing adversarial evasion attacks."
uss_2023_215,Authenticated private information retrieval.,"No. The abstract discusses protocols for authenticated private information retrieval, focusing on client-server interaction and data authenticity, without mentioning adversarial attacks or machine learning systems."
uss_2023_216,Don't be Dense: Efficient Keyword PIR for Sparse Databases.,"No, the abstract is not related to AML. It focuses on private information retrieval (PIR) techniques for querying sparse databases, which involves cryptographic methods rather than machine learning models or adversarial attacks."
uss_2023_217,GigaDORAM: Breaking the Billion Address Barrier.,"No, the given abstract is not related to AML. It focuses on designing a protocol for secure access to memory on untrusted servers, which is related to data privacy and security rather than adversarial machine learning."
uss_2023_218,One Server for the Price of Two: Simple and Fast Single-Server Private Information Retrieval.,"No, the abstract is not related to AML because it focuses on private information retrieval and secure communication, which are cryptographic concerns rather than adversarial attacks or defenses in the context of machine learning."
uss_2023_219,Duoram: A Bandwidth-Efficient Distributed ORAM for 2- and 3-Party Computation.,"No, the abstract describes a distributed ORAM protocol for secure multi-party computation, focusing on communication efficiency, which is not related to adversarial machine learning or its techniques."
uss_2023_220,A Peek into the Metaverse: Detecting 3D Model Clones in Mobile Games.,"No, the abstract is not related to AML because it focuses on the detection of 3D model cloning in mobile games, rather than adversarial manipulation or defense mechanisms within machine learning systems."
uss_2023_221,PATROL: Provable Defense against Adversarial Policy in Two-player Games.,"Yes. The abstract is related to AML because it discusses a new attack specifically designed against deep reinforcement learning, where an adversarial agent exploits the weaknesses of a victim agent."
uss_2023_222,The Blockchain Imitation Game.,"No. The abstract discusses automated and adversarial trading on blockchains and the issue of front-running, which is more related to financial trading strategies and blockchain transparency rather than adversarial machine learning."
uss_2023_223,It's all in your head(set): Side-channel attacks on AR/VR systems.,"No, the abstract is not related to AML. It discusses side-channel attacks on AR/VR systems which exploit software vulnerabilities rather than manipulating machine learning models or their inputs."
uss_2023_224,Egg Hunt in Tesla Infotainment: A First Look at Reverse Engineering of Qt Binaries.,"No, the abstract is not related to AML because it focuses on reverse engineering and semantic symbol recovery in Qt binaries, rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2023_225,Reusable Enclaves for Confidential Serverless Computing.,"No. The abstract is focused on improving the performance and security of confidential serverless computing through the use of enclaves, and it does not discuss adversarial attacks or manipulations related to machine learning systems."
uss_2023_226,EnigMap: External-Memory Oblivious Map for Secure Enclaves.,"No. The abstract is focused on the use of secure enclaves to maintain privacy in data queries, which pertains to privacy and security rather than adversarial machine learning."
uss_2023_227,AEX-Notify: Thwarting Precise Single-Stepping Attacks through Interrupt Awareness for Intel SGX Enclaves.,"No, the abstract is related to side-channel attacks on Intel SGX and does not involve adversarial machine learning attacks or defenses focused on manipulating or understanding ML systems."
uss_2023_228,Controlled Data Races in Enclaves: Attacks and Detection.,"No. The abstract is not related to AML as it focuses on controlled data race attacks against Intel SGX, which involves security vulnerabilities in trusted execution environments rather than adversarial manipulations of machine learning models."
uss_2023_229,Guarding Serverless Applications with Kalium.,"No, the given abstract is related to serverless computing security rather than Adversarial Machine Learning. It focuses on enforcing control-flow integrity to mitigate attacks on serverless applications, without mentioning or addressing adversarial attacks on machine learning models."
uss_2023_230,"""To Do This Properly, You Need More Resources"": The Hidden Costs of Introducing Simulated Phishing Campaigns.","No, the given abstract is not related to AML. It focuses on phishing simulation campaigns for raising security awareness among employees rather than discussing attacks or defenses pertaining to adversarial machine learning."
uss_2023_231,You've Got Report: Measurement and Security Implications of DMARC Reporting.,"No, the abstract is not related to Adversarial Machine Learning as it primarily focuses on email security and mismanagement issues related to DMARC reporting, without discussing manipulation or exploitation of machine learning systems."
uss_2023_232,Knowledge Expansion and Counterfactual Interaction for Reference-Based Phishing Detection.,"No. The abstract focuses on phishing attacks and a reference-based detection method for identifying phishing webpages, but it does not explicitly address adversarial machine learning techniques or concepts."
uss_2023_233,Rods with Laser Beams: Understanding Browser Fingerprinting on Phishing Pages.,"No, the abstract is not related to AML. It focuses on phishing attacks and browser fingerprinting techniques used in social engineering, without mentioning any manipulation or strategies against machine learning systems specifically."
uss_2023_234,Content-Type: multipart/oracle - Tapping into Format Oracles in Email End-to-End Encryption.,"No, the abstract is not related to AML. It discusses format oracle attacks in the context of E2EE email settings, which are cryptographic vulnerabilities rather than specific adversarial attacks or defenses against machine learning systems."
uss_2023_235,PET: Prevent Discovered Errors from Being Triggered in the Linux Kernel.,"No. The abstract discusses a solution for preventing errors in the Linux kernel from being exploited before patches are available, but it does not involve machine learning or adversarial attacks on ML models."
uss_2023_236,A Hybrid Alias Analysis and Its Application to Global Variable Protection in the Linux Kernel.,"No. The abstract is discussing defense mechanisms for memory corruption attacks in the Linux kernel, which is more focused on system security rather than adversarial machine learning."
uss_2023_237,AlphaEXP: An Expert System for Identifying Security-Sensitive Kernel Objects.,"No. The abstract is focused on identifying and protecting sensitive objects in the Linux kernel from memory corruption vulnerabilities, which is related to system security rather than adversarial machine learning."
uss_2023_238,Mitigating Security Risks in Linux with KLAUS: A Method for Evaluating Patch Correctness.,"No, the abstract is not related to AML. It focuses on the evaluation of Linux kernel patches and improving patch quality rather than discussing adversarial attacks or defensive strategies in machine learning systems."
uss_2023_239,Detecting Union Type Confusion in Component Object Model.,"No, the abstract is not related to AML. It discusses type confusion vulnerabilities in Microsoft's Component Object Model, which is focused on software architecture and security, rather than machine learning or adversarial attacks."
uss_2023_240,Network Detection of Interactive SSH Impostors Using Deep Learning.,"No. The abstract focuses on detecting impostors using SSH by examining typing dynamics and packet sizes, which is more related to cybersecurity and anomaly detection rather than adversarial machine learning."
uss_2023_241,ARGUS: Context-Based Detection of Stealthy IoT Infiltration Attacks.,"No, the abstract is not related to AML because it focuses on detecting abnormal IoT device behaviors and lacks specific discussion on adversarial attacks or defenses targeting machine learning models."
uss_2023_242,Generative Intrusion Detection and Prevention on Data Stream.,"No, this abstract is not directly related to Adversarial Machine Learning as it focuses on developing a new streaming algorithm to detect frequent signatures for cybersecurity rather than discussing adversarial attacks or the manipulation of machine learning models."
uss_2023_243,xNIDS: Explaining Deep Learning-based Network Intrusion Detection Systems for Active Intrusion Responses.,"No, the abstract is not related to AML. It discusses the explainability and limitations of Deep Learning-based Network Intrusion Detection Systems, which is more about improving interpretability and performance rather than adversarial manipulation or defenses against attacks on machine learning models."
uss_2023_244,PROGRAPHER: An Anomaly Detection System based on Provenance Graph Embedding.,"No, the abstract is not related to AML. The focus is on Advanced Persistent Threats (APT) and data provenance for tracking and detecting attacks in computing environments, which does not specifically relate to manipulating or studying the behavior of machine learning models."
uss_2023_245,Dubhe: Succinct Zero-Knowledge Proofs for Standard AES and related Applications.,No. The abstract is related to zero-knowledge proofs (ZKP) and cryptographic proof systems rather than adversarial attacks or defenses in machine learning.
uss_2023_246,Curve Trees: Practical and Transparent Zero-Knowledge Accumulators.,"No. The abstract is related to cryptographic techniques for privacy in applications, dealing with zero-knowledge proofs, and does not address adversarial machine learning or attacks on ML systems."
uss_2023_247,BalanceProofs: Maintainable Vector Commitments with Fast Aggregation.,"No, the abstract is not related to AML. It focuses on vector commitments, improving update, proof aggregation, and verification times, which pertain to cryptographic efficiency rather than adversarial machine learning attacks or defenses."
uss_2023_248,zkSaaS: Zero-Knowledge SNARKs as a Service.,"No. The abstract is about zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs), which is a cryptographic concept and not related to adversarial machine learning."
uss_2023_249,VeriZexe: Decentralized Private Computation with Universal Setup.,"No, the abstract is not related to Adversarial Machine Learning. It discusses blockchain technology and decentralized private computation, focusing on scalability and privacy rather than adversarial attacks or defenses in machine learning."
uss_2023_250,Intender: Fuzzing Intent-Based Networking with Intent-State Transition Guidance.,"No, the abstract is not related to AML as it focuses on the security challenges and semantic bugs within Intent-based networking (IBN) systems and not on adversarial attacks or defenses pertaining to machine learning systems."
uss_2023_251,Bleem: Packet Sequence Oriented Fuzzing for Protocol Implementations.,No. The abstract focuses on vulnerability detection in network protocol implementations and does not mention machine learning models or adversarial attacks related to AML.
uss_2023_252,Automated Exploitable Heap Layout Generation for Heap Overflows Through Manipulation Distance-Guided Fuzzing.,"No. The abstract focuses on generating exploitable heap layouts for exploiting heap overflows, which is more related to software exploitation and security rather than adversarial machine learning."
uss_2023_253,MINER: A Hybrid Data-Driven Approach for REST API Fuzzing.,"No. The abstract describes a novel approach to REST API fuzzing to find errors and security bugs in cloud services, which does not involve adversarial machine learning or attacking or defending machine learning systems."
uss_2023_254,Systematic Assessment of Fuzzers using Mutation Analysis.,"No. The abstract is related to software testing and fuzzing techniques for discovering vulnerabilities, and does not mention adversarial attacks or manipulation against machine learning models."
uss_2023_255,HOMESPY: The Invisible Sniffer of Infrared Remote Control of Smart TVs.,No. The abstract focuses on the security of IR remote controls in IoT environments and does not involve manipulating or defending machine learning models.
uss_2023_256,Remote Attacks on Speech Recognition Systems Using Sound from Power Supply.,"Yes, the abstract is related to AML because it describes an attack on speech recognition systems that manipulates their inputs through power supply signals, highlighting a novel adversarial approach to compromising machine learning models in security contexts."
uss_2023_257,Near-Ultrasound Inaudible Trojan (Nuit): Exploiting Your Speaker to Attack Your Microphone.,"Yes, the abstract is related to AML because it discusses a new class of attacks on Voice Control Systems that manipulate inputs (voice commands) to exploit machine learning or voice processing systems, along with proposing a defense mechanism."
uss_2023_258,Medusa Attack: Exploring Security Hazards of In-App QR Code Scanning.,"Yes. The abstract is related to AML because it discusses the potential for attackers to exploit apps through malicious QR codes, which aligns with the concept of adversarial attacks in machine learning systems."
uss_2023_259,"Othered, Silenced and Scapegoated: Understanding the Situated Security of Marginalised Populations in Lebanon.",No. The abstract focuses on the digital security experiences of marginalized populations in Lebanon and does not discuss adversarial machine learning or attacks on machine learning systems.
uss_2023_260,Examining Power Dynamics and User Privacy in Smart Technology Use Among Jordanian Households.,"No. The abstract discusses privacy concerns and power dynamics related to smart technologies and domestic workers, but does not address adversarial attacks or defenses in machine learning systems."
uss_2023_261,"""If sighted people know, I should be able to know: "" Privacy Perceptions of Bystanders with Visual Impairments around Camera-based Technology.","No, the given abstract is not related to AML because it focuses on the privacy concerns and perceptions of visually impaired individuals regarding camera usage, rather than any interaction with or manipulation of machine learning models."
uss_2023_262,A Research Framework and Initial Study of Browser Security for the Visually Impaired.,"No. The abstract focuses on improving security warnings for visually impaired users in web browsers, which is unrelated to adversarial machine learning."
uss_2023_263,ELASM: Error-Latency-Aware Scale Management for Fully Homomorphic Encryption.,"No, this abstract is not related to AML because it discusses privacy-preserving machine learning using homomorphic encryption techniques, which is focused on data privacy rather than adversarial attacks or defenses on machine learning models."
uss_2023_264,HECO: Fully Homomorphic Encryption Compiler.,"No. The abstract is related to Fully Homomorphic Encryption (FHE) and focuses on the development and optimization of FHE applications, which is distinct from adversarial machine learning and does not involve manipulation or testing of machine learning systems."
uss_2023_265,A Verified Confidential Computing as a Service Framework for Privacy Preservation.,"No, the abstract is not related to Adversarial Machine Learning (AML) as it focuses on using Trusted Execution Environments (TEEs) for privacy and security in cloud computing, without mention of machine learning models or adversarial attacks."
uss_2023_266,CSHER: A System for Compact Storage with HE-Retrieval.,"No, the abstract is not related to AML, as it focuses on optimizing storage solutions for homomorphic encryption rather than any specific adversarial attacks or defenses in machine learning systems."
uss_2023_267,Precise and Generalized Robustness Certification for Neural Networks.,"Yes. The abstract discusses neural network robustness certification against semantic-level mutations, which is related to adversarial machine learning as it involves certifying the model's resistance to specific adversarial input changes."
uss_2023_268,DiffSmooth: Certifiably Robust Learning via Diffusion Models and Local Smoothing.,"Yes, the abstract is related to AML because it discusses the use of diffusion models for adversarial purification and improving certified robustness, which are key aspects of defending against adversarial attacks in machine learning."
uss_2023_269,ACORN: Input Validation for Secure Aggregation.,"Yes, the abstract is related to AML as it discusses methods to prevent malicious clients from disproportionately influencing aggregate statistics or machine learning models, which aligns with the concept of defending against adversarial attacks like data poisoning."
uss_2023_270,HOLMES: Efficient Distribution Testing for Secure Collaborative Learning.,"No. The abstract focuses on secure multiparty computation for collaborative machine learning without revealing data, and addresses legal and regulatory concerns, rather than discussing adversarial attacks or defenses on machine learning models."
uss_2023_271,"Keep Your Friends Close, but Your Routeservers Closer: Insights into RPKI Validation in the Internet.","No, the abstract is not related to Adversarial Machine Learning because it focuses on network security regarding IP prefix hijacking and the deployment of RPKI to secure BGP routing, rather than adversarial tactics or defenses in machine learning systems."
uss_2023_272,Exploring the Unknown DTLS Universe: Analysis of the DTLS Server Ecosystem on the Internet.,"No. The abstract is focused on the security guarantees and potential vulnerabilities of the DTLS protocol compared to TLS, without mentioning or addressing adversarial attacks or defenses specific to machine learning systems."
uss_2023_273,We Really Need to Talk About Session Tickets: A Large-Scale Analysis of Cryptographic Dangers with TLS Session Tickets.,No. The abstract discusses the use of session tickets to improve the performance of the TLS protocol but does not mention any adversarial machine learning techniques or attacks.
uss_2023_274,Extended Hell(o): A Comprehensive Large-Scale Study on Email Confidentiality and Integrity Mechanisms in the Wild.,"No, the given abstract is not related to AML. It focuses on the security measures and configurations of email protocols, rather than adversarial attacks or defenses in machine learning systems."
uss_2023_275,"No Linux, No Problem: Fast and Correct Windows Binary Fuzzing via Target-embedded Snapshotting.",No. The abstract focuses on improving fuzzing techniques for software security vulnerabilities and does not relate to adversarial attacks or defenses against machine learning models.
uss_2023_276,DAFL: Directed Grey-box Fuzzing guided by Data Dependency.,"No, the abstract is not related to AML because it focuses on directed grey-box fuzzing techniques for software testing and bug discovery, which is different from adversarial attacks or defenses on machine learning models."
uss_2023_277,DynSQL: Stateful Fuzzing for Database Management Systems with Complex and Valid SQL Query Generation.,"No, the abstract is not related to AML. It discusses using fuzzing techniques to test database management systems for bugs, without mentioning any adversarial techniques or machine learning systems."
uss_2023_278,AIFORE: Smart Fuzzing Based on Automatic Input Format Reverse Engineering.,"No. The abstract is focused on automated input format reverse engineering and smart fuzzing for program analysis, not on adversarial attacks or defenses related to machine learning."
uss_2023_279,BoKASAN: Binary-only Kernel Address Sanitizer for Effective Kernel Fuzzing.,"No, the abstract is not related to AML. It discusses Kernel Address Sanitizer (KASAN) and techniques for finding software bugs, which is more related to software security and debugging rather than adversarial attacks on machine learning systems."
uss_2023_280,ACTOR: Action-Guided Kernel Fuzzing.,"No. The abstract focuses on fuzzing techniques for finding bugs in software, which is a software testing approach, rather than discussing adversarial attacks or defenses related to machine learning systems."
uss_2023_281,FirmSolo: Enabling dynamic analysis of binary Linux-based IoT kernel modules.,"No. The abstract focuses on analyzing security vulnerabilities in Linux-based firmware for IoT devices, particularly in kernel space, rather than on adversarial attacks or defenses in machine learning systems."
uss_2023_282,KextFuzz: Fuzzing macOS Kernel EXTensions on Apple Silicon via Exploiting Mitigations.,"No, the abstract is not related to Adversarial Machine Learning (AML). It focuses on discovering kernel vulnerabilities in macOS drivers through a fuzzing approach rather than targeting or manipulating machine learning models."
uss_2023_283,Uncontained: Uncovering Container Confusion in the Linux Kernel.,"No, the abstract is not related to AML. It focuses on analyzing type confusion bugs in complex C projects and their impact on security, without discussing any aspect of adversarial machine learning."
uss_2023_284,"""I'm going to trust this until it burns me"" Parents' Privacy Concerns and Delegation of Trust in K-8 Educational Technology.","No, the abstract is not related to AML as it focuses on the privacy and security concerns surrounding the use of educational technologies rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2023_285,Educators' Perspectives of Using (or Not Using) Online Exam Proctoring.,"No. The abstract discusses educators' perspectives on remote exam proctoring and student privacy concerns, but it does not involve any manipulation or attack on machine learning systems."
uss_2023_286,No more Reviewer #2: Subverting Automatic Paper-Reviewer Assignment using Adversarial Learning.,Yes. The abstract is related to AML as it describes an attack on an automated paper-reviewer assignment system using adversarial learning to manipulate the paper's content to influence reviewer selection.
uss_2023_287,A Two-Decade Retrospective Analysis of a University's Vulnerability to Attacks Exploiting Reused Passwords.,"No, the abstract is not related to Adversarial Machine Learning (AML). It discusses vulnerabilities and analysis of credential-guessing attacks based on password reuse and data breaches, which are security issues but do not involve exploiting or manipulating machine learning systems."
uss_2023_288,Ethical Frameworks and Computer Security Trolley Problems: Foundations for Conversations.,"No. The abstract is centered around ethical considerations and moral philosophy in computer security research, rather than directly discussing adversarial machine learning or attacks on ML models."
uss_2023_289,Catch You and I Can: Revealing Source Voiceprint Against Voice Conversion.,"Yes, the abstract is related to AML because it addresses the challenge of uncovering the original speaker's features from audios manipulated through voice conversion, which aligns with the concept of adversarial attacks and defenses in machine learning."
uss_2023_290,"V-Cloak: Intelligibility-, Naturalness- & Timbre-Preserving Real-Time Voice Anonymization.","Yes. The abstract is related to AML as it discusses a voice anonymization system designed to protect against malicious adversaries who may attempt identity inference or identity theft, a concern closely tied to adversarial threats in machine learning systems."
uss_2023_291,Assessing Anonymity Techniques Employed in German Court Decisions: A De-Anonymization Experiment.,No. The abstract focuses on the anonymization techniques of court decisions and their vulnerabilities but does not involve any aspect of adversarial attacks or defenses on machine learning models.
uss_2023_292,Person Re-identification in 3D Space: A WiFi Vision-based Approach.,"No, the abstract is not related to Adversarial Machine Learning as it focuses on a WiFi vision-based system for person re-identification using deep learning, but does not discuss manipulating machine learning models or intentional malicious attacks."
uss_2023_293,In the Quest to Protect Users from Side-Channel Attacks - A User-Centred Design Space to Mitigate Thermal Attacks on Public Payment Terminals.,"No, the abstract is not related to AML because it focuses on thermal attacks, which are a type of side-channel attack, rather than attacks or defenses specifically targeting machine learning models."
uss_2023_294,Extracting Training Data from Diffusion Models.,"Yes. This abstract is related to AML because it explores how diffusion models can unintentionally memorize and reproduce training data, posing privacy concerns that an adversary could exploit."
uss_2023_295,PCAT: Functionality and Data Stealing from Split Learning by Pseudo-Client Attack.,"Yes. The abstract is related to AML because it describes a new type of attack (Pseudo-ClientATtack) on split learning systems to extract private data and model functionality without knowledge of the client's model, aligning with adversarial attack goals in machine learning."
uss_2023_296,A Plot is Worth a Thousand Words: Model Information Stealing Attacks via Scientific Plots.,"Yes, the abstract is related to AML because it describes a method for stealing confidential model information using scientific plots as a side channel, which can be used to perform further adversarial attacks."
uss_2023_297,Beyond The Gates: An Empirical Analysis of HTTP-Managed Password Stealers and Operators.,"No. The abstract focuses on analyzing the behavior and impact of commodity malware designed for credential theft, rather than specifically discussing adversarial attacks or defenses on machine learning systems."
uss_2023_298,LightThief: Your Optical Communication Information is Stolen behind the Wall.,"No. The abstract is related to a novel method of eavesdropping on Optical Wireless Communication through the conversion of optical signals to RF signals, but it does not involve manipulating or attacking machine learning systems or models."
uss_2023_299,WaterBear: Practical Asynchronous BFT Matching Security Guarantees of Partially Synchronous BFT.,"No. The abstract discusses Byzantine fault-tolerant protocols which are related to distributed systems and fault tolerance, not adversarial machine learning."
uss_2023_300,Practical Asynchronous High-threshold Distributed Key Generation and Distributed Polynomial Sampling.,"No, the abstract is not related to AML. It focuses on asynchronous distributed key generation for cryptographic protocols, which does not mention or involve machine learning or adversarial attacks and defenses."
uss_2023_301,Efficient 3PC for Binary Circuits with Application to Maliciously-Secure DNN Inference.,"No. The abstract focuses on improving the efficiency of a secure multi-party computation protocol, which is more relevant to cryptography and secure computing rather than adversarial machine learning."
uss_2023_302,TVA: A multi-party computation system for secure and expressive time series analytics.,"No, the abstract is not related to AML. It describes a secure multi-party computation system for analytics on time series data, focusing on privacy and efficiency, without mentioning adversarial attacks or manipulations in machine learning systems."
uss_2023_303,Long Live The Honey Badger: Robust Asynchronous DPSS and its Applications.,"No. The abstract focuses on secret sharing and fault tolerance in distributed applications, without mentioning adversarial attacks or defenses in machine learning systems."
uss_2023_304,Powering Privacy: On the Energy Demand and Feasibility of Anonymity Networks on Smartphones.,"No. The abstract is focused on anonymity networks and their practicality on smartphones, not on adversarial machine learning or attacks on machine learning models."
uss_2023_305,Eye-Shield: Real-Time Protection of Mobile Device Screen Information from Shoulder Surfing.,"No, the abstract is not related to AML. This is because the proposed Eye-Shield solution focuses on preventing shoulder surfing for mobile device screens and does not involve machine learning models or adversarial attacks."
uss_2023_306,The OK Is Not Enough: A Large Scale Study of Consent Dialogs in Smartphone Applications.,"No, the given abstract is not related to AML. It focuses on privacy consent dialogs and the use of dark patterns in mobile applications, which is more relevant to privacy and user consent issues rather than adversarial machine learning."
uss_2023_307,Notice the Imposter! A Study on User Tag Spoofing Attack in Mobile Apps.,"No, the given abstract is unrelated to AML. It discusses privacy issues related to user tag sharing and data labeling but does not mention adversarial attacks or machine learning systems."
uss_2023_308,Lost in Conversion: Exploit Data Structure Conversion with Attribute Loss to Break Android Systems.,"No, the abstract is related to vulnerabilities in Android's configuration files and privilege escalation, but it does not discuss adversarial machine learning or attacks on machine learning models."
uss_2023_309,Silent Spring: Prototype Pollution Leads to Remote Code Execution in Node.js.,"No, the given abstract is unrelated to Adversarial Machine Learning (AML) as it describes a security vulnerability specific to JavaScript and Node.js related to prototype pollution, without mentioning any machine learning systems or adversarial attacks on them."
uss_2023_310,Cookie Crumbles: Breaking and Fixing Web Session Integrity.,"No. This abstract focuses on web security vulnerabilities related to cookies and session integrity, which are not directly related to adversarial machine learning or attacks on ML models."
uss_2023_311,Minimalist: Semi-automated Debloating of PHP Web Applications through Static Analysis.,No. The abstract discusses web application debloating to reduce attack surfaces but does not mention adversarial attacks or defenses related to machine learning systems.
uss_2023_312,AnimateDead: Debloating Web Applications Using Concolic Execution.,"No. The abstract focuses on reducing code bloat in web applications and mentions security improvements from debloating, without discussing adversarial machine learning or its related attacks and defenses."
uss_2023_313,NAUTILUS: Automated RESTful API Vulnerability Detection.,"No. The abstract is focused on the limitations of blackbox vulnerability scanners in testing RESTful APIs, not on adversarial attacks or defenses related to machine learning systems."
uss_2023_314,"""Un-Equal Online Safety?"" A Gender Analysis of Security and Privacy Protection Advice and Behaviour Patterns.",No. The abstract focuses on the gender differences in engagement with security and privacy technologies rather than adversarial attacks or defenses related to machine learning systems.
uss_2023_315,"""Millions of people are watching you"": Understanding the Digital-Safety Needs and Practices of Creators.","No, the given abstract is not related to AML as it focuses on the digital-safety experiences and protective practices of online content creators, rather than exploring adversarial attacks or defenses against machine learning systems."
uss_2023_316,How Library IT Staff Navigate Privacy and Security Challenges and Responsibilities.,"No, the abstract is not related to Adversarial Machine Learning because it focuses on the privacy and security challenges faced by library IT staff, without discussing any aspects of machine learning models, adversarial attacks, or defenses."
uss_2023_317,Problematic Advertising and its Disparate Exposure on Facebook.,No. The abstract focuses on the distribution and perception of problematic online ads and does not discuss any manipulation or adversarial tactics against machine learning models.
uss_2023_318,One Size Does not Fit All: Quantifying the Risk of Malicious App Encounters for Different Android User Profiles.,"No, the given abstract is not related to AML as it focuses on analyzing malware risk across user profiles and not on manipulating or attacking machine learning models."
uss_2023_319,How Effective is Multiple-Vantage-Point Domain Control Validation?,No. The abstract is focused on BGP hijacks and domain control validation in the context of Web PKI and not on adversarial machine learning attacks or defenses.
uss_2023_320,Bypassing Tunnels: Leaking VPN Client Traffic by Abusing Routing Tables.,No. The abstract is focused on the security and privacy aspects of Virtual Private Networks (VPNs) rather than on adversarial attacks or defenses related to machine learning systems.
uss_2023_321,Back to School: On the (In)Security of Academic VPNs.,"No. The abstract focuses on evaluating the security aspects of VPN setups and configurations, which is not directly related to adversarial machine learning or attacks targeting machine learning systems."
uss_2023_322,FABRID: Flexible Attestation-Based Routing for Inter-Domain Networks.,"No, the abstract is unrelated to AML because it discusses network transparency and control issues without mentioning machine learning or adversarial attacks."
uss_2023_323,"""All of them claim to be the best"": Multi-perspective study of VPN users and VPN providers.","No, the abstract is not related to AML as it focuses on understanding VPN users' needs and trust issues rather than discussing manipulation or security vulnerabilities in machine learning systems."
uss_2023_324,Greenhouse: Single-Service Rehosting of Linux-Based Firmware Binaries in User-Space Emulation.,"No. The abstract discusses improving emulation fidelity for IoT device firmware analysis, rather than addressing adversarial machine learning techniques or attacks."
uss_2023_325,FuncTeller: How Well Does eFPGA Hide Functionality?,"No, the abstract is not related to AML because it focuses on attacks against hardware intellectual property using electronic design automation tools, rather than machine learning models or systems."
uss_2023_326,ACFA: Secure Runtime Auditing & Guaranteed Device Healing via Active Control Flow Attestation.,"No. The abstract focuses on security vulnerabilities in embedded devices and discusses Remote Attestation as a method to ensure binary integrity, rather than addressing adversarial attacks targeting machine learning models."
uss_2023_327,Fuzz The Power: Dual-role State Guided Black-box Fuzzing for USB Power Delivery.,"No. The abstract focuses on security concerns related to USB Power Delivery firmware vulnerabilities, not on adversarial attacks or defenses within machine learning systems."
uss_2023_328,The Impostor Among US(B): Off-Path Injection Attacks on USB Communications.,"No, the abstract is not related to AML because it discusses vulnerabilities and attacks related to USB communications at the hardware and protocol level, rather than addressing attacks or vulnerabilities specific to machine learning systems."
uss_2023_329,"A comprehensive, formal and automated analysis of the EDHOC protocol.","No. The abstract is related to the formal analysis of a key exchange protocol EDHOC for IoT communications, focusing on security verification rather than adversarial machine learning."
uss_2023_330,Hash Gone Bad: Automated discovery of protocol attacks that exploit hash function weaknesses.,"No. The abstract discusses the security of cryptographic hash functions and their use in cryptographic protocols, but it does not relate to adversarial attacks or the manipulation of machine learning systems."
uss_2023_331,How fast do you heal? A taxonomy for post-compromise security in secure-channel establishment.,"No. The abstract is focused on Post-Compromise Security (PCS) in secure-channel establishment schemes and their resilience, which is related to cryptography and secure communication rather than adversarial machine learning."
uss_2023_332,Automated Analysis of Protocols that use Authenticated Encryption: How Subtle AEAD Differences can impact Protocol Security.,"No, the given abstract is not related to AML. It focuses on the use of cryptographic primitives and security protocols, rather than discussing machine learning models, adversarial attacks, or defenses against such attacks."
uss_2023_333,High Recovery with Fewer Injections: Practical Binary Volumetric Injection Attacks against Dynamic Searchable Encryption.,"Yes. The abstract describes injection attacks that exploit information leakages in searchable symmetric encryption, which aligns with adversarial machine learning concepts by discussing how adversaries manipulate inputs to extract sensitive information."
uss_2023_334,Cross Container Attacks: The Bewildered eBPF on Clouds.,"No. The abstract is focused on security risks and attack surfaces associated with eBPF in container environments, rather than manipulating or extracting information from machine learning systems which is the focus of adversarial machine learning."
uss_2023_335,DScope: A Cloud-Native Internet Telescope.,"No. The abstract discusses a cloud-based Internet telescope designed for monitoring and analyzing network traffic, but it does not address machine learning systems or adversarial attacks, which are central to adversarial machine learning."
uss_2023_336,Credit Karma: Understanding Security Implications of Exposed Cloud Services through Automated Capability Inference.,"No. The abstract is focused on data security and over-privileged cloud credentials, which is related to cloud security vulnerabilities rather than adversarial attacks on machine learning models."
uss_2023_337,Detecting Multi-Step IAM Attacks in AWS Environments via Model Checking.,"No. The abstract discusses cloud services, security vulnerabilities, and the use of model checking for verification, but it does not address adversarial attacks or manipulations related to machine learning systems."
uss_2023_338,Remote Direct Memory Introspection.,"No, the abstract is not related to AML as it focuses on hypervisor offloading for cloud security and performance improvements, with no mention of adversarial attacks or defense mechanisms in machine learning systems."
uss_2023_339,Auditing Framework APIs via Inferred App-side Security Specifications.,"No. The abstract focuses on auditing access control implementations for Android private framework APIs, which pertains to security and privacy rather than adversarial attacks or defenses in machine learning systems."
uss_2023_340,WHIP: Improving Static Vulnerability Detection in Web Application by Forcing tools to Collaborate.,"No. The abstract focuses on improving static application security testing (SAST) to detect vulnerabilities in web applications, which is more related to traditional software security rather than adversarial machine learning."
uss_2023_341,SQIRL: Grey-Box Detection of SQL Injection Vulnerabilities Using Reinforcement Learning.,"No, the abstract is not related to AML. It discusses web security scanners and their limitations in detecting SQL injection vulnerabilities but does not involve manipulating machine learning models or adversarial techniques."
uss_2023_342,Hiding in Plain Sight: An Empirical Study of Web Application Abuse in Malware.,"No. The abstract is focused on detecting and analyzing web applications being abused by malware, rather than specifically addressing adversarial attacks or defenses on machine learning models."
uss_2023_343,Bilingual Problems: Studying the Security Risks Incurred by Native Extensions in Scripting Languages.,"No, the abstract is not related to AML. It discusses the security implications of using native extensions in scripting languages, which is a topic more related to software security rather than adversarial machine learning."
uss_2023_344,Did the Shark Eat the Watchdog in the NTP Pool? Deceiving the NTP Pool's Monitoring System.,"No. The abstract focuses on analyzing and enhancing the security of the NTP pool, not on adversarial attacks or defenses against machine learning systems."
uss_2023_345,Device Tracking via Linux's New TCP Source Port Selection Algorithm.,"No. This abstract describes a tracking technique exploiting a network protocol implementation for device identification, which is more related to security and privacy concerns rather than adversarial machine learning."
uss_2023_346,Temporal CDN-Convex Lens: A CDN-Assisted Practical Pulsing DDoS Attack.,"No, the abstract is not related to Adversarial Machine Learning (AML) because it discusses the exploitation of CDNs to compromise service availability, which is more related to network security rather than manipulating machine learning models."
uss_2023_347,An Efficient Design of Intelligent Network Data Plane.,"No. The abstract discusses enhancing intelligent network traffic analysis and model deployment efficiency, but it does not mention adversarial manipulations or threats specific to machine learning models."
uss_2023_348,Glowing in the Dark: Uncovering IPv6 Address Discovery and Scanning Strategies in the Wild.,No. The abstract is focused on identifying scanning strategies of IPv6 scanners on the Internet and does not involve machine learning or adversarial attacks related to it.
uss_2023_349,Oops..! I Glitched It Again! How to Multi-Glitch the Glitching-Protections on ARM TrustZone-M.,"No, the given abstract is not related to AML because it focuses on voltage fault injection attacks, which are more concerned with hardware security rather than manipulating machine learning models or their inputs."
uss_2023_350,SHELTER: Extending Arm CCA with Isolation in User Space.,"No, the abstract is not related to AML as it focuses on confidentiality and security issues related to TrustZone, rather than adversarial machine learning techniques or attacks on machine learning models."
uss_2023_351,"Hot Pixels: Frequency, Power, and Temperature Attacks on GPUs and Arm SoCs.","No. The abstract discusses side-channel attacks related to hardware and computing devices, not adversarial attacks or defenses within machine learning systems."
uss_2023_352,SpectrEM: Exploiting Electromagnetic Emanations During Transient Execution.,"No. This abstract is related to transient execution attacks exploiting physical side channels on processors, which is more relevant to cybersecurity and hardware security rather than adversarial machine learning."
uss_2023_353,ARMore: Pushing Love Back Into Binaries.,"No. The abstract is focused on static rewriting for the ARM architecture to improve software introspection and coverage analysis, without mentioning adversarial machine learning or related attacks/defenses."
uss_2023_354,Secure Floating-Point Training.,"No. The abstract is focused on enhancing secure two-party computation protocols for floating-point arithmetic in the context of deep learning, which relates more to cryptographic efficiency in ML rather than adversarial attacks or defenses."
uss_2023_355,NeuroPots: Realtime Proactive Defense against Bit-Flip Attacks in Neural Networks.,"Yes. The abstract discusses bit-flip attacks on deep neural networks, which are a form of adversarial attack, and presents a defense mechanism to detect and recover from such attacks, aligning with concepts in adversarial machine learning."
uss_2023_356,FedVal: Different good or different bad in federated learning.,"Yes, the abstract is related to AML as it addresses the susceptibility of federated learning systems to poisoning attacks and proposes a method to enhance robustness and fairness against these adversarial threats."
uss_2023_357,Gradient Obfuscation Gives a False Sense of Security in Federated Learning.,"Yes. The abstract is related to AML as it discusses reconstruction attacks on federated learning, highlighting vulnerabilities in privacy protection and proposing a new attack framework related to adversarial tactics."
uss_2023_358,FreeEagle: Detecting Complex Neural Trojans in Data-Free Cases.,"Yes. The abstract addresses a Trojan or backdoor attack on deep neural networks, which is a form of adversarial attack in the context of adversarial machine learning, as well as proposing a method for its detection."
uss_2023_359,Prime Match: A Privacy-Preserving Inventory Matching System.,"No, the abstract is related to financial trading and inventory matching in stock markets, not about machine learning or adversarial attacks."
uss_2023_360,Squirrel: A Scalable Secure Two-Party Computation Framework for Training Gradient Boosting Decision Tree.,"No, the abstract is not related to AML. It focuses on secure multi-party computation for privacy-preserving training of a Gradient Boosting Decision Tree, rather than adversarial attacks or defenses against machine learning models."
uss_2023_361,Eos: Efficient Private Delegation of zkSNARK Provers.,"No. The abstract focuses on cryptographic techniques for privacy protection, rather than addressing adversarial interactions with machine learning systems."
uss_2023_362,Machine-checking Multi-Round Proofs of Shuffle: Terelius-Wikstrom and Bayer-Groth.,"No, the abstract is not related to AML. It focuses on the security of electronic voting systems and the verification of proofs of shuffle, which is more relevant to cryptography and secure computation rather than adversarial machine learning."
uss_2023_363,TAP: Transparent and Privacy-Preserving Data Services.,"No. The abstract focuses on building a multi-user system for data privacy, integrity, and transparency, but it does not address any manipulation or security challenges specifically related to machine learning models."
uss_2023_364,Trojan Source: Invisible Vulnerabilities.,No. The abstract describes an attack exploiting text-encoding subtleties in source code for vulnerabilities but does not mention machine learning or adversarial manipulation of ML systems specifically.
uss_2023_365,Cheesecloth: Zero-Knowledge Proofs of Real World Vulnerabilities.,"No. This abstract discusses the dilemma faced by security analysts when disclosing software vulnerabilities, which is more related to cybersecurity and vulnerability management, not adversarial machine learning."
uss_2023_366,V1SCAN: Discovering 1-day Vulnerabilities in Reused C/C++ Open-source Software Components Using Code Classification Techniques.,"No, the abstract is not related to AML because it focuses on detecting vulnerabilities in open-source software components, rather than exploring or defending against adversarial attacks on machine learning models."
uss_2023_367,VulChecker: Graph-based Vulnerability Localization in Source Code.,"No, the abstract is not related to AML because it focuses on using deep learning for detecting code vulnerabilities without mention of adversarial threats or attacks targeting machine learning models."
uss_2023_368,DISTDET: A Cost-Effective Distributed Cyber Threat Detection System.,"No. The abstract describes a distributed detection system for Advanced Persistent Threat (APT) attacks using provenance graphs, but it does not specifically mention adversarial attacks or adversarial machine learning techniques."
uss_2023_369,Automated Security Analysis of Exposure Notification Systems.,"No. The abstract is focused on analyzing the security of exposure notification systems, which is more about public health data privacy than adversarial machine learning attacks or defenses."
uss_2023_370,Formal Analysis of SPDM: Security Protocol and Data Model version 1.2.,"No, the abstract is not related to AML as it focuses on standardizing a security protocol for securing communication and device attestation, without any mention of machine learning or adversarial attacks."
uss_2023_371,One Size Does Not Fit All: Uncovering and Exploiting Cross Platform Discrepant APIs in WeChat.,"No. The abstract focuses on identifying API discrepancies for platform fingerprinting in mobile and desktop apps, which targets application vulnerabilities rather than specific adversarial manipulations in machine learning models."
uss_2023_372,The Most Dangerous Codec in the World: Finding and Exploiting Vulnerabilities in H.264 Decoders.,"No. The abstract discusses security risks and vulnerabilities associated with video encoding standards, not adversarial machine learning or interactions with machine learning systems."
uss_2023_373,Are You Spying on Me? Large-Scale Analysis on IoT Data Exposure through Companion Apps.,"No. The abstract focuses on analyzing unauthorized data exposure and privacy implications in IoT devices and their companion apps, without discussing any manipulation or adversarial attacks on machine learning models."
uss_2023_374,Strategies and Vulnerabilities of Participants in Venezuelan Influence Operations.,"No, the abstract is not related to AML as it focuses on human participants in influence operations and their strategies on social media platforms, rather than on machine learning systems and adversarial attacks or defenses."
uss_2023_375,TRIDENT: Towards Detecting and Mitigating Web-based Social Engineering Attacks.,"No, the abstract is not related to AML. It focuses on detecting web-based social engineering attacks aimed at human users rather than adversarial attacks or defenses targeting machine learning systems."
uss_2023_376,Fact-Saboteurs: A Taxonomy of Evidence Manipulation Attacks against Fact-Verification Systems.,"Yes, the abstract is related to AML as it discusses adversarial attacks on fact-checking models by tampering with online evidence to degrade their performance."
uss_2023_377,"Reversing, Breaking, and Fixing the French Legislative Election E-Voting Protocol.",No. The abstract is focused on the security analysis of an e-voting protocol and does not involve adversarial machine learning or the manipulation of machine learning models.
uss_2023_378,PROVIDENCE: a Flexible Round-by-Round Risk-Limiting Audit.,"No, the given abstract is not related to AML because it focuses on risk-limiting audits for election tabulation, which pertains to election security and data auditing rather than adversarial machine learning attacks or defenses."
uss_2023_379,NVLeak: Off-Chip Side-Channel Attacks via Non-Volatile Memory Systems.,No. The abstract is focused on microarchitectural side-channel attacks and defenses related to NVRAM hardware rather than on manipulating or defending machine learning models specifically.
uss_2023_380,Cipherfix: Mitigating Ciphertext Side-Channel Attacks in Software.,"No, the abstract is not related to AML. It focuses on side-channel vulnerabilities and hardware security in trusted execution environments, which do not involve machine learning models or adversarial manipulation of such models."
uss_2023_381,Side-Channel Attacks on Optane Persistent Memory.,"No, the given abstract is not related to AML. It focuses on the security implications of a new memory storage technology rather than adversarial attacks or defenses in machine learning systems."
uss_2023_382,Pspray: Timing Side-Channel based Linux Kernel Heap Exploitation Technique.,"No, the given abstract is not related to AML as it focuses on the stealthiness of exploits related to heap-based vulnerabilities in the Linux kernel, which pertains more to cybersecurity rather than adversarial machine learning."
uss_2023_383,CipherH: Automated Detection of Ciphertext Side-channel Vulnerabilities in Cryptographic Implementations.,"No. The abstract focuses on a side-channel attack exploiting vulnerabilities in trusted execution environments and deterministic memory encryption, which pertains to cryptographic security, not adversarial machine learning."
uss_2023_384,ICSPatch: Automated Vulnerability Localization and Non-Intrusive Hotpatching in Industrial Control Systems using Data Dependence Graphs.,"No. The abstract is focused on patching vulnerabilities in Operational Technology (OT) devices using ICSPatch, with no mention of adversarial attacks or defenses related to machine learning systems."
uss_2023_385,Access Denied: Assessing Physical Risks to Internet Access Networks.,"No, the abstract is not related to AML because it discusses the vulnerability of regional access networks to physical attacks, not malicious manipulation or adversarial attacks on machine learning systems."
uss_2023_386,ZBCAN: A Zero-Byte CAN Defense System.,"No. The abstract is focused on securing the Controller Area Network (CAN) protocol against communication attacks in various systems, without explicit reference to adversarial machine learning or attacks targeting machine learning models."
uss_2023_387,RIDAS: Real-time identification of attack sources on controller area networks.,"No, the abstract is not related to AML. The focus is on identification and response to cyber attacks on vehicle networks rather than adversarial manipulation or extraction of information from machine learning models."
uss_2023_388,That Person Moves Like A Car: Misclassification Attack Detection for Autonomous Systems Using Spatiotemporal Consistency.,"Yes. The abstract discusses developing a defense mechanism, PercepGuard, to detect misclassification attacks in object detection and tracking systems, which falls under the domain of adversarial machine learning."
uss_2023_389,TRust: A Compilation Framework for In-process Isolation to Protect Safe Rust against Untrusted Code.,"No, the abstract is not related to AML. It focuses on enhancing security in Rust programming through a compilation framework, rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2023_390,Jinn: Hijacking Safe Programs with Trojans.,"No, the abstract is related to hardware security rather than adversarial machine learning, as it discusses hardware trojans and their impact on hardware-enforced security mechanisms, not attacks or defenses relevant to machine learning systems."
uss_2023_391,ARGUS: A Framework for Staged Static Taint Analysis of GitHub Workflows and Actions.,"No. The abstract focuses on identifying and analyzing code injection vulnerabilities in GitHub Actions, which is a topic related to software security rather than adversarial machine learning."
uss_2023_392,McFIL: Model Counting Functionality-Inherent Leakage.,"No. The abstract focuses on cryptographic techniques for data confidentiality and secure computation, not on adversarial attacks or defenses in machine learning."
uss_2023_393,Extracting Protocol Format as State Machine via Controlled Static Loop Analysis.,"No. The abstract discusses static program analysis for protocol message formats and enhancing protocol fuzzers, but it does not address adversarial machine learning or related attack and defense techniques."
uss_2023_394,Isolated and Exhausted: Attacking Operating Systems via Site Isolation in the Browser.,"No, the abstract is not related to AML because it deals with browser security architecture and OS resource exhaustion attacks, which are unrelated to machine learning models or adversarial attacks on them."
uss_2023_395,Extending a Hand to Attackers: Browser Privilege Escalation Attacks via Extensions.,"No, the abstract is not related to AML. It discusses security practices and architectures in web browsers, specifically concerning the principle of least privilege and browser extensions, but does not mention adversarial attacks or machine learning models."
uss_2023_396,RÃ¸B: Ransomware over Modern Web Browsers.,"No, the abstract is not related to AML because it focuses on a new attack vector using the File System Access API and WebAssembly for developing ransomware, rather than manipulating or attacking machine learning models."
uss_2023_397,Pool-Party: Exploiting Browser Resource Pools for Web Tracking.,"No. The abstract discusses covert channels in web browsers used for cross-site tracking, which is related to browser security and privacy vulnerabilities, not adversarial machine learning."
uss_2023_398,Checking Passwords on Leaky Computers: A Side Channel Analysis of Chrome's Password Leak Detect Protocol.,"No, the abstract is not related to AML as it focuses on password leakage detection and credential stuffing attacks, which are more relevant to cybersecurity rather than adversarial attacks on machine learning models."
uss_2023_399,Ultimate SLH: Taking Speculative Load Hardening to the Next Level.,"No, the given abstract is not related to AML as it focuses on addressing the Spectre v1 vulnerability in computer processors and compiler-based defenses rather than on adversarial attacks and defenses in machine learning systems."
uss_2023_400,Speculation at Fault: Modeling and Testing Microarchitectural Leakage of CPU Exceptions.,"No. The abstract discusses microarchitectural leakage models used for secure compilation and verification in hardware and software, which is more related to hardware security rather than adversarial machine learning."
uss_2023_401,ProSpeCT: Provably Secure Speculation for the Constant-Time Policy.,"No, the abstract is not related to AML. It focuses on providing a formal processor model to secure against Spectre attacks in hardware speculation, which is more relevant to hardware security rather than adversarial machine learning."
uss_2023_402,Title Redacted Due to Vulnerability Embargo.,"No. The abstract focuses on transient execution attacks that target hardware vulnerabilities in CPUs, not on adversarial attacks against machine learning models."
uss_2023_403,FACE-AUDITOR: Data Auditing in Facial Recognition Systems.,"Yes. The abstract discusses modifying facial images to prevent misuse and adaptive attacks, which falls under the realm of adversarial machine learning, as it involves defending against unauthorized or malicious use of facial recognition systems."
uss_2023_404,UnGANable: Defending Against GAN-based Face Manipulation.,"Yes. The abstract is related to AML as it discusses a defense mechanism, UnGANable, against GAN-inversion-based face manipulation, an adversarial attack on machine learning models."
uss_2023_405,Fairness Properties of Face Recognition and Obfuscation Systems.,"Yes, the abstract is related to AML because it discusses the use of evasion attacks to create perturbed images that cause face recognition systems, which are based on metric embedding networks, to misidentify users."
uss_2023_406,GlitchHiker: Uncovering Vulnerabilities of Image Signal Transmission with IEMI.,"Yes. The abstract describes a new type of attack, the GlitchHiker attack, that leverages vulnerabilities in the camera's image signal transmission to manipulate camera inputs, potentially affecting object and face detectors, which aligns with the concepts of evasion attacks in adversarial machine learning."
uss_2023_407,(M)WAIT for It: Bridging the Gap between Microarchitectural and Architectural Side Channels.,"No. The abstract is related to microarchitectural attacks on CPUs, which involve exploiting hardware vulnerabilities rather than manipulating inputs or outputs in a machine learning system."
uss_2023_408,Collide+Power: Leaking Inaccessible Data with Software-based Power Side Channels.,"No. The abstract is related to a side-channel attack (Differential Power Analysis) on modern CPUs, which is a hardware security threat, rather than an adversarial machine learning attack on a machine learning model."
uss_2023_409,Inception: Exposing New Attack Surfaces with Training in Transient Execution.,"No. The abstract is focused on hardware-based and microarchitectural attacks rather than adversarial machine learning, which deals with manipulating inputs to deceive machine learning models or extracting information from them."
uss_2023_410,BunnyHop: Exploiting the Instruction Prefetcher.,"No. The given abstract is related to microarchitecture and instruction prefetching, not adversarial machine learning or attacks on machine learning models."
uss_2023_411,Can a Deep Learning Model for One Architecture Be Used for Others? Retargeted-Architecture Binary Code Analysis.,"No, the abstract is not related to AML. It focuses on improving binary code analysis across different ISAs by transferring knowledge, rather than discussing adversarial attacks or defenses in the context of machine learning models."
uss_2023_412,Decompiling x86 Deep Neural Network Executables.,"No. The abstract discusses the use of deep learning compilers to optimize DL model performance on various hardware, which does not pertain to adversarial machine learning attacks or defenses."
uss_2023_413,AIRS: Explanation for Deep Reinforcement Learning based Security Applications.,"No, the abstract is focused on explainability and trust issues in deep reinforcement learning (DRL) models for security applications, but it does not specifically address adversarial attacks or defenses which are the core elements of Adversarial Machine Learning (AML)."
uss_2023_414,Differential Testing of Cross Deep Learning Framework APIs: Revealing Inconsistencies and Vulnerabilities.,"No. The abstract focuses on testing and identifying security bugs in cross-framework API conversions for deep learning models, not on adversarial attacks or defenses aimed at exploiting or mitigating vulnerabilities in the models themselves."
uss_2023_415,Every Signature is Broken: On the Insecurity of Microsoft Office's OOXML Signatures.,"No. The abstract discusses attacks on document integrity protection in Microsoft Office and other office standards, but it does not involve machine learning models or adversarial techniques related to AML."
uss_2023_416,Downgrading DNSSEC: How to Exploit Crypto Agility for Hijacking Signed Zones.,"No. The abstract discusses the deployment and agility of cryptographic algorithms in DNSSEC for security purposes, not related to adversarial attacks or defenses in machine learning."
uss_2023_417,Security Analysis of MongoDB Queryable Encryption.,"No. The abstract discusses the integration of searchable encryption technology in a database system, which relates to data security and privacy rather than adversarial machine learning."
uss_2023_418,All cops are broadcasting: TETRA under scrutiny.,"No, the given abstract is not related to AML as it focuses on the security analysis of a radio communication standard and its cryptographic aspects, without mention of machine learning systems or adversarial attacks."
uss_2023_419,On the Feasibility of Malware Unpacking via Hardware-assisted Loop Profiling.,"No, the abstract is not directly related to AML because it discusses the use of Hardware Performance Counters for general security applications, without specifically mentioning adversarial attacks or defenses in the context of machine learning systems."
uss_2023_420,Multiview: Finding Blind Spots in Access-Deny Issues Diagnosis.,"No. The abstract discusses the challenges faced by system administrators in balancing availability and security when addressing access-deny issues, which is more related to systems security and permissions management rather than adversarial machine learning."
uss_2023_421,Attacks are Forwarded: Breaking the Isolation of MicroVM-based Containers Through Operation Forwarding.,No. The abstract discusses virtualization techniques to improve security in containerized environments and does not mention or relate to adversarial attacks or defenses in machine learning systems.
uss_2023_422,AutoFR: Automated Filter Rule Generation for Adblocking.,"No. The abstract describes a reinforcement learning framework for automating adblocking filter rule creation, which is unrelated to adversarial learning as it doesn't involve manipulating machine learning inputs to achieve adversarial outcomes."
