uuid,title,response
uss_2020_0,"29th USENIX Security Symposium, USENIX Security 2020, August 12-14, 2020.","No. The abstract is not provided, so there is no information available to determine its relation to Adversarial Machine Learning."
uss_2020_1,Horizontal Privilege Escalation in Trusted Applications.,"No, the given abstract is unrelated to AML as it focuses on vulnerabilities in Trusted Execution Environments (TEEs) and privilege escalation rather than adversarial attacks or manipulations specific to machine learning models."
uss_2020_2,"The 2020 Election: Remote Voting, Disinformation, and Audit.","No. The abstract is focused on election security, disinformation, and voting technologies, rather than adversarial attacks or defenses in machine learning systems."
uss_2020_3,DELF: Safeguarding deletion correctness in Online Social Networks.,"No. The abstract is focused on data deletion practices in online social networks and the potential privacy implications of developer errors, which are not specifically related to adversarial machine learning attacks or defenses."
uss_2020_4,Digital Contact Tracing.,"No. The abstract discusses digital contact tracing systems and related security, privacy, ethical, and legal issues, but it does not address machine learning or adversarial attacks on such systems."
uss_2020_5,A Formal Analysis of IEEE 802.11's WPA2: Countering the Kracks Caused by Cracking the Counters.,"No, the abstract is not related to AML. It discusses vulnerabilities in the IEEE 802.11 WPA2 protocol and the challenges in formally analyzing its security updates, which are more relevant to network security and cryptography rather than adversarial machine learning."
uss_2020_6,Frankenstein: Advanced Wireless Fuzzing to Exploit New Bluetooth Escalation Targets.,"No, the abstract is not related to AML because it focuses on a fuzzing framework for uncovering vulnerabilities in wireless communication firmware, rather than any manipulation or attacks specifically targeting machine learning systems."
uss_2020_7,Breaking Secure Pairing of Bluetooth Low Energy Using Downgrade Attacks.,"No. The abstract discusses security vulnerabilities in Bluetooth Low Energy (BLE) communication and proposes solutions, but it does not pertain to adversarial machine learning, which involves manipulating machine learning models."
uss_2020_8,You Are What You Broadcast: Identification of Mobile and IoT Devices from (Public) WiFi.,"No, the abstract is not related to AML because it focuses on device identification and anomaly detection through network traffic analysis, rather than discussing manipulations or attacks on machine learning models."
uss_2020_9,Call Me Maybe: Eavesdropping Encrypted LTE Calls With ReVoLTE.,"No, the given abstract is not related to AML because it focuses on exploiting an implementation flaw in VoLTE to eavesdrop on calls, which pertains more to network security and cryptography rather than adversarial machine learning techniques or defenses."
uss_2020_10,A Comprehensive Quality Evaluation of Security and Privacy Advice on the Web.,No. The abstract focuses on evaluating the quality of online security advice for end users and does not discuss adversarial attacks or machine learning systems.
uss_2020_11,"Understanding security mistakes developers make: Qualitative analysis from Build It, Break It, Fix It.","No. The abstract focuses on secure software development and identifying security-relevant errors in programming, rather than discussing adversarial attacks or defenses specifically related to machine learning systems."
uss_2020_12,Empirical Measurement of Systemic 2FA Usability.,"No. The abstract is focused on evaluating the usability and operational impact of Two-Factor Authentication (2FA) systems, which is more related to security and user experience rather than adversarial machine learning."
uss_2020_13,"What Twitter Knows: Characterizing Ad Targeting Practices, User Perceptions, and Ad Explanations Through Users' Own Twitter Data.","No. The abstract focuses on users' privacy perceptions and transparency in targeted advertising, without addressing adversarial manipulations or attacks on machine learning systems."
uss_2020_14,The Impact of Ad-Blockers on Product Search and Purchase Behavior: A Lab Experiment.,"No, the abstract is not related to AML because it discusses the privacy, security, and economic implications of ad-blocking applications, rather than any aspect of adversarial machine learning or attacks on machine learning systems."
uss_2020_15,"Symbolic execution with SymCC: Don't interpret, compile!","No. The abstract focuses on symbolic execution and compiler optimization for better software testing and vulnerability detection, rather than discussing adversarial machine learning techniques or defenses."
uss_2020_16,Sys: A Static/Symbolic Tool for Finding Good Bugs in Good (Browser) Code.,"No, the abstract is not related to AML because it focuses on finding security bugs in codebases using static checkers and symbolic execution, without involving any adversarial machine learning attacks or defenses."
uss_2020_17,Everything Old is New Again: Binary Security of WebAssembly.,"No, the abstract is not related to AML because it focuses on the security vulnerabilities and potential exploits in WebAssembly binaries, rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2020_18,AURORA: Statistical Crash Analysis for Automated Root Cause Explanation.,"No, the abstract is not related to AML. It focuses on identifying and analyzing software crashes using techniques like reverse execution and backward taint analysis, rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2020_19,SmartVerif: Push the Limit of Automation Capability of Verifying Security Protocols by Dynamic Strategies.,"No. The abstract focuses on a framework for automated verification of security protocols using a dynamic strategy, rather than addressing adversarial machine learning or related attacks and defenses."
uss_2020_20,BigMAC: Fine-Grained Policy Analysis of Android Firmware.,No. The abstract is related to analyzing and understanding security policies and access controls in the Android operating system rather than discussing adversarial machine learning attacks or defenses.
uss_2020_21,From Needs to Actions to Secure Apps? The Effect of Requirements and Developer Practices on App Security.,"No, the given abstract is not related to AML because it discusses the general security practices and compliance of app developers rather than adversarial attacks or defenses specific to machine learning systems."
uss_2020_22,FANS: Fuzzing Android Native System Services via Automated Interface Analysis.,"No. The abstract discusses fuzzing techniques for finding vulnerabilities in Android native system services, focusing on interprocess communication and testing mechanisms, which do not pertain to adversarial attacks or defenses in machine learning systems."
uss_2020_23,Chaperone: Real-time Locking and Loss Prevention for Smartphones.,"No, this abstract is not related to AML as it focuses on smartphone loss prevention using acoustic sensing to detect unattended status, rather than discussing machine learning models or adversarial attacks on such models."
uss_2020_24,Towards HTTPS Everywhere on Android: We Are Not There Yet.,"No, the abstract is not related to AML. It focuses on evaluating network security mechanisms for mobile apps and analyzing their adoption and effectiveness, rather than discussing adversarial attacks against machine learning systems."
uss_2020_25,Sunrise to Sunset: Analyzing the End-to-end Life Cycle and Effectiveness of Phishing Attacks at Scale.,"No, this abstract is not related to AML. It focuses on analyzing and measuring phishing attacks and their impact on victims but not on how machine learning models are manipulated or attacked adversarially."
uss_2020_26,PhishTime: Continuous Longitudinal Measurement of the Effectiveness of Anti-phishing Blacklists.,"No. The abstract discusses anti-phishing blacklists and evasion techniques used by phishing websites, which is focused on evaluating the effectiveness of web security measures rather than machine learning systems specifically."
uss_2020_27,Who's Calling? Characterizing Robocalls through Audio and Metadata Analysis.,"No. This abstract focuses on analyzing unsolicited phone calls and identifying calling campaigns, which is related to telecommunications security rather than adversarial machine learning."
uss_2020_28,See No Evil: Phishing for Permissions with False Transparency.,"No, the given abstract is not related to AML because it focuses on exploiting Android's permission model through false transparency attacks rather than manipulating or attacking machine learning models."
uss_2020_29,A different cup of TI? The added value of commercial threat intelligence.,No. The abstract is focused on assessing the coverage and timeliness of commercial threat intelligence services and does not discuss machine learning systems or adversarial attacks on them.
uss_2020_30,HybCache: Hybrid Side-Channel-Resilient Caches for Trusted Execution Environments.,"No, the abstract is not related to Adversarial Machine Learning. The focus is on cache side-channel attacks related to hardware security rather than manipulating or defending against machine learning systems."
uss_2020_31,CopyCat: Controlled Instruction-Level Attacks on Enclaves.,"No. The abstract focuses on controlled-channel attacks and memory access tracking in trusted execution environments, which are more related to computer security and hardware vulnerabilities rather than adversarial machine learning."
uss_2020_32,An Off-Chip Attack on Hardware Enclaves via the Memory Bus.,"No, the abstract is not related to AML. It describes a hardware-based attack on memory confidentiality, not an adversarial attack on a machine learning system."
uss_2020_33,Civet: An Efficient Java Partitioning Framework for Hardware Enclaves.,"No. The abstract discusses partitioning applications using hardware enclaves for executing sensitive code, which is a topic more related to system security and trusted execution rather than adversarial machine learning."
uss_2020_34,BesFS: A POSIX Filesystem for Enclaves with a Mechanized Safety Proof.,"No. The abstract focuses on secure filesystem interfaces and enclave integrity against OS attacks, which are related to system security, not adversarial machine learning."
uss_2020_35,EPIC: Every Packet Is Checked in the Data Plane of a Path-Aware Internet.,"No, the given abstract is not related to AML. It discusses path-aware networking architectures for improving internet security and efficiency, without mention of adversarial attacks or defenses specific to machine learning systems."
uss_2020_36,ShadowMove: A Stealthy Lateral Movement Strategy.,"No, the abstract is related to cyber security and discusses APT attack techniques and stealthy lateral movement strategies, but it does not mention or involve exploiting or defending machine learning systems, which is the key focus of adversarial machine learning."
uss_2020_37,Poison Over Troubled Forwarders: A Cache Poisoning Attack Targeting DNS Forwarding Devices.,"No. The abstract focuses on vulnerabilities in DNS infrastructure and forwarders, which is related more to network security rather than adversarial machine learning."
uss_2020_38,Programmable In-Network Security for Context-aware BYOD Policies.,"No. The abstract discusses challenges and solutions related to Bring Your Own Device (BYOD) security and network management, focusing on access control and context-aware security rather than adversarial techniques or machine learning vulnerabilities."
uss_2020_39,A Longitudinal and Comprehensive Study of the DANE Ecosystem in Email.,"No. The abstract discusses the DANE standard for secure TLS connections and its reliance on DNSSEC, focusing on authentication and integrity rather than addressing adversarial machine learning concerns."
uss_2020_40,NXNSAttack: Recursive DNS Inefficiencies and Vulnerabilities.,"No, the abstract is not related to AML because it focuses on a specific vulnerability and attack within the DNS system, which targets network protocols rather than machine learning models."
uss_2020_41,Shim Shimmeny: Evaluating the Security and Privacy Contributions of Link Shimming in the Modern Web.,"No. The abstract is about examining the use of link shimming by websites for security, privacy, and analytics purposes, and doesn't involve manipulating or attacking machine learning systems."
uss_2020_42,Cached and Confused: Web Cache Deception in the Wild.,"No, the given abstract is not related to AML as it focuses on web cache deception attacks, which are more aligned with network security rather than adversarial machine learning attacks on machine learning models."
uss_2020_43,A Tale of Two Headers: A Formal Analysis of Inconsistent Click-Jacking Protection on the Web.,"No, the abstract is not related to AML because it focuses on analyzing and addressing inconsistencies in web security mechanisms for click-jacking protection, which does not involve attacking or defending machine learning systems."
uss_2020_44,Retrofitting Fine Grain Isolation in the Firefox Renderer.,"No. The abstract is focused on securing browser architecture by sandboxing third-party libraries to mitigate vulnerabilities, which is related to software security but not specifically to adversarial machine learning."
uss_2020_45,Zero-delay Lightweight Defenses against Website Fingerprinting.,"Yes. The abstract is related to AML as it discusses attacks and defenses in the context of identifying webpage visits through network traffic analysis, which aligns with evasion attacks in adversarial machine learning."
uss_2020_46,Achieving Keyless CDNs with Conclaves.,"No, the abstract is not related to AML. It focuses on the security implications of Content Delivery Networks handling private keys for HTTPS services, rather than discussing machine learning systems or adversarial machine learning attacks and defenses."
uss_2020_47,"SENG, the SGX-Enforcing Network Gateway: Authorizing Communication from Shielded Clients.","No. The abstract is related to network security and the challenges in creating effective firewall policies, but it does not involve adversarial attacks or defenses in the context of machine learning systems."
uss_2020_48,APEX: A Verified Architecture for Proofs of Execution on Remote Devices under Full Software Compromise.,"No, the abstract is not related to AML. It focuses on trust and security in Cyber-Physical Systems and IoT devices rather than discussing attacks or defenses specific to machine learning models."
uss_2020_49,PARTEMU: Enabling Dynamic Analysis of Real-World TrustZone Software Using Emulation.,"No, the given abstract is not related to AML. It focuses on emulating ARM's TrustZone technology for dynamic analysis and vulnerability testing, rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2020_50,PHMon: A Programmable Hardware Monitor and Its Security Use Cases.,"No, the abstract is not related to AML because it focuses on hardware-based security and monitoring solutions that enforce security policies, rather than discussing adversarial attacks or machine learning systems."
uss_2020_51,TeeRex: Discovery and Exploitation of Memory Corruption Vulnerabilities in SGX Enclaves.,"No, the abstract is not related to AML. It focuses on analyzing vulnerabilities in SGX enclaves, which pertains to secure hardware and memory protection, rather than discussing adversarial techniques or attacks on machine learning models."
uss_2020_52,Stealthy Tracking of Autonomous Vehicles with Cache Side Channels.,"No. The abstract is related to software side-channel attacks on autonomous vehicles, which are security vulnerabilities but not specifically related to adversarial machine learning techniques or attacks."
uss_2020_53,Towards Robust LiDAR-based Perception in Autonomous Driving: General Black-box Adversarial Sensor Attack and Countermeasures.,"Yes, the abstract is related to AML as it explores vulnerabilities and defenses against spoofing attacks on LiDAR-based perception systems in autonomous cars, which is an adversarial attack context in machine learning."
uss_2020_54,SAVIOR: Securing Autonomous Vehicles with Robust Physical Invariants.,"Yes. The abstract discusses securing autonomous vehicles against attacks that manipulate sensor data, which is akin to an evasion attack in adversarial machine learning."
uss_2020_55,From Control Model to Program: Investigating Robotic Aerial Vehicle Accidents with MAYDAY.,"No, the abstract is not related to AML because it focuses on a framework for investigating robotic aerial vehicle accidents by analyzing control programs rather than discussing adversarial machine learning attacks or defenses."
uss_2020_56,Drift with Devil: Security of Multi-Sensor Fusion based Localization in High-Level Autonomous Driving under GPS Spoofing.,"Yes. The abstract is related to AML as it investigates the security of Multi-Sensor Fusion algorithms used in Autonomous Vehicles against GPS spoofing attacks, which is a type of adversarial attack."
uss_2020_57,Plug-N-Pwned: Comprehensive Vulnerability Analysis of OBD-II Dongles as A New Over-the-Air Attack Surface in Automotive IoT.,"No, the abstract is not related to AML because it focuses on the security vulnerabilities of wireless OBD-II dongles in vehicles and does not involve manipulating or attacking machine learning models."
uss_2020_58,PCKV: Locally Differentially Private Correlated Key-Value Data Collection with Optimized Utility.,"No, the abstract is not related to AML. It focuses on enhancing data collection techniques under the framework of local differential privacy, rather than addressing adversarial attacks or defenses in machine learning systems."
uss_2020_59,Actions Speak Louder than Words: Entity-Sensitive Privacy Policy and Data Flow Analysis with PoliCheck.,No. The given abstract is not related to AML because it focuses on detecting privacy policy inconsistencies in mobile applications rather than attacks or defenses involving adversarial manipulation of machine learning models.
uss_2020_60,Walking Onions: Scaling Anonymity Networks while Protecting Users.,"No. The abstract is focused on the challenges of scaling anonymity networks and preventing certain types of attacks within such networks, which is not specifically related to adversarial machine learning."
uss_2020_61,Differentially-Private Control-Flow Node Coverage for Software Usage Analysis.,"No. The abstract discusses a privacy-preserving solution using differential privacy for software usage analysis, but it does not mention adversarial attacks or machine learning systems."
uss_2020_62,Visor: Privacy-Preserving Video Analytics as a Cloud Service.,"No. The abstract is focused on privacy and security concerns in video analytics services and trusted execution environments, rather than adversarial machine learning or attacks on machine learning models."
uss_2020_63,Datalog Disassembly.,"No, the abstract is not related to AML because it focuses on a disassembly technique and binary analysis for reassembling binaries, which is not directly connected to adversarial machine learning or attacks on machine learning models."
uss_2020_64,KOOBE: Towards Facilitating Exploit Generation of Kernel Out-Of-Bounds Write Vulnerabilities.,"No. The abstract is focused on operating system vulnerabilities and automated exploit generation for memory bugs, which is primarily related to security research rather than adversarial machine learning."
uss_2020_65,Automatic Techniques to Systematically Discover New Heap Exploitation Primitives.,"No. The abstract focuses on exploitation techniques for heap allocators, which is more related to software security and vulnerability exploitation rather than adversarial machine learning."
uss_2020_66,The Industrial Age of Hacking.,"No, the abstract is not related to AML. The focus is on an alternative strategy for software bug detection and analysis rather than on manipulating or defending against machine learning systems."
uss_2020_67,BScout: Direct Whole Patch Presence Test for Java Executables.,"No. The abstract is related to applying security patches to software and does not discuss adversarial attacks, manipulation of ML systems, or defenses which are key aspects of adversarial machine learning."
uss_2020_68,MVP: Detecting Vulnerabilities using Patch-Enhanced Vulnerability Signatures.,"No. The abstract discusses identifying recurring vulnerabilities in software systems, focusing on code similarities and differences, rather than on adversarial machine learning or attacks against ML models."
uss_2020_69,Shattered Chain of Trust: Understanding Security Risks in Cross-Cloud IoT Access Delegation.,"No, the given abstract is not related to AML, as it primarily focuses on the security risks and vulnerabilities in IoT access delegation mechanisms, rather than discussing adversarial machine learning attacks or defenses on machine learning systems."
uss_2020_70,HALucinator: Firmware Re-hosting Through Abstraction Layer Emulation.,"No, the abstract is not related to AML. It focuses on firmware analysis and emulation using High-Level Emulation (HLE) techniques, which is more related to embedded systems security rather than adversarial machine learning."
uss_2020_71,Silhouette: Efficient Protected Shadow Stacks for Embedded Systems.,"No, the abstract is not related to Adversarial Machine Learning. It discusses the security vulnerabilities of microcontroller-based embedded systems programmed in C, focusing on type safety and memory safety, rather than adversarial attacks or defenses on machine learning models."
uss_2020_72,P2IM: Scalable and Hardware-independent Firmware Testing via Automatic Peripheral Interface Modeling.,"No. The abstract is related to testing and fuzzing of embedded firmware, which is focused on identifying bugs and vulnerabilities rather than adversarial attacks or defenses in machine learning."
uss_2020_73,COUNTERFOIL: Verifying Provenance of Integrated Circuits using Intrinsic Package Fingerprints and Inexpensive Cameras.,"No, the abstract is not related to AML as it focuses on developing an anti-counterfeiting system for semiconductor chips using imaging and digital authentication techniques, rather than manipulating or defending against machine learning models."
uss_2020_74,Hall Spoofing: A Non-Invasive DoS Attack on Grid-Tied Solar Inverter.,"Yes, the abstract is related to AML because it describes a methodology for an adversarial attack that manipulates the behavior of a grid-tied solar inverter through noninvasive means, impacting the output and potentially destabilizing the grid."
uss_2020_75,Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning.,"No, the abstract is not related to AML because it discusses the progression of machine learning and online learning scenarios without mentioning adversarial attacks or defenses.
"
uss_2020_76,Exploring Connections Between Active Learning and Model Extraction.,"Yes. The abstract is related to AML as it discusses model extraction attacks, where adversaries exploit MLaaS systems to maliciously obtain a proprietary model, and also explores potential defense strategies."
uss_2020_77,Hybrid Batch Attacks: Finding Black-box Adversarial Examples with Limited Queries.,"Yes. The abstract discusses black-box adversarial examples and introduces hybrid attack strategies to effectively find adversarial examples using limited queries, which are key topics in adversarial machine learning."
uss_2020_78,High Accuracy and High Fidelity Extraction of Neural Networks.,"Yes. The abstract discusses model extraction attacks, which are a type of adversarial attack focused on stealing a machine learning model by exploiting its prediction outputs, clearly falling under the scope of adversarial machine learning."
uss_2020_79,Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning.,"Yes, the abstract is related to AML because it discusses attacks on machine learning preprocessing and their potential impact, which is a concern in adversarial machine learning."
uss_2020_80,TextShield: Robust Text Classification Based on Multimodal Embedding and Neural Machine Translation.,"Yes. The abstract is related to AML as it discusses adversarial texts, which are crafted to exploit vulnerabilities in deep learning-based text classification models for toxic content detection."
uss_2020_81,"Data Recovery from ""Scrubbed"" NAND Flash Storage: Need for Analog Sanitization.","No, the abstract is not related to AML. It focuses on the recovery of data from flash memory after digital sanitization and does not discuss machine learning models or adversarial attacks against them."
uss_2020_82,PKU Pitfalls: Attacks on PKU-based Memory Isolation Systems.,"No, the abstract is not related to Adversarial Machine Learning (AML) because it discusses intra-process memory isolation and system security at the operating system level, rather than focusing on malicious attacks or defenses targeting machine learning models."
uss_2020_83,Medusa: Microarchitectural Data Leakage via Automated Attack Synthesis.,"No, the given abstract is not related to AML. It discusses a transient execution attack on microarchitectural elements of a CPU rather than an attack on a machine learning system or model."
uss_2020_84,V0LTpwn: Attacking x86 Processor Integrity from Software.,"No. The abstract focuses on fault-injection attacks targeting hardware-based security measures, which are more related to hardware security rather than adversarial machine learning."
uss_2020_85,DeepHammer: Depleting the Intelligence of Deep Neural Networks through Targeted Chain of Bit Flips.,"Yes, the abstract is related to AML as it describes a hardware-based attack, DeepHammer, that manipulates the integrity of deep neural networks by inducing bit flips, demonstrating an adversarial attack on the model's inference accuracy."
uss_2020_86,SpecFuzz: Bringing Spectre-type vulnerabilities to the surface.,"No. The abstract is related to detecting speculative execution vulnerabilities, which is concerned with hardware security rather than adversarial attacks on machine learning systems."
uss_2020_87,Security Analysis of Unified Payments Interface and Payment Apps in India.,No. The abstract is related to the security analysis of the UPI protocol and does not involve adversarial machine learning attacks or defenses against machine learning models.
uss_2020_88,Cardpliance: PCI DSS Compliance of Android Applications.,"No. The abstract focuses on analyzing compliance with the Payment Card Industry Data Security Standard (PCI DSS) in mobile applications, rather than discussing adversarial machine learning or attacks on machine learning systems."
uss_2020_89,"The Ballot is Busted Before the Blockchain: A Security Analysis of Voatz, the First Internet Voting Application Used in U.S. Federal Elections.","No. The abstract focuses on the security analysis of a mobile voting application and its use of blockchain and other security technologies, not on adversarial attacks or defenses specific to machine learning systems."
uss_2020_90,VoteAgain: A scalable coercion-resistant voting system.,"No. The abstract is focused on developing a voting system that provides coercion resistance and is related to cryptographic techniques, not on adversarial attacks or defenses in machine learning systems."
uss_2020_91,Boxer: Preventing fraud by scanning credit cards.,"No, the abstract is not related to AML. It focuses on combating card-not-present credit card fraud by using a mobile SDK to verify genuine cards, not on attacking or defending against machine learning models."
uss_2020_92,Fawkes: Protecting Privacy against Unauthorized Deep Learning Models.,"Yes. The abstract discusses the misuse of facial recognition systems, which is related to adversarial machine learning as it involves unauthorized data usage and raises concerns about privacy and potential adversarial threats."
uss_2020_93,Stolen Memories: Leveraging Model Memorization for Calibrated White-Box Membership Inference.,"Yes. This abstract is related to AML as it describes membership inference (MI) attacks, a type of adversarial attack that exploits information leakage from machine learning models, and explores their effectiveness in the white-box setting."
uss_2020_94,Local Model Poisoning Attacks to Byzantine-Robust Federated Learning.,"Yes. The abstract is related to AML as it discusses local model poisoning attacks on federated learning, which involve adversarial manipulation of machine learning models to increase error rates."
uss_2020_95,Justinian's GAAvernor: Robust Distributed Learning with Gradient Aggregation Agent.,"Yes. The abstract is related to AML as it discusses defending against Byzantine attacks, a type of adversarial attack, in distributed learning systems."
uss_2020_96,Interpretable Deep Learning under Fire.,"Yes, the abstract is related to AML because it discusses the potential susceptibility of interpretability models for DNNs to malicious manipulations, which aligns with the concept of adversarial attacks on machine learning systems."
uss_2020_97,Donky: Domain Keys - Efficient In-Process Isolation for RISC-V and x86.,"No. The abstract discusses in-process isolation for improved security and performance in computing environments, but it does not touch on adversarial machine learning or manipulating machine learning systems."
uss_2020_98,(Mostly) Exitless VM Protection from Untrusted Hypervisor through Disaggregated Nested Virtualization.,"No, the abstract is not related to AML because it discusses a nested hypervisor design for cloud security, focusing on reducing performance overhead and enhancing protection mechanisms, without addressing machine learning models or adversarial attacks."
uss_2020_99,"DECAF: Automatic, Adaptive De-bloating and Hardening of COTS Firmware.","No. The abstract is about the vulnerabilities in server firmware and the risks posed by complex and unnecessary code in firmware supply chains, but it does not discuss machine learning systems or adversarial attacks on them."
uss_2020_100,McTiny: Fast High-Confidence Post-Quantum Key Erasure for Tiny Network Servers.,"No. The abstract discusses cryptography performance and key sizes related to post-quantum systems, not machine learning or adversarial attacks."
uss_2020_101,Temporal System Call Specialization for Attack Surface Reduction.,"No, this abstract is not related to AML because it focuses on software debloating techniques to reduce the attack surface by removing unnecessary application features, which is more related to traditional software security rather than manipulating or attacking machine learning systems."
uss_2020_102,Big Numbers - Big Troubles: Systematically Analyzing Nonce Leakage in (EC)DSA Implementations.,"No, the abstract is not related to AML because it focuses on side-channel attacks and vulnerabilities in cryptographic implementations, which are unrelated to adversarial manipulation or attacks on machine learning systems."
uss_2020_103,Estonian Electronic Identity Card: Security Flaws in Key Management.,"No, the given abstract is not related to Adversarial Machine Learning (AML) as it focuses on the Estonian electronic identity card system, which is centered around secure public-key cryptography and digital signatures, rather than adversarial attacks or defenses in machine learning systems."
uss_2020_104,The Unpatchable Silicon: A Full Break of the Bitstream Encryption of Xilinx 7-Series FPGAs.,"No. The abstract is focused on the security of FPGA hardware and bitstream encryption, which relates to hardware security and cryptography rather than adversarial machine learning."
uss_2020_105,Automating the Development of Chosen Ciphertext Attacks.,"No. This abstract focuses on automating the development of adaptive chosen ciphertext attacks using SAT and SMT solvers, which pertains more to cryptographic attack strategies rather than adversarial machine learning threats or defenses."
uss_2020_106,SHA-1 is a Shambles: First Chosen-Prefix Collision on SHA-1 and Application to the PGP Web of Trust.,No. The abstract is focused on cryptographic vulnerabilities in the SHA-1 hash function rather than on adversarial or malicious attacks targeted at machine learning models.
uss_2020_107,"A Spectral Analysis of Noise: A Comprehensive, Automated, Formal Analysis of Diffie-Hellman Protocols.","No. The abstract is related to cryptographic protocols for secure communications, not about adversarial attacks or defenses in machine learning."
uss_2020_108,An Observational Investigation of Reverse Engineers' Processes.,"No, the abstract is not related to AML. It focuses on reverse engineering and the development of tools for understanding software, without mentioning machine learning or adversarial attacks."
uss_2020_109,The Tools and Tactics Used in Intimate Partner Surveillance: An Analysis of Online Infidelity Forums.,"No, the abstract is not related to AML. It focuses on intimate partner surveillance (IPS) tactics and the study of online forums discussing these strategies, rather than machine learning systems or adversarial attacks on such systems."
uss_2020_110,DatashareNetwork: A Decentralized Privacy-Preserving Search Engine for Investigative Journalists.,"No, the abstract is not related to AML because it focuses on a decentralized and privacy-preserving search system for sharing documents among journalists, without any mention of machine learning models or adversarial attacks."
uss_2020_111,"""I am uncomfortable sharing what I can't see"": Privacy Concerns of the Visually Impaired with Camera Based Assistive Applications.","No, the abstract is not related to AML as it primarily focuses on privacy concerns and human-assisted question-answering systems, rather than adversarial machine learning techniques or attacks."
uss_2020_112,'I have too much respect for my elders': Understanding South African Mobile Users' Perceptions of Privacy and Current Behaviors on Facebook and WhatsApp.,No. The abstract focuses on user privacy concerns and behaviors on social media in resource-constrained settings rather than addressing adversarial attacks or defense mechanisms in machine learning systems.
uss_2020_113,RELOAD+REFRESH: Abusing Cache Replacement Policies to Perform Stealthy Cache Attacks.,"No. The abstract is related to side-channel attacks focusing on cache manipulation to extract information across logical isolation boundaries, rather than adversarial techniques targeting machine learning models."
uss_2020_114,Timeless Timing Attacks: Exploiting Concurrency to Leak Secrets over Remote Connections.,"No. The given abstract discusses remote timing attacks, which focus on exploiting timing side-channels in network communication, rather than attacking or manipulating machine learning models specifically."
uss_2020_115,Cache Telepathy: Leveraging Shared Resource Attacks to Learn DNN Architectures.,"Yes. The abstract is related to AML as it discusses attacking a DNN to extract its architecture, which is a form of adversarial attack aimed at exploiting or undermining machine learning systems."
uss_2020_116,Certified Side Channels.,"No, the given abstract is unrelated to Adversarial Machine Learning as it focuses on vulnerabilities in cryptographic key handling and side-channel attacks within cryptosystems, without involving machine learning models or adversarial manipulation of ML systems."
uss_2020_117,NetWarden: Mitigating Network Covert Channels while Preserving Performance.,"No, this abstract is not related to AML. It focuses on defending against network covert channels in distributed systems, which is a security and network performance issue, rather than adversarial machine learning."
uss_2020_118,TPM-FAIL: TPM meets Timing and Lattice Attacks.,"No, the given abstract is not related to Adversarial Machine Learning (AML). The abstract focuses on timing attacks against hardware-based security features, specifically targeting cryptographic key recovery from TPMs, which is more relevant to cryptography and hardware security rather than machine learning."
uss_2020_119,Scaling Verifiable Computation Using Efficient Set Accumulators.,"No, the abstract is not related to AML. It discusses verifiable outsourcing using succinct proofs like SNARKs in blockchain systems, which is more about computation verification and blockchain technology rather than machine learning and adversarial attacks or defenses."
uss_2020_120,Pixel: Multi-signatures for Consensus.,"No, the abstract is related to blockchain security and digital signatures but does not discuss adversarial machine learning techniques or attacks on machine learning models."
uss_2020_121,SANNS: Scaling Up Secure Approximate k-Nearest Neighbors Search.,"No. The abstract discusses privacy concerns related to k-Nearest Neighbor Search in cloud-based services, but does not address adversarial attacks or defenses in machine learning systems."
uss_2020_122,MIRAGE: Succinct Arguments for Randomized Algorithms with Applications to Universal zk-SNARKs.,"No, the abstract is not related to AML as it discusses improvements in zero-knowledge proof systems, which are cryptographic techniques unrelated to adversarial attacks or defenses in machine learning."
uss_2020_123,Secure Multi-party Computation of Differentially Private Median.,"No. The abstract focuses on distributed private learning and collecting statistics without disclosing individual values, which is more related to privacy-preserving techniques rather than adversarial machine learning."
uss_2020_124,"That Was Then, This Is Now: A Security Evaluation of Password Generation, Storage, and Autofill in Browser-Based Password Managers.","No, the abstract is not related to AML. It focuses on assessing the security of password managers, rather than discussing malicious attacks or defenses targeting machine learning systems."
uss_2020_125,Composition Kills: A Case Study of Email Sender Authentication.,"No. The abstract focuses on identifying vulnerabilities in email systems due to component inconsistencies, but it does not discuss manipulating machine learning systems or defenses against such attacks."
uss_2020_126,Detecting Stuffing of a User's Credentials at Her Own Accounts.,"No. The abstract focuses on detecting credential stuffing using anomaly detection and secure information sharing, which is more related to cybersecurity rather than manipulating or extracting information from machine learning models."
uss_2020_127,Liveness is Not Enough: Enhancing Fingerprint Authentication with Behavioral Biometrics to Defeat Puppet Attacks.,"No, the abstract is not related to AML as it focuses on improving fingerprint authentication security against presentation attacks using intrinsic fingertip-touch behaviors rather than addressing or manipulating machine learning models."
uss_2020_128,Human Distinguishable Visual Key Fingerprints.,"No. The abstract is about generating visual fingerprint images for identity verification, which focuses on security and biometric representation rather than adversarial machine learning."
uss_2020_129,FuzzGuard: Filtering out Unreachable Inputs in Directed Grey-box Fuzzing through Deep Learning.,"No, the abstract discusses directed grey-box fuzzing, a software testing technique, which is not related to adversarial machine learning or manipulating machine learning models."
uss_2020_130,FuzzGen: Automatic Fuzzer Generation.,"No, the abstract is unrelated to AML as it focuses on fuzzing techniques for discovering software vulnerabilities rather than attacks or defenses related to manipulating machine learning models."
uss_2020_131,ParmeSan: Sanitizer-guided Greybox Fuzzing.,"No. The abstract discusses techniques for improving fuzzing strategies to identify software vulnerabilities, which is a topic related to software testing and bug detection, not adversarial machine learning."
uss_2020_132,EcoFuzz: Adaptive Energy-Saving Greybox Fuzzing as a Variant of the Adversarial Multi-Armed Bandit.,"No, this abstract is not related to AML as it focuses on optimizing fuzzing techniques for identifying security vulnerabilities rather than on adversarial attacks or defenses on machine learning models."
uss_2020_133,MUZZ: Thread-aware Grey-box Fuzzing for Effective Bug Hunting in Multithreaded Programs.,"No, the given abstract is not related to AML as it focuses on improving grey-box fuzzing techniques for testing vulnerabilities in multithreaded software, rather than discussing adversarial attacks or defenses on machine learning systems."
uss_2020_134,On Training Robust PDF Malware Classifiers.,"Yes, the abstract is related to AML because it discusses evasion attacks on PDF malware classifiers, which is a type of adversarial attack focused on compromising the robustness of machine learning models."
uss_2020_135,Measuring and Modeling the Label Dynamics of Online Anti-Malware Engines.,"No. The abstract primarily focuses on evaluating and improving methods for aggregating malware labels from VirusTotal, rather than exploring adversarial techniques or defenses related to machine learning systems."
uss_2020_136,FIRMSCOPE: Automatic Uncovering of Privilege-Escalation Vulnerabilities in Pre-Installed Apps in Android Firmware.,"No, the abstract is not related to AML because it focuses on analyzing Android firmware for privilege-escalation vulnerabilities in pre-installed apps, rather than dealing with adversarial attacks or defenses on machine learning systems."
uss_2020_137,Automatic Hot Patch Generation for Android Kernels.,"No, the given abstract is not related to AML. It focuses on addressing security vulnerabilities in the Android ecosystem through hot patching, rather than discussing adversarial machine learning attacks or defenses."
uss_2020_138,"iOS, Your OS, Everybody's OS: Vetting and Analyzing Network Services of iOS Applications.",No. The abstract focuses on identifying network service vulnerabilities in iOS applications rather than manipulating or attacking machine learning systems specifically.
uss_2020_139,SEAL: Attack Mitigation for Encrypted Databases via Adjustable Leakage.,"No, the abstract is not related to AML because it discusses searchable encryption and defenses against leakage-abuse attacks, which are more relevant to cryptography and data security rather than adversarial machine learning."
uss_2020_140,Pancake: Frequency Smoothing for Encrypted Data Stores.,"No, the abstract is not related to AML. It focuses on preventing access pattern leakage attacks in key-value stores using frequency smoothing, which is more related to data security and encryption rather than adversarial machine learning."
uss_2020_141,Droplet: Decentralized Authorization and Access Control for Encrypted Data Streams.,"No, the abstract discusses a decentralized data access control service for securely sharing encrypted data, which pertains to data security and access control, not adversarial machine learning."
uss_2020_142,Secure parallel computation on national scale volumes of data.,"No, the abstract is not related to AML because it focuses on secure multi-party computation and privacy-preserving techniques, rather than on adversarial attacks or defenses in machine learning systems."
uss_2020_143,Delphi: A Cryptographic Inference Service for Neural Networks.,"No, the abstract is not related to AML. It discusses privacy concerns in neural network prediction services, focusing on protecting user data and proprietary models, rather than adversarial attacks or defenses against them."
uss_2020_144,Analysis of DTLS Implementations Using Protocol State Fuzzing.,"No. The abstract discusses the development and challenges of the DTLS protocol in the context of UDP communication, which relates to cryptography and secure data transport rather than adversarial machine learning."
uss_2020_145,Agamotto: Accelerating Kernel Driver Fuzzing with Lightweight Virtual Machine Checkpoints.,"No. The abstract focuses on fuzzing techniques for finding vulnerabilities in kernel-mode drivers, which is related to software security testing, not adversarial machine learning."
uss_2020_146,USBFuzz: A Framework for Fuzzing USB Drivers by Device Emulation.,"No. The abstract discusses vulnerabilities in OS kernels and device drivers due to malicious USB devices, focusing on security testing challenges and fuzzing, rather than addressing adversarial machine learning attacks or defenses within a machine learning context."
uss_2020_147,GREYONE: Data Flow Sensitive Fuzzing.,No. The abstract is primarily focused on data flow analysis techniques for improving fuzzing efficiency and does not mention malicious attacks or defenses applicable to adversarial machine learning.
uss_2020_148,Fuzzing Error Handling Code using Context-Sensitive Software Fault Injection.,"No, the abstract is not related to AML. It focuses on improving fuzzing techniques to test error handling in code, rather than on adversarial attacks or defenses in machine learning systems."
uss_2020_149,Montage: A Neural Network Language Model-Guided JavaScript Engine Fuzzer.,"No, the given abstract is not related to Adversarial Machine Learning (AML) as it focuses on identifying JavaScript engine vulnerabilities using a neural network-guided fuzzer, rather than manipulating machine learning systems or models."
uss_2020_150,Light Commands: Laser-Based Audio Injection Attacks on Voice-Controllable Systems.,"No, the abstract is primarily focused on signal injection attacks on microphones using light rather than manipulating or attacking machine learning models specifically."
uss_2020_151,SkillExplorer: Understanding the Behavior of Skills in Large Scale.,"Yes. The abstract is related to AML as it involves analyzing potential malicious behaviors in third-party skills of smart speakers, which relates to adversarial attacks by exploiting ambiguities in skill names to trick users."
uss_2020_152,Devil's Whisper: A General Approach for Physical Adversarial Attacks against Commercial Black-box Speech Recognition Devices.,"Yes. The abstract discusses a method for conducting black-box adversarial attacks on commercial automatic speech recognition (ASR) systems, which is a clear example of adversarial machine learning."
uss_2020_153,Void: A fast and light voice liveness detection system.,"Yes. The abstract is related to AML because it discusses a defense mechanism against spoofing attacks on voice assistants, which is a type of adversarial attack on machine learning systems."
uss_2020_154,Preech: A System for Privacy-Preserving Speech Transcription.,"No, this abstract is not related to Adversarial Machine Learning because it focuses on improving privacy in Automated Speech Recognition systems rather than discussing methods to attack or defend against adversarial inputs in machine learning systems."
uss_2020_155,BlockSci: Design and applications of a blockchain analysis platform.,"No. The abstract is related to blockchain analysis and does not mention machine learning, adversarial attacks, or techniques for manipulating or defending ML systems."
uss_2020_156,Remote Side-Channel Attacks on Anonymous Transactions.,"No. The abstract is focused on side-channel attacks against privacy-focused cryptocurrencies, which involves cryptographic vulnerabilities rather than adversarial attacks on machine learning models."
uss_2020_157,ETHBMC: A Bounded Model Checker for Smart Contracts.,"No. The abstract is focused on the analysis and security of smart contracts within the blockchain ecosystem, with no mention of adversarial attacks or the manipulation of machine learning models."
uss_2020_158,TXSPECTOR: Uncovering Attacks in Ethereum from Transactions.,"No. The abstract is related to blockchain security and smart contract vulnerability detection, not directly to adversarial machine learning or attacks on machine learning systems."
uss_2020_159,An Ever-evolving Game: Evaluation of Real-world Attacks and Defenses in Ethereum Ecosystem.,"No, the abstract is not related to AML. It focuses on smart contract security and the detection of vulnerabilities and attacks on the Ethereum blockchain rather than adversarial attacks or defenses on machine learning systems."
