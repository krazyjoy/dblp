uuid,title,response
uss_2024_0,"33rd USENIX Security Symposium, USENIX Security 2024, Philadelphia, PA, USA, August 14-16, 2024.","No, the given abstract ""nan"" does not contain any specific information or context related to adversarial machine learning or any other topic."
uss_2024_1,"""I feel physically safe but not politically safe"": Understanding the Digital Threats and Safety Practices of OnlyFans Creators.","No, the abstract is not related to AML. It focuses on the online harassment and safety practices of OnlyFans creators, rather than adversarial attacks or defenses within machine learning systems."
uss_2024_2,"""I chose to fight, be brave, and to deal with it"": Threat Experiences and Security Practices of Pakistani Content Creators.","No. The abstract focuses on the online threat landscape and protective measures concerning content creators in Pakistan but does not mention machine learning systems, adversarial attacks, or techniques relevant to Adversarial Machine Learning."
uss_2024_3,Investigating Moderation Challenges to Combating Hate and Harassment: The Case of Mod-Admin Power Dynamics and Feature Misuse on Reddit.,"No. The abstract focuses on the challenges and strategies of moderators dealing with online abuse on social media platforms, but it does not involve machine learning systems or adversarial attacks against such systems."
uss_2024_4,"""Did They F***ing Consent to That?"": Safer Digital Intimacy via Proactive Protection Against Image-Based Sexual Abuse.","No. The abstract focuses on the risks and prevention strategies related to the sharing of intimate content and image-based sexual abuse, without discussing machine learning systems or adversarial attacks."
uss_2024_5,AttackGNN: Red-Teaming GNNs in Hardware Security Using Reinforcement Learning.,"No. The abstract focuses on using machine learning techniques, specifically graph neural networks (GNNs), for detecting security issues in hardware, without discussing adversarial attacks or defenses related to machine learning systems."
uss_2024_6,INSIGHT: Attacking Industry-Adopted Learning Resilient Logic Locking Techniques Using Explainable Graph Neural Network.,"Yes. The abstract discusses the development of learning-resilient locking techniques to protect against powerful ML-based attacks, which is directly related to adversarial machine learning by focusing on hardware security against such attacks."
uss_2024_7,Eye of Sauron: Long-Range Hidden Spy Camera Detection and Positioning with Inbuilt Memory EM Radiation.,"No. The abstract is focused on detecting spy cameras using electromagnetic radiation patterns, which is not related to adversarial machine learning attacks or defenses."
uss_2024_8,Improving the Ability of Thermal Radiation Based Hardware Trojan Detection.,"No. The abstract is primarily focused on hardware security and methods for detecting hardware Trojans using thermal radiation, rather than on adversarial attacks or defenses in machine learning systems."
uss_2024_9,Endokernel: A Thread Safe Monitor for Lightweight Subprocess Isolation.,"No. The abstract discusses application compartmentalization and memory isolation for enhancing security, which is more related to systems security rather than adversarial machine learning."
uss_2024_10,HIVE: A Hardware-assisted Isolated Execution Environment for eBPF on AArch64.,"No, the abstract is not related to AML. It focuses on enhancing security for eBPF programs in the Linux kernel through isolation techniques, rather than discussing adversarial attacks or defenses related to machine learning systems."
uss_2024_11,BUDAlloc: Defeating Use-After-Free Bugs by Decoupling Virtual Address Management from Kernel.,"No, the given abstract is not related to AML as it focuses on memory allocation techniques to prevent or detect use-after-free bugs in software, which is more relevant to system-level security rather than adversarial machine learning."
uss_2024_12,Page-Oriented Programming: Subverting Control-Flow Integrity of Commodity Operating System Kernels with Non-Writable Code Pages.,"No. The abstract focuses on a novel code-reuse attack technique related to kernel vulnerability and integrity breaches, not specifically on adversarial attacks or defenses in the context of machine learning systems."
uss_2024_13,SmartCookie: Blocking Large-Scale SYN Floods with a Split-Proxy Defense on Programmable Data Planes.,"No, the abstract is not related to AML because it focuses on defending against SYN flooding attacks, a type of network security issue, and does not involve manipulating or protecting against machine learning systems or models."
uss_2024_14,Loopy Hell(ow): Infinite Traffic Loops at the Application Layer.,"No, the given abstract is unrelated to AML as it discusses Denial-of-Service (DoS) attacks and traffic loops in network infrastructures, rather than adversarial manipulation or attacks on machine learning systems."
uss_2024_15,Zero-setup Intermediate-rate Communication Guarantees in a Global Internet.,"No, the abstract is not related to Adversarial Machine Learning. It focuses on addressing volumetric DDoS attacks in networks, which is a cybersecurity issue, rather than discussing attacks or defenses related to machine learning systems."
uss_2024_16,Towards an Effective Method of ReDoS Detection for Non-backtracking Engines.,"No, the given abstract is not related to Adversarial Machine Learning (AML) as it focuses on detecting vulnerabilities related to Regular expression Denial of Service (ReDoS) attacks, which are not specifically about manipulating or defending machine learning models."
uss_2024_17,FAMOS: Robust Privacy-Preserving Authentication on Payment Apps via Federated Multi-Modal Contrastive Learning.,"No, the abstract is not related to Adversarial Machine Learning (AML) because it addresses issues in behavioral authentication and user privacy rather than discussing adversarial attacks or defenses against machine learning models."
uss_2024_18,Efficient Privacy Auditing in Federated Learning.,"Yes. The abstract is related to AML because it describes a membership inference attack, which is a type of adversarial attack aimed at assessing privacy risks in federated learning."
uss_2024_19,Defending Against Data Reconstruction Attacks in Federated Learning: An Information Theory Approach.,"Yes, the abstract is related to AML because it discusses how Federated Learning is vulnerable to membership inference and data reconstruction attacks, which are forms of adversarial attacks on machine learning systems."
uss_2024_20,Lotto: Secure Participant Selection against Adversarial Servers in Federated Learning.,"Yes, the abstract is related to AML because it addresses adversarial threats in Federated Learning, focusing on how to protect against an adversarial server's manipulation to ensure secure participant selection."
uss_2024_21,Ahoy SAILR! There is No Need to DREAM of C: A Compiler-Aware Structuring Algorithm for Binary Decompilation.,"No. The abstract focuses on the process of decompilation and preserving the structure of original source code, which is unrelated to adversarial machine learning or manipulation of machine learning models."
uss_2024_22,A Taxonomy of C Decompiler Fidelity Issues.,"No, the given abstract is not related to AML as it focuses on evaluating and improving the fidelity of decompiler output, which pertains to reverse engineering and computer security, rather than manipulating or defending against machine learning models."
uss_2024_23,D-Helix: A Generic Decompiler Testing Framework Using Symbolic Differentiation.,"No. The abstract discusses the accuracy and correctness of decompilers and their effect on security tasks, but does not focus on adversarial attacks or defenses in the context of machine learning systems."
uss_2024_24,SymFit: Making the Common (Concrete) Case Fast for Binary-Code Concolic Execution.,"No. The abstract describes improvements in concolic execution related to software testing and optimization, without discussing adversarial machine learning or attacks on machine learning systems."
uss_2024_25,K-Waay: Fast and Deniable Post-Quantum X3DH without Ring Signatures.,No. The abstract is focused on improving cryptographic protocols to be quantum secure and does not involve adversarial techniques or machine learning systems.
uss_2024_26,Diffie-Hellman Picture Show: Key Exchange Stories from Commercial VoWiFi Deployments.,No. The abstract focuses on the security protocols and encryption mechanisms involved in VoWiFi communication rather than on attacking or defending machine learning systems.
uss_2024_27,Formal verification of the PQXDH Post-Quantum key agreement protocol for end-to-end secure messaging.,"No. The abstract is about the introduction of a new key agreement protocol in messaging which focuses on providing post-quantum security and encryption, not about adversarial machine learning attacks or defenses."
uss_2024_28,SWOOSH: Efficient Lattice-Based Non-Interactive Key Exchange.,"No, the abstract is not related to AML as it focuses on lattice-based cryptography for post-quantum cryptography schemes and does not discuss machine learning or adversarial attacks on ML systems."
uss_2024_29,PhishDecloaker: Detecting CAPTCHA-cloaked Phishing Websites via Hybrid Vision-based Interactive Models.,"No. The abstract primarily discusses phishing attacks using CAPTCHA-based cloaking techniques to evade detection, which is more related to cybersecurity and social engineering, and does not focus on manipulating machine learning systems or models as in AML."
uss_2024_30,Less Defined Knowledge and More True Alarms: Reference-based Phishing Detection without a Pre-defined Reference List.,"No. The abstract discusses phishing detection methods, which focus on reference-based techniques for identifying phishing websites, and does not mention any manipulation or attack on machine learning models."
uss_2024_31,In Wallet We Trust: Bypassing the Digital Wallets Payment Security for Free Shopping.,"No, the abstract is not related to Adversarial Machine Learning (AML) because it focuses on the security vulnerabilities in digital payment systems rather than attacks or defenses involving machine learning models."
uss_2024_32,The Impact of Exposed Passwords on Honeyword Efficacy.,"No, the abstract is not related to AML as it focuses on honeywords for detecting credential leaks and does not involve manipulating machine learning systems or defending against adversarial attacks."
uss_2024_33,InSpectre Gadget: Inspecting the Residual Attack Surface of Cross-privilege Spectre v2.,"No, the given abstract is not related to AML as it focuses on Spectre v2, a security vulnerability related to speculative execution in CPUs, rather than adversarial attacks on machine learning models."
uss_2024_34,Shesha : Multi-head Microarchitectural Leakage Discovery in new-generation Intel Processors.,"No. The abstract is related to microarchitectural side-channel attacks, specifically focusing on the discovery of transient execution vulnerabilities in CPUs, which is different from adversarial attacks on machine learning models."
uss_2024_35,BeeBox: Hardening BPF against Transient Execution Attacks.,"No. The abstract is related to security architecture and mitigating transient execution attacks in the context of the OS kernel, without discussing machine learning or adversarial attacks on ML systems."
uss_2024_36,SpecLFB: Eliminating Cache Side Channels in Speculative Executions.,No. The abstract is related to mitigating cache side-channel attacks through hardware design and is unrelated to adversarial machine learning.
uss_2024_37,Towards Privacy-Preserving Social-Media SDKs on Android.,"No, the abstract is not related to AML. It focuses on addressing privacy threats and compliance issues with social SDKs rather than adversarial attacks or manipulating machine learning models."
uss_2024_38,UIHash: Detecting Similar Android UIs through Grid-Based Visual Appearance Representation.,"Yes. The abstract is related to AML because it discusses the development of a more robust method for detecting visually deceptive user interfaces, which are a type of evasion attack, to prevent phishing and spoofing attacks."
uss_2024_39,Racing for TLS Certificate Validation: A Hijacker's Guide to the Android TLS Galaxy.,"No, the abstract is not related to AML because it focuses on TLS validation issues in Android apps and their exploitation by network attackers, not on adversarial attacks or defenses on machine learning systems."
uss_2024_40,DVa: Extracting Victims and Abuse Vectors from Android Accessibility Malware.,"No. The abstract is related to malware analysis and detection on Android devices rather than adversarial machine learning, as it does not mention manipulation or attacks specifically targeting machine learning models."
uss_2024_41,SoK: State of the Krawlers - Evaluating the Effectiveness of Crawling Algorithms for Web Security Measurements.,"No. The abstract focuses on web crawlers used in web security measurements and their performance evaluation, without discussing any aspect of adversarial machine learning or attacks on machine learning systems."
uss_2024_42,Vulnerability-oriented Testing for RESTful APIs.,No. The abstract focuses on designing a framework for vulnerability detection in RESTful APIs rather than involving any aspects of manipulating or defending against adversarial inputs specifically in machine learning systems.
uss_2024_43,Web Platform Threats: Automated Detection of Web Security Issues With WPT.,"No, the abstract is not related to AML. It focuses on detecting security flaws in client-side security mechanisms in web browsers, not on adversarial attacks or defenses in machine learning systems."
uss_2024_44,Rise of Inspectron: Automated Black-box Auditing of Cross-platform Electron Apps.,No. The given abstract is not related to Adversarial Machine Learning because it focuses on auditing security vulnerabilities in Electron apps rather than addressing adversarial attacks or defenses against machine learning models.
uss_2024_45,KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection.,"No. While the abstract discusses phishing detection and improvements over existing methods, it does not focus on adversarial attacks or defenses within the context of machine learning systems."
uss_2024_46,Exploring ChatGPT's Capabilities on Vulnerability Management.,"No, the abstract is not related to AML because it focuses on ChatGPT's capabilities in code analysis and vulnerability management, rather than on adversarial attacks or defenses in machine learning systems."
uss_2024_47,Large Language Models for Code Analysis: Do LLMs Really Do Their Job?,"No, the abstract is not related to AML. It discusses the evaluation of large language models for code analysis, but it does not mention any intention to manipulate the models or protect against adversarial attacks."
uss_2024_48,PentestGPT: Evaluating and Harnessing Large Language Models for Automated Penetration Testing.,"No, the abstract is not related to AML. It focuses on the application of large language models for automating penetration testing processes rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2024_49,OptFuzz: Optimization Path Guided Fuzzing for JavaScript JIT Compilers.,"No, the abstract is not related to AML because it focuses on a fuzzing solution for testing optimization paths in JavaScript JIT compilers rather than addressing any adversarial aspects or manipulations of machine learning systems."
uss_2024_50,Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing.,"No. The abstract describes techniques to improve software testing and vulnerability detection in BusyBox using fuzzing and large language models, but it does not involve manipulating or attacking a machine learning system."
uss_2024_51,Towards Generic Database Management System Fuzzing.,"No, the abstract is not related to AML as it focuses on developing a fuzzing framework to test database management systems for vulnerabilities, without addressing adversarial attacks on machine learning systems."
uss_2024_52,HYPERPILL: Fuzzing for Hypervisor-bugs by leveraging the Hardware Virtualization Interface.,"No, the given abstract is not related to Adversarial Machine Learning (AML) as it focuses on identifying vulnerabilities in hypervisors for cloud computing security, rather than discussing attacks or defenses specific to machine learning systems."
uss_2024_53,Less is More: Revisiting the Gaussian Mechanism for Differential Privacy.,No. The abstract discusses differential privacy and Gaussian mechanisms for data privacy rather than adversarial attacks or defenses targeting machine learning models.
uss_2024_54,Relation Mining Under Local Differential Privacy.,"No. The abstract discusses a privacy-preserving data mining method using local differential privacy, which is more related to data privacy and security rather than adversarial machine learning or attacks on machine learning models."
uss_2024_55,Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD.,"Yes, the abstract is related to AML because it analyzes the privacy leakage in DP-SGD, highlighting how certain data points may be more susceptible to attacks, which is pertinent to understanding and defending against adversarial attacks in machine learning."
uss_2024_56,DPAdapter: Improving Differentially Private Deep Learning through Noise Tolerance Pre-training.,"No, the abstract is not related to AML. It focuses on the integration of differential privacy in machine learning to protect individual data, which is more about privacy preservation than adversarial attacks or manipulations."
uss_2024_57,Double Face: Leveraging User Intelligence to Characterize and Recognize AI-synthesized Faces.,"Yes. This abstract is related to AML as it discusses the use of AI-synthesized face images for deceptive purposes, which can be considered an adversarial attack to manipulate user trust and opinions."
uss_2024_58,"SoK: The Good, The Bad, and The Unbalanced: Measuring Structural Limitations of Deepfake Media Datasets.","Yes. The abstract is related to AML as it discusses deepfake media, which involves manipulating inputs to deceive systems, and focuses on building defenses against such adversarial techniques."
uss_2024_59,Can I Hear Your Face? Pervasive Attack on Voice Authentication Systems with a Single Face Image.,"Yes, because the abstract describes a method to create synthetic voice samples to deceive voice authentication systems, which is an example of an adversarial attack against machine learning models."
uss_2024_60,dp-promise: Differentially Private Diffusion Probabilistic Models for Image Synthesis.,"Yes, because the abstract discusses privacy concerns and a solution involving differentially private diffusion models in deep learning, which is a relevant aspect of adversarial machine learning."
uss_2024_61,DMAAUTH: A Lightweight Pointer Integrity-based Secure Architecture to Defeat DMA Attacks.,"No, the abstract is unrelated to AML as it discusses the performance and vulnerabilities of the IOMMU in preventing DMA attacks, which is more relevant to hardware security than adversarial machine learning."
uss_2024_62,Bending microarchitectural weird machines towards practicality.,"No. The abstract is related to microarchitectural attacks on CPUs, which focus on hardware security vulnerabilities rather than manipulating inputs or behaviors of machine learning models."
uss_2024_63,GoFetch: Breaking Constant-Time Cryptographic Implementations Using Data Memory-Dependent Prefetchers.,"No. The abstract is related to microarchitectural side-channel attacks, which pertain to hardware security and not adversarial machine learning."
uss_2024_64,CacheWarp: Software-based Fault Injection using Selective State Reset.,"No. The abstract is focused on a trusted-execution environment (TEE) for virtual machines, which pertains to hardware security rather than adversarial machine learning."
uss_2024_65,MOAT: Towards Safe BPF Kernel Extension.,"No, the given abstract is not related to Adversarial Machine Learning (AML). It focuses on using Intel Memory Protection Keys to improve the isolation of BPF programs for kernel security, rather than discussing attacks or defenses specific to machine learning models."
uss_2024_66,SeaK: Rethinking the Design of a Secure Allocator for OS Kernel.,No. The abstract focuses on securing the Linux kernel heap from heap-based exploitation and does not involve machine learning models or adversarial attacks or defenses.
uss_2024_67,Take a Step Further: Understanding Page Spray in Linux Kernel Exploitation.,"No, the abstract is not related to AML. It focuses on understanding and mitigating a specific kernel vulnerability exploitation technique called Page Spray, which does not involve adversarial attacks or defenses in machine learning systems."
uss_2024_68,SafeFetch: Practical Double-Fetch Protection with Kernel-Fetch Caching.,"No. The abstract is related to operating system security and describes double-fetch bugs and their mitigation, which are not related to adversarial machine learning."
uss_2024_69,LanDscAPe: Exploring LDAP weaknesses and data leaks at Internet scale.,No. The abstract focuses on the security and storage capabilities of LDAP directories rather than discussing adversarial attacks or defenses specific to machine learning systems.
uss_2024_70,FakeBehalf: Imperceptible Email Spoofing Attacks against the Delegation Mechanism in Email Systems.,"No. The abstract focuses on vulnerabilities in email protocols and mechanisms related to spoofing, which is more related to cyber security and email security rather than adversarial attacks on machine learning models."
uss_2024_71,Rethinking the Security Threats of Stale DNS Glue Records.,"No, the abstract is not related to AML. It focuses on the security risks and vulnerabilities associated with DNS glue records, rather than on adversarial attacks or defenses targeting machine learning systems."
uss_2024_72,EVOKE: Efficient Revocation of Verifiable Credentials in IoT Networks.,"No. The abstract focuses on trust and security issues related to IoT devices using decentralized identifiers and verifiable credentials, without addressing adversarial machine learning attacks or defenses."
uss_2024_73,DNN-GP: Diagnosing and Mitigating Model's Faults Using Latent Concepts.,"Yes. The abstract is related to AML as it discusses adversarial attacks and how the proposed tool, DNN-GP, interprets and mitigates faults in DNNs caused by such attacks and concept drift."
uss_2024_74,"Yes, One-Bit-Flip Matters! Universal DNN Model Inference Depletion with Runtime Code Fault Injection.","Yes. The abstract is related to AML as it describes FrameFlip, an attack targeting DNN model inference through fault injection, which fits into the category of adversarial attacks on machine learning models."
uss_2024_75,Tossing in the Dark: Practical Bit-Flipping on Gray-box Deep Neural Networks for Runtime Trojan Injection.,"Yes, the abstract is related to AML as it discusses a novel type of attack on deep neural networks—run-time Trojan injection—which manipulates the model's inputs to implant a Trojan, thereby aligning with adversarial machine learning objectives."
uss_2024_76,Forget and Rewire: Enhancing the Resilience of Transformer-based Models against Bit-Flip Attacks.,"Yes, the abstract is related to AML because it discusses a defense mechanism against Bit-Flip Attacks (BFAs), which are a type of adversarial attack on machine learning models."
uss_2024_77,What IF Is Not Enough? Fixing Null Pointer Dereference With Contextual Check.,"No, the abstract is not related to AML because it focuses on generating fixes for null pointer dereference errors in software development, not on machine learning or adversarial attacks against ML models."
uss_2024_78,Unleashing the Power of Type-Based Call Graph Construction by Using Regional Pointer Information.,"No, this abstract is not related to AML. It focuses on improving the precision and scalability of call graph construction in C code through pointer analysis, which is unrelated to adversarial machine learning or manipulating ML models."
uss_2024_79,Practical Data-Only Attack Generation.,"No. The abstract focuses on control-flow hijacking and data-only attacks, which are related to exploiting software vulnerabilities but not specifically related to attacking or manipulating machine learning models."
uss_2024_80,Don't Waste My Efforts: Pruning Redundant Sanitizer Checks by Developer-Implemented Type Checks.,"No. The abstract discusses type confusion vulnerabilities in C or C++ code and the methods to detect them, which is related to programming language security, not adversarial machine learning."
uss_2024_81,Two Shuffles Make a RAM: Improved Constant Overhead Zero Knowledge RAM.,"No. The abstract is related to optimizing Zero Knowledge proofs, which are cryptographic techniques, and it does not discuss any machine learning models or adversarial machine learning attacks and defenses."
uss_2024_82,Notus: Dynamic Proofs of Liabilities from Zero-knowledge RSA Accumulators.,"No, the abstract is not related to AML as it focuses on cryptographic proofs and liability verification in financial systems, rather than on machine learning systems and adversarial attacks or defenses."
uss_2024_83,Practical Security Analysis of Zero-Knowledge Proof Circuits.,"No. The abstract is focused on detecting vulnerabilities in zero-knowledge proof circuits using static analysis, which is related to security and privacy but not specifically to adversarial machine learning techniques or attacks on machine learning models."
uss_2024_84,Formalizing Soundness Proofs of Linear PCP SNARKs.,"No. The abstract is focused on SNARKs, which are cryptographic constructs related to proving statements about knowledge efficiently; it doesn't address machine learning systems or adversarial attacks."
uss_2024_85,Guardians of the Galaxy: Content Moderation in the InterPlanetary File System.,"No, the abstract is not related to Adversarial Machine Learning. It discusses content moderation challenges in the InterPlanetary File System (IPFS), focusing on the identification and removal of problematic content without involving machine learning models or adversarial attacks."
uss_2024_86,"True Attacks, Attack Attempts, or Benign Triggers? An Empirical Measurement of Network Alerts in a Security Operations Center.",No. The abstract focuses on the challenges faced by Security Operations Centers in handling excessive security alerts and does not mention adversarial attacks or defenses related to machine learning systems.
uss_2024_87,DARKFLEECE: Probing the Dark Side of Android Subscription Apps.,"No, the given abstract is not related to AML because it focuses on detecting fleeceware apps using dark patterns and Explainable AI, rather than discussing adversarial techniques or defenses against machine learning models."
uss_2024_88,Into the Dark: Unveiling Internal Site Search Abused for Black Hat SEO.,No. The abstract is focused on identifying and addressing a Black Hat SEO technique known as Internal Site Search Abuse Promotion (ISAP) without specific mention or use of adversarial machine learning methods or techniques.
uss_2024_89,ABACuS: All-Bank Activation Counters for Scalable and Low Overhead RowHammer Mitigation.,"No. The abstract discusses a hardware-based RowHammer mitigation technique, which is focused on addressing specific hardware vulnerabilities rather than adversarial machine learning attacks or defenses."
uss_2024_90,SledgeHammer: Amplifying Rowhammer via Bank-level Parallelism.,"No. This abstract discusses a hardware vulnerability called Rowhammer, which is related to hardware security, not adversarial machine learning."
uss_2024_91,ZenHammer: Rowhammer Attacks on AMD Zen-based Platforms.,"No. The abstract describes a Rowhammer attack focused on hardware memory vulnerability in AMD CPUs, which is unrelated to adversarial machine learning."
uss_2024_92,Go Go Gadget Hammer: Flipping Nested Pointers for Arbitrary Data Leakage.,"No, the abstract is not related to AML. It describes a hardware-based vulnerability in DRAM known as Rowhammer, which is not specifically about manipulating or attacking machine learning models."
uss_2024_93,00SEVen - Re-enabling Virtual Machine Forensics: Introspecting Confidential VMs Using Privileged in-VM Agents.,No. The abstract focuses on the security guarantees and forensic capabilities of confidential virtual machines (VMs) rather than discussing adversarial attacks or defenses in the context of machine learning models.
uss_2024_94,WEBRR: A Forensic System for Replaying and Investigating Web-Based Attacks in The Modern Web.,"No. The abstract is focused on web-based forensic analysis and record/replay systems for web browsers, not on adversarial attacks or defenses on machine learning models."
uss_2024_95,AI Psychiatry: Forensic Investigation of Deep Learning Networks in Memory Images.,"Yes, the abstract is related to AML because it describes a technique to recover and rehost unique deployment models for testing against potential attacks, which is a component of adversarial machine learning defense."
uss_2024_96,Cost-effective Attack Forensics by Recording and Correlating File System Changes.,No. The abstract focuses on attack forensics in IoT systems using file-system snapshots and does not mention adversarial machine learning or manipulating ML inputs.
uss_2024_97,Automated Large-Scale Analysis of Cookie Notice Compliance.,"No. The abstract focuses on privacy regulation compliance and violations related to data collection notices on websites, which is unrelated to adversarial attacks or defenses in machine learning systems."
uss_2024_98,Detecting and Mitigating Sampling Bias in Cybersecurity with Unlabeled Data.,"No. The abstract focuses on addressing sampling bias in machine learning classifiers for cybersecurity applications, rather than discussing adversarial attacks or defenses specific to adversarial machine learning."
uss_2024_99,Code is not Natural Language: Unlock the Power of Semantics-Oriented Graph Representation for Binary Code Similarity Detection.,"No. The abstract is not related to AML because it focuses on developing a novel approach for binary code similarity detection, which is not related to adversarial attacks or defenses in machine learning systems."
uss_2024_100,VulSim: Leveraging Similarity of Multi-Dimensional Neighbor Embeddings for Vulnerability Detection.,"No, the abstract is not related to AML because it focuses on vulnerability detection in software using deep learning models, rather than examining or defending against adversarial techniques aimed at deceiving such models."
uss_2024_101,An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection.,"Yes. The abstract is related to AML as it discusses CodeBreaker, a framework specifically for performing backdoor attacks on code completion models using LLMs, highlighting a form of adversarial attack in machine learning."
uss_2024_102,REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models.,"Yes. The abstract discusses watermarking frameworks for texts generated by large language models to protect against malicious exploitation, which aligns with adversarial machine learning concepts such as defending against misuse and manipulation of ML-generated content."
uss_2024_103,Formalizing and Benchmarking Prompt Injection Attacks and Defenses.,"Yes, the abstract is related to AML as it discusses prompt injection attacks on LLM-Integrated Applications, which are a type of adversarial attack targeting machine learning models, and provides a framework and evaluations for understanding and defending against such attacks."
uss_2024_104,Instruction Backdoor Attacks Against Customized LLMs.,"Yes. The abstract is related to AML as it discusses backdoor attacks on customized Large Language Models, which are a form of adversarial manipulation, and also suggests possible defenses."
uss_2024_105,FIRE: Combining Multi-Stage Filtering with Taint Analysis for Scalable Recurring Vulnerability Detection.,"No. The abstract focuses on a method for detecting recurring vulnerabilities in open-source software, which is more related to software security than adversarial machine learning."
uss_2024_106,Inference of Error Specifications and Bug Detection Using Structural Similarities.,"No, the abstract is not related to Adversarial Machine Learning (AML) because it focuses on error-handling in system software to detect bugs, rather than discussing vulnerabilities or defenses in machine learning models."
uss_2024_107,A Binary-level Thread Sanitizer or Why Sanitizing on the Binary Level is Hard.,"No. The abstract discusses dynamic software testing and binary instrumentation using fuzzing techniques, but does not mention adversarial machine learning or methods for attacking or defending machine learning models."
uss_2024_108,ORANalyst: Systematic Testing Framework for Open RAN Implementations.,"No, the abstract is not related to Adversarial Machine Learning because it focuses on testing the robustness and identifying vulnerabilities in Open RAN implementations, which are not specifically related to manipulating or defending against machine learning models."
uss_2024_109,Scalable Multi-Party Computation Protocols for Machine Learning in the Honest-Majority Setting.,"No. This abstract is related to privacy-preserving machine learning (PPML) using multi-party computation (MPC) techniques, but it does not specifically discuss adversarial attacks or defenses concerning AML."
uss_2024_110,Lightweight Authentication of Web Data via Garble-Then-Prove.,"No. The abstract focuses on improving the efficiency of Transport Layer Security (TLS) proofs using Two-Party Computation for privacy and data authenticity, which is unrelated to adversarial machine learning."
uss_2024_111,Holding Secrets Accountable: Auditing Privacy-Preserving Machine Learning.,"No, the abstract is not related to AML because it focuses on enhancing privacy-preserving machine learning and auditing, without discussing adversarial attacks or defenses against such attacks."
uss_2024_112,Secure Account Recovery for a Privacy-Preserving Web Service.,"No. The abstract focuses on designing a cryptographic protocol for account recovery on a web service, which is related to security and privacy but not specifically about adversarial attacks or defenses in machine learning."
uss_2024_113,Navigating Traumatic Stress Reactions During Computer Security Interventions.,"No, the abstract is not related to AML. It discusses the provision of security support to at-risk populations experiencing trauma, but does not involve attacks or defenses related to machine learning systems."
uss_2024_114,Exploring digital security and privacy in relative poverty in Germany through qualitative interviews.,No. The abstract focuses on understanding the security and privacy concerns of low-income users and does not discuss adversarial machine learning or attacks on machine learning systems.
uss_2024_115,"""But they have overlooked a few things in Afghanistan: "" An Analysis of the Integration of Biometric Voter Verification in the 2019 Afghan Presidential Elections.","No, the abstract is not related to AML because it focuses on the use of biometric voter verification in an election context and does not discuss any manipulation or adversarial interactions with machine learning systems."
uss_2024_116,Understanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants.,"No. The abstract focuses on data privacy challenges for blind and low-vision users and their interactions with privacy tools, rather than adversarial attacks, defenses, or manipulations in machine learning systems."
uss_2024_117,Assessing Suspicious Emails with Banner Warnings Among Blind and Low-Vision Users in Realistic Settings.,"No, the abstract is not related to AML as it focuses on the accessibility and usability of email banner warnings for blind and low-vision users, rather than discussing any adversarial attacks or defenses in the context of machine learning systems."
uss_2024_118,Invalidate+Compare: A Timer-Free GPU Cache Attack Primitive.,"No. The abstract focuses on cache side-channel attacks on GPUs, which are related to hardware security rather than adversarial machine learning methods or defenses."
uss_2024_119,Peep With A Mirror: Breaking The Integrity of Android App Sandboxing via Unprivileged Cache Side Channel.,"No. The abstract focuses on side-channel attacks related to hardware security and app sandboxing in the Android platform, not on adversarial attacks or defenses within machine learning systems."
uss_2024_120,Indirector: High-Precision Branch Target Injection Attacks Exploiting the Indirect Branch Predictor.,"No, the abstract is not related to AML. It focuses on exploiting vulnerabilities in CPU branch prediction mechanisms and hardware defenses, rather than on manipulating machine learning systems or models."
uss_2024_121,Prefetch for Fun and Profit: A Revisit of Prefetch Attacks on Apple M1.,"No. The given abstract ""nan"" does not provide any information about adversarial machine learning or related topics."
uss_2024_122,Intellectual Property Exposure: Subverting and Securing Intellectual Property Encapsulation in Texas Instruments Microcontrollers.,"No, the given abstract is not related to Adversarial Machine Learning because it focuses on evaluating and exploiting security vulnerabilities in embedded device hardware and software, not on manipulating or attacking machine learning models."
uss_2024_123,AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE.,"No. The abstract focuses on secure inference of CNNs using RNS-CKKS and optimizes efficiency and accuracy, but it does not address adversarial attacks or defenses in machine learning."
uss_2024_124,Fast and Private Inference of Deep Neural Networks by Co-designing Activation Functions.,"No, the abstract is not related to AML because it focuses on improving the efficiency of privacy-preserving inference in Machine Learning as a Service using multi-party computation, without addressing adversarial attacks or defenses."
uss_2024_125,OblivGNN: Oblivious Inference on Transductive and Inductive Graph Neural Network.,No. The abstract primarily focuses on privacy concerns and the deployment of GNNs in cloud-based services rather than on adversarial attacks or defenses related to machine learning systems.
uss_2024_126,MD-ML: Super Fast Privacy-Preserving Machine Learning for Malicious Security with a Dishonest Majority.,"No, the abstract is not related to Adversarial Machine Learning because it focuses on privacy-preserving machine learning using secure multi-party computation, which is more about data privacy and security rather than manipulating or defending against adversarial attacks on machine learning models."
uss_2024_127,Accelerating Secure Collaborative Machine Learning with Protocol-Aware RDMA.,"No, the abstract is not related to AML. It focuses on improving the efficiency of secure collaborative machine learning through optimized communication protocols, rather than discussing adversarial attacks or defenses in machine learning systems."
uss_2024_128,CalcuLatency: Leveraging Cross-Layer Network Latency Measurements to Detect Proxy-Enabled Abuse.,"No. The given abstract discusses abuse prevention in ad delivery systems related to geolocation fraud and privacy concerns, not the exploitation or manipulation of machine learning models."
uss_2024_129,6Sense: Internet-Wide IPv6 Scanning and its Security Applications.,"No. The abstract is focused on the development of IPv6 scanning methods for enhancing Internet security, rather than discussing techniques related to adversarial machine learning or attacks on machine learning models."
uss_2024_130,A Flushing Attack on the DNS Cache.,"No. The abstract describes a vulnerability in the DNS resolver's cache and introduces a novel attack on DNS, which is more related to network security rather than adversarial machine learning."
uss_2024_131,SnailLoad: Exploiting Remote Network Latency Measurements without JavaScript.,"No. The abstract focuses on inferring user activities from network traffic rather than manipulating or exploiting machine learning models specifically, which falls outside the scope of adversarial machine learning."
uss_2024_132,An Interview Study on Third-Party Cyber Threat Hunting Processes in the U.S. Department of Homeland Security.,No. The abstract focuses on cyber threat hunting as a proactive cybersecurity measure and does not mention adversarial attacks on machine learning models or how machine learning is involved in the threat hunting process.
uss_2024_133,A Linear Reconstruction Approach for Attribute Inference Attacks against Synthetic Data.,"Yes. This abstract is related to AML as it discusses inference attacks on synthetic data, which is a type of adversarial attack targeting machine learning systems to compromise privacy."
uss_2024_134,Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models.,"Yes. The abstract is related to AML as it discusses a method for membership inference attacks on large language models to determine if a document was part of the model's training data, which is a type of inference attack in adversarial machine learning."
uss_2024_135,MIST: Defending Against Membership Inference Attacks Through Membership-Invariant Subspace Training.,"Yes. The abstract discusses Member Inference (MI) attacks, which are a type of adversarial attack on machine learning models, and the defenses against such attacks, making it relevant to adversarial machine learning."
uss_2024_136,Inf2Guard: An Information-Theoretic Framework for Learning Privacy-Preserving Representations against Inference Attacks.,"No, the abstract provided is insufficient and does not provide any information for determining relevance to adversarial machine learning."
uss_2024_137,Property Existence Inference against Generative Models.,"Yes, because the abstract discusses exploiting generative models to infer property existence in the training data, which is an information leakage attack—a type of adversarial attack in AML."
uss_2024_138,SDFuzz: Target States Driven Directed Fuzzing.,"No. The abstract discusses directed fuzzing, a software testing technique focused on identifying vulnerabilities in program code, without any mention of machine learning models or adversarial attacks."
uss_2024_139,Critical Code Guided Directed Greybox Fuzzing for Commits.,"No. The abstract discusses improving fuzzing techniques to test commit changes for vulnerabilities, which is related to software testing and security, rather than adversarial machine learning."
uss_2024_140,Toward Unbiased Multiple-Target Fuzzing with Path Diversity.,"No. The abstract discusses directed fuzzing, a software testing technique for discovering vulnerabilities, without mentioning adversarial interactions, attacks, or defenses relevant to machine learning systems."
uss_2024_141,SymBisect: Accurate Bisection for Fuzzer-Exposed Vulnerabilities.,No. The abstract is focused on improving fuzzing and bug bisection techniques for software development rather than discussing adversarial attacks or defenses on machine learning systems.
uss_2024_142,Data Coverage for Guided Fuzzing.,"No. The abstract discusses code coverage and fuzzing in the context of identifying program bugs, but it does not mention machine learning or any adversarial attacks on machine learning systems."
uss_2024_143,I/O-Efficient Dynamic Searchable Encryption meets Forward & Backward Privacy.,"No. The abstract is about improving efficiency and privacy in dynamic searchable encryption, which is related to data security and cryptography, not adversarial machine learning."
uss_2024_144,FEASE: Fast and Expressive Asymmetric Searchable Encryption.,"No, the abstract is not related to AML. It discusses cryptographic techniques for searchable encryption and attribute-based encryption, with no mention of adversarial machine learning or attacks on ML models."
uss_2024_145,d-DSE: Distinct Dynamic Searchable Encryption Resisting Volume Leakage in Encrypted Databases.,"No. The abstract focuses on Dynamic Searchable Encryption and handling volume leakage, which are related to data encryption and security, not adversarial machine learning or attacks on ML models."
uss_2024_146,MUSES: Efficient Multi-User Searchable Encrypted Database.,No. The abstract discusses searchable encrypted systems and their associated challenges but does not address adversarial attacks or defenses related to machine learning systems.
uss_2024_147,Query Recovery from Easy to Hard: Jigsaw Attack against SSE.,"No. The abstract is related to searchable symmetric encryption and the leakage of sensitive information, not specifically about adversarial attacks or defenses on machine learning models."
uss_2024_148,GFWeb: Measuring the Great Firewall's Web Censorship at Scale.,"No, the abstract is not related to AML. It focuses on understanding and measuring the censorship mechanisms of the Great Firewall rather than adversarial attacks or defenses involving machine learning systems."
uss_2024_149,"Snowflake, a censorship circumvention system using temporary WebRTC proxies.","No, the abstract describes a system for circumventing internet censorship using dynamic proxies, which is focused on network security rather than adversarial machine learning attacks or defenses on ML systems."
uss_2024_150,SpotProxy: Rediscovering the Cloud for Censorship Circumvention.,"No, the abstract is not related to AML because it focuses on utilizing cloud features for censorship circumvention, without discussing any adversarial attacks or defenses in machine learning systems."
uss_2024_151,Bridging Barriers: A Survey of Challenges and Priorities in the Censorship Circumvention Landscape.,"No. The abstract discusses censorship circumvention tools and their distribution, which is unrelated to adversarial machine learning, as it does not involve manipulating or defending against machine learning models."
uss_2024_152,Fingerprinting Obfuscated Proxy Traffic with Encapsulated TLS Handshakes.,"No, this abstract is not related to Adversarial Machine Learning (AML) because it focuses on detecting proxy protocols and tunneling methods in Internet traffic, which relates to network security and can be considered under the domain of cybersecurity, rather than attacking or defending machine learning models."
uss_2024_153,When the User Is Inside the User Interface: An Empirical Study of UI Security Properties in Augmented Reality.,"No. The abstract focuses on UI security in augmented reality platforms, specifically addressing UI security properties and their implications, rather than adversarial machine learning or attacks on AI models."
uss_2024_154,Can Virtual Reality Protect Users from Keystroke Inference Attacks?,"Yes, the abstract is related to AML because it involves designing attacks that infer private information in a machine learning context, specifically through analyzing user interactions in virtual reality environments."
uss_2024_155,Remote Keylogging Attacks in Multi-user VR Applications.,"No, the abstract is not related to Adversarial Machine Learning (AML). While it involves a security threat, the focus is on extracting sensitive information in virtual reality environments through motion data rather than on manipulating or attacking machine learning systems directly."
uss_2024_156,That Doesn't Go There: Attacks on Shared State in Multi-User Augmented Reality Applications.,"Yes. The abstract discusses novel attacks related to poisoning and unauthorized access in augmented reality frameworks, which involves adversarial interactions and vulnerabilities in machine learning systems managing shared state."
uss_2024_157,Penetration Vision through Virtual Reality Headsets: Identifying 360-degree Videos from Head Movements.,"No. The abstract describes a side-channel attack leveraging physical user behavior (head movements) to infer information, which does not involve manipulating or misleading a machine learning model directly, so it is not related to adversarial machine learning."
uss_2024_158,"""I'm not convinced that they don't collect more than is necessary"": User-Controlled Data Minimization Design in Search Engines.","No, the abstract is not related to AML as it focuses on the principle of data minimization from a user-centered perspective, rather than on adversarial techniques or manipulations targeting machine learning systems."
uss_2024_159,The Effect of Design Patterns on (Present and Future) Cookie Consent Decisions.,"No. The abstract focuses on the study of user consent banner designs and their impact on decisions in compliance with GDPR, which does not involve adversarial manipulation or attacks on machine learning systems."
uss_2024_160,Unpacking Privacy Labels: A Measurement and Developer Perspective on Google's Data Safety Section.,No. The abstract is unrelated to AML as it focuses on data transparency and privacy practices within the Google Data Safety Section rather than any adversarial machine learning techniques or attacks.
uss_2024_161,"Dissecting Privacy Perspectives of Websites Around the World: ""Aceptar Todo, Alle Akzeptieren, Accept All..."".","No. The abstract focuses on privacy laws, user consent, and privacy practices on websites, without discussing adversarial machine learning or related attacks and defenses."
uss_2024_162,Data Subjects' Reactions to Exercising Their Right of Access.,"No, the abstract is not related to AML because it focuses on data subject access requests and user experiences with data transparency, which is more about privacy and data rights rather than adversarial attacks or defenses in machine learning systems."
uss_2024_163,Neural Network Semantic Backdoor Detection and Mitigation: A Causality-Based Approach.,"Yes. The abstract discusses semantic backdoors, a type of adversarial attack, in neural networks and presents a method for their detection and mitigation, which is a topic within adversarial machine learning (AML)."
uss_2024_164,On the Difficulty of Defending Contrastive Learning against Backdoor Attacks.,"Yes, the given abstract is related to AML as it discusses backdoor attacks in contrastive learning, which involve injecting malicious functions into machine learning models to manipulate their behavior, a core concept of adversarial machine learning."
uss_2024_165,Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models.,"Yes. The abstract discusses backdoor attacks and proposes a method to patch foundation models to remove these backdoors, which is a topic related to adversarial machine learning."
uss_2024_166,Xplain: Analyzing Invisible Correlations in Model Explanation.,"Yes, the abstract is related to AML because it discusses the challenges of detecting backdoor patterns in adversarial situations, which is a core concept in adversarial machine learning."
uss_2024_167,Verify your Labels! Trustworthy Predictions and Datasets via Confidence Scores.,"Yes. The abstract is related to AML because it discusses poisoning attacks, which are a type of adversarial attack in machine learning, affecting the correctness of sample-label mappings."
uss_2024_168,"More Simplicity for Trainers, More Opportunity for Attackers: Black-Box Attacks on Speaker Recognition Systems by Inferring Feature Extractor.","Yes, the given abstract is related to AML as it discusses a new adversarial example attack method called VoxCloak, which targets deep learning-based speaker recognition systems to enhance attack success rates and reduce necessary queries, clearly involving adversarial machine learning concepts."
uss_2024_169,Transferability of White-box Perturbations: Query-Efficient Adversarial Attacks against Commercial DNN Services.,"Yes, the abstract is related to AML as it discusses a new adversarial attack method, the Dispersed Sampling Attack (DSA), designed to efficiently exploit and improve attack success on Deep Neural Networks."
uss_2024_170,Adversarial Illusions in Multi-Modal Embeddings.,"Yes. The abstract is related to AML because it discusses an adversarial attack called ""adversarial illusions"" that perturbs multi-modal embeddings, which is a type of evasion attack on machine learning models."
uss_2024_171,It Doesn't Look Like Anything to Me: Using Diffusion Model to Subvert Visual Phishing Detectors.,"Yes. The abstract discusses adversarial attacks (LogoMorph) on visual phishing detectors and evaluates their impact on machine learning systems, which is directly related to adversarial machine learning (AML)."
uss_2024_172,Invisibility Cloak: Proactive Defense Against Visual Game Cheating.,"Yes. The abstract is related to AML because it discusses using imperceptible perturbations to thwart visual aimbots in gaming, which involves manipulating inputs to disrupt AI model functionality, a core aspect of adversarial machine learning."
uss_2024_173,Logic Gone Astray: A Security Analysis Framework for the Control Plane Protocols of 5G Basebands.,"No, the abstract is not related to AML. It focuses on testing and analyzing the security of 5G basebands using black-box automata learning for protocol behaviors, which is more related to security analysis and testing rather than adversarial machine learning."
uss_2024_174,SPF Beyond the Standard: Management and Operational Challenges in Practice and Practical Recommendations.,"No, this abstract is unrelated to AML as it focuses on email security vulnerabilities and countermeasures like the Sender Policy Framework, rather than discussing manipulation or attacks specifically targeting machine learning models."
uss_2024_175,A Formal Analysis of SCTP: Attack Synthesis and Patch Verification.,"No, the abstract is not related to AML. It discusses the vulnerabilities and conformance testing of the SCTP transport protocol, without addressing machine learning systems or adversarial attacks."
uss_2024_176,Athena: Analyzing and Quantifying Side Channels of Transport Layer Protocols.,"No, the abstract is related to identifying and analyzing side-channel vulnerabilities in transport layer protocols, which involves security concerns but does not specifically pertain to adversarial machine learning attacks or defenses."
uss_2024_177,"Shaken, not Stirred - Automated Discovery of Subtle Attacks on Protocols using Mix-Nets.","No. The abstract primarily focuses on Mix-Nets and cryptographic protocols, specifically how to model and identify attacks due to incorrect usage of these protocols in privacy-related contexts, rather than on adversarial machine learning techniques or defenses."
uss_2024_178,Rabbit-Mix: Robust Algebraic Anonymous Broadcast from Additive Bases.,"No, the abstract is not related to AML because it focuses on an anonymous broadcast protocol for client-server communication rather than discussing machine learning models or adversarial attacks on them."
uss_2024_179,PerfOMR: Oblivious Message Retrieval with Reduced Communication and Computation.,"No. The abstract is related to privacy and security in message delivery, focusing on protecting recipient metadata, which is not directly related to adversarial attacks or defenses in machine learning systems."
